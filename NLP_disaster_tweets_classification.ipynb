{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The goal of this notebook is to build a model that predicts which tweets are about real disasters and which ones aren't"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-25 05:42:47.031834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import sklearn \n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import xgboost\n",
    "import catboost\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F     \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages from libraries\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1108)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/alijanatiidr/Desktop/Prog/Projects/Disaster_tweets_classification/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What's up man?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>@engineshed Great atmosphere at the British Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>10834</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cramer: Iger's 3 words that wrecked Disney's s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>10837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These boxes are ready to explode! Exploding Ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>10841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sirens everywhere!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>10848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I just heard a really loud bang and everyone i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4342 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword location  \\\n",
       "15       23      NaN      NaN   \n",
       "16       24      NaN      NaN   \n",
       "17       25      NaN      NaN   \n",
       "18       26      NaN      NaN   \n",
       "19       28      NaN      NaN   \n",
       "...     ...      ...      ...   \n",
       "7581  10833  wrecked  Lincoln   \n",
       "7582  10834  wrecked      NaN   \n",
       "7584  10837      NaN      NaN   \n",
       "7587  10841      NaN      NaN   \n",
       "7593  10848      NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "15                                       What's up man?       0  \n",
       "16                                        I love fruits       0  \n",
       "17                                     Summer is lovely       0  \n",
       "18                                    My car is so fast       0  \n",
       "19                         What a goooooooaaaaaal!!!!!!       0  \n",
       "...                                                 ...     ...  \n",
       "7581  @engineshed Great atmosphere at the British Li...       0  \n",
       "7582  Cramer: Iger's 3 words that wrecked Disney's s...       0  \n",
       "7584  These boxes are ready to explode! Exploding Ki...       0  \n",
       "7587                                 Sirens everywhere!       0  \n",
       "7593  I just heard a really loud bang and everyone i...       0  \n",
       "\n",
       "[4342 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['target'] == 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the columns, their types and missing data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop irrelevant columns\n",
    "del df['id']\n",
    "del df['keyword']\n",
    "del df['location']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot missing data as a heatmap\n",
    "sns.heatmap(df.isnull(), yticklabels = False, cmap= 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "labels": [
          "Not a disaster",
          "Disaster"
         ],
         "type": "pie",
         "values": [
          4342,
          3271
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of the target variable"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the target variable in a pie chart\n",
    "fig = go.Figure(data=[go.Pie(labels=['Not a disaster', 'Disaster'], values=df['target'].value_counts())])\n",
    "fig.update_layout(title_text='Distribution of the target variable')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing helpers functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that processes the tweets by removing stopwords, removing urls, lowercasing, tokenizing and stemming them\n",
    "def process_tweet(tweet):\n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tweet = ' '.join([word for word in tweet.split() if word not in stop_words])\n",
    "    # remove urls\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    # remove punctuation\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    # lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # tokenize\n",
    "    tweet = tweet.split()\n",
    "    # stem\n",
    "    ps = nltk.PorterStemmer()\n",
    "    tweet = [ps.stem(word) for word in tweet]\n",
    "    tweet = ' '.join(tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i student univers tehran'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the function with a random tweet\n",
    "process_tweet('I am a student at the University of Tehran')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function that creates a dictionary of words and their frequencies depending on the target variable\n",
    "def build_freqs(tweets, ys):\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating frequency dictionary for the train set\n",
    "freqs = build_freqs(df['text'], df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that extracts features from the tweets\n",
    "def extract_features(tweet, freqs):\n",
    "    word_l = process_tweet(tweet)\n",
    "    x = np.zeros((1, 3))\n",
    "    x[0,0] = 1 # bias term\n",
    "    for word in word_l:\n",
    "        x[0,1] += freqs.get((word, 1.0), 0) # count of positive words\n",
    "        x[0,2] += freqs.get((word, 0.0), 0) # count of negative words\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000e+00, 3.37093e+05, 4.01132e+05]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the function with a random tweet\n",
    "extract_features('I am a student at the University of Tehran', freqs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['target'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df, test_df = train_test_split(val_df, test_size=0.5, stratify=val_df['target'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freqs(train_df['text'], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing tweets using the frequency dictionary for the train set\n",
    "processed_X_train = [process_tweet(tweet) for tweet in train_df['text']]\n",
    "X_vectors = np.zeros((len(processed_X_train), 3))\n",
    "for i in range(len(processed_X_train)):\n",
    "    for word in processed_X_train[i]:\n",
    "        X_vectors[i, 0] = 1 # bias term\n",
    "        X_vectors[i, 1] += freqs.get((word, 1), 0)\n",
    "        X_vectors[i, 2] += freqs.get((word, 0), 0)\n",
    "\n",
    "x_train = X_vectors\n",
    "y_train = train_df['target']\n",
    "\n",
    "# vectorizing tweets using the frequency dictionary for the validation set\n",
    "processed_X_val = [process_tweet(tweet) for tweet in val_df['text']]\n",
    "X_vectors = np.zeros((len(processed_X_val), 3))\n",
    "for i in range(len(processed_X_val)):\n",
    "    for word in processed_X_val[i]:\n",
    "        X_vectors[i, 0] = 1 # bias term\n",
    "        X_vectors[i, 1] += freqs.get((word, 1), 0)\n",
    "        X_vectors[i, 2] += freqs.get((word, 0), 0)\n",
    "\n",
    "x_val = X_vectors\n",
    "y_val = val_df['target']\n",
    "\n",
    "# vectorizing tweets using the frequency dictionary for the test set\n",
    "processed_X_test = [process_tweet(tweet) for tweet in test_df['text']]\n",
    "X_vectors = np.zeros((len(processed_X_test), 3))\n",
    "for i in range(len(processed_X_test)):\n",
    "    for word in processed_X_test[i]:\n",
    "        X_vectors[i, 0] = 1 # bias term\n",
    "        X_vectors[i, 1] += freqs.get((word, 1), 0)\n",
    "        X_vectors[i, 2] += freqs.get((word, 0), 0)\n",
    "\n",
    "x_test = X_vectors\n",
    "y_test = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6090, 3), (6090,), (762, 3), (762,), (761, 3), (761,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelizing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.022283\n",
      "0:\tlearn: 0.6920307\ttotal: 56.8ms\tremaining: 56.8s\n",
      "1:\tlearn: 0.6909109\ttotal: 58.4ms\tremaining: 29.2s\n",
      "2:\tlearn: 0.6898629\ttotal: 59.9ms\tremaining: 19.9s\n",
      "3:\tlearn: 0.6888039\ttotal: 61.4ms\tremaining: 15.3s\n",
      "4:\tlearn: 0.6879212\ttotal: 62.4ms\tremaining: 12.4s\n",
      "5:\tlearn: 0.6870309\ttotal: 63.8ms\tremaining: 10.6s\n",
      "6:\tlearn: 0.6860919\ttotal: 65.3ms\tremaining: 9.26s\n",
      "7:\tlearn: 0.6852368\ttotal: 66.7ms\tremaining: 8.27s\n",
      "8:\tlearn: 0.6843786\ttotal: 68.2ms\tremaining: 7.51s\n",
      "9:\tlearn: 0.6835380\ttotal: 69.7ms\tremaining: 6.89s\n",
      "10:\tlearn: 0.6827604\ttotal: 71.1ms\tremaining: 6.39s\n",
      "11:\tlearn: 0.6819757\ttotal: 72.7ms\tremaining: 5.99s\n",
      "12:\tlearn: 0.6812957\ttotal: 74.2ms\tremaining: 5.64s\n",
      "13:\tlearn: 0.6806722\ttotal: 75.6ms\tremaining: 5.33s\n",
      "14:\tlearn: 0.6800032\ttotal: 77ms\tremaining: 5.06s\n",
      "15:\tlearn: 0.6793432\ttotal: 78.5ms\tremaining: 4.83s\n",
      "16:\tlearn: 0.6786325\ttotal: 80ms\tremaining: 4.63s\n",
      "17:\tlearn: 0.6781349\ttotal: 80.9ms\tremaining: 4.41s\n",
      "18:\tlearn: 0.6775114\ttotal: 82.3ms\tremaining: 4.25s\n",
      "19:\tlearn: 0.6770477\ttotal: 83.7ms\tremaining: 4.1s\n",
      "20:\tlearn: 0.6765416\ttotal: 85.2ms\tremaining: 3.97s\n",
      "21:\tlearn: 0.6761090\ttotal: 86.5ms\tremaining: 3.85s\n",
      "22:\tlearn: 0.6756122\ttotal: 88.1ms\tremaining: 3.74s\n",
      "23:\tlearn: 0.6751574\ttotal: 89.8ms\tremaining: 3.65s\n",
      "24:\tlearn: 0.6747409\ttotal: 91.3ms\tremaining: 3.56s\n",
      "25:\tlearn: 0.6743388\ttotal: 92.8ms\tremaining: 3.48s\n",
      "26:\tlearn: 0.6739693\ttotal: 94.2ms\tremaining: 3.39s\n",
      "27:\tlearn: 0.6735514\ttotal: 95.6ms\tremaining: 3.32s\n",
      "28:\tlearn: 0.6732158\ttotal: 97.1ms\tremaining: 3.25s\n",
      "29:\tlearn: 0.6728604\ttotal: 98.5ms\tremaining: 3.19s\n",
      "30:\tlearn: 0.6725153\ttotal: 100ms\tremaining: 3.13s\n",
      "31:\tlearn: 0.6721712\ttotal: 101ms\tremaining: 3.07s\n",
      "32:\tlearn: 0.6718906\ttotal: 103ms\tremaining: 3.02s\n",
      "33:\tlearn: 0.6715917\ttotal: 105ms\tremaining: 2.97s\n",
      "34:\tlearn: 0.6713079\ttotal: 106ms\tremaining: 2.93s\n",
      "35:\tlearn: 0.6710312\ttotal: 108ms\tremaining: 2.88s\n",
      "36:\tlearn: 0.6708017\ttotal: 109ms\tremaining: 2.84s\n",
      "37:\tlearn: 0.6704809\ttotal: 111ms\tremaining: 2.8s\n",
      "38:\tlearn: 0.6701986\ttotal: 112ms\tremaining: 2.76s\n",
      "39:\tlearn: 0.6699727\ttotal: 113ms\tremaining: 2.72s\n",
      "40:\tlearn: 0.6697118\ttotal: 115ms\tremaining: 2.69s\n",
      "41:\tlearn: 0.6695018\ttotal: 116ms\tremaining: 2.65s\n",
      "42:\tlearn: 0.6693208\ttotal: 118ms\tremaining: 2.62s\n",
      "43:\tlearn: 0.6691346\ttotal: 119ms\tremaining: 2.59s\n",
      "44:\tlearn: 0.6688568\ttotal: 121ms\tremaining: 2.56s\n",
      "45:\tlearn: 0.6686698\ttotal: 122ms\tremaining: 2.53s\n",
      "46:\tlearn: 0.6684672\ttotal: 124ms\tremaining: 2.51s\n",
      "47:\tlearn: 0.6683145\ttotal: 125ms\tremaining: 2.48s\n",
      "48:\tlearn: 0.6680287\ttotal: 126ms\tremaining: 2.45s\n",
      "49:\tlearn: 0.6678710\ttotal: 128ms\tremaining: 2.43s\n",
      "50:\tlearn: 0.6676952\ttotal: 130ms\tremaining: 2.41s\n",
      "51:\tlearn: 0.6675388\ttotal: 131ms\tremaining: 2.39s\n",
      "52:\tlearn: 0.6673125\ttotal: 133ms\tremaining: 2.37s\n",
      "53:\tlearn: 0.6671401\ttotal: 134ms\tremaining: 2.35s\n",
      "54:\tlearn: 0.6670151\ttotal: 135ms\tremaining: 2.33s\n",
      "55:\tlearn: 0.6668867\ttotal: 137ms\tremaining: 2.31s\n",
      "56:\tlearn: 0.6666821\ttotal: 139ms\tremaining: 2.29s\n",
      "57:\tlearn: 0.6665233\ttotal: 140ms\tremaining: 2.27s\n",
      "58:\tlearn: 0.6662394\ttotal: 142ms\tremaining: 2.26s\n",
      "59:\tlearn: 0.6661121\ttotal: 143ms\tremaining: 2.24s\n",
      "60:\tlearn: 0.6660128\ttotal: 144ms\tremaining: 2.22s\n",
      "61:\tlearn: 0.6658653\ttotal: 146ms\tremaining: 2.21s\n",
      "62:\tlearn: 0.6657312\ttotal: 147ms\tremaining: 2.19s\n",
      "63:\tlearn: 0.6655793\ttotal: 149ms\tremaining: 2.18s\n",
      "64:\tlearn: 0.6654715\ttotal: 150ms\tremaining: 2.16s\n",
      "65:\tlearn: 0.6653038\ttotal: 152ms\tremaining: 2.15s\n",
      "66:\tlearn: 0.6651264\ttotal: 154ms\tremaining: 2.14s\n",
      "67:\tlearn: 0.6650429\ttotal: 155ms\tremaining: 2.13s\n",
      "68:\tlearn: 0.6648884\ttotal: 157ms\tremaining: 2.11s\n",
      "69:\tlearn: 0.6647262\ttotal: 158ms\tremaining: 2.1s\n",
      "70:\tlearn: 0.6646482\ttotal: 160ms\tremaining: 2.09s\n",
      "71:\tlearn: 0.6644979\ttotal: 161ms\tremaining: 2.08s\n",
      "72:\tlearn: 0.6643248\ttotal: 163ms\tremaining: 2.06s\n",
      "73:\tlearn: 0.6642174\ttotal: 164ms\tremaining: 2.05s\n",
      "74:\tlearn: 0.6641312\ttotal: 166ms\tremaining: 2.04s\n",
      "75:\tlearn: 0.6640210\ttotal: 168ms\tremaining: 2.04s\n",
      "76:\tlearn: 0.6639098\ttotal: 169ms\tremaining: 2.03s\n",
      "77:\tlearn: 0.6637661\ttotal: 171ms\tremaining: 2.02s\n",
      "78:\tlearn: 0.6636626\ttotal: 173ms\tremaining: 2.01s\n",
      "79:\tlearn: 0.6634855\ttotal: 174ms\tremaining: 2s\n",
      "80:\tlearn: 0.6634271\ttotal: 176ms\tremaining: 2s\n",
      "81:\tlearn: 0.6633307\ttotal: 178ms\tremaining: 1.99s\n",
      "82:\tlearn: 0.6632816\ttotal: 180ms\tremaining: 1.99s\n",
      "83:\tlearn: 0.6631966\ttotal: 183ms\tremaining: 1.99s\n",
      "84:\tlearn: 0.6629611\ttotal: 185ms\tremaining: 2s\n",
      "85:\tlearn: 0.6628309\ttotal: 188ms\tremaining: 2s\n",
      "86:\tlearn: 0.6627540\ttotal: 190ms\tremaining: 1.99s\n",
      "87:\tlearn: 0.6626502\ttotal: 192ms\tremaining: 1.99s\n",
      "88:\tlearn: 0.6625758\ttotal: 196ms\tremaining: 2s\n",
      "89:\tlearn: 0.6623906\ttotal: 198ms\tremaining: 2s\n",
      "90:\tlearn: 0.6622511\ttotal: 200ms\tremaining: 2s\n",
      "91:\tlearn: 0.6620853\ttotal: 202ms\tremaining: 2s\n",
      "92:\tlearn: 0.6619853\ttotal: 204ms\tremaining: 1.99s\n",
      "93:\tlearn: 0.6619324\ttotal: 205ms\tremaining: 1.98s\n",
      "94:\tlearn: 0.6618407\ttotal: 207ms\tremaining: 1.97s\n",
      "95:\tlearn: 0.6617819\ttotal: 209ms\tremaining: 1.97s\n",
      "96:\tlearn: 0.6617222\ttotal: 211ms\tremaining: 1.96s\n",
      "97:\tlearn: 0.6616579\ttotal: 212ms\tremaining: 1.95s\n",
      "98:\tlearn: 0.6615735\ttotal: 214ms\tremaining: 1.95s\n",
      "99:\tlearn: 0.6615063\ttotal: 216ms\tremaining: 1.94s\n",
      "100:\tlearn: 0.6613855\ttotal: 217ms\tremaining: 1.94s\n",
      "101:\tlearn: 0.6612835\ttotal: 219ms\tremaining: 1.93s\n",
      "102:\tlearn: 0.6612164\ttotal: 220ms\tremaining: 1.92s\n",
      "103:\tlearn: 0.6610393\ttotal: 222ms\tremaining: 1.91s\n",
      "104:\tlearn: 0.6609762\ttotal: 224ms\tremaining: 1.91s\n",
      "105:\tlearn: 0.6609480\ttotal: 225ms\tremaining: 1.9s\n",
      "106:\tlearn: 0.6609008\ttotal: 227ms\tremaining: 1.89s\n",
      "107:\tlearn: 0.6608246\ttotal: 229ms\tremaining: 1.89s\n",
      "108:\tlearn: 0.6606777\ttotal: 230ms\tremaining: 1.88s\n",
      "109:\tlearn: 0.6606030\ttotal: 232ms\tremaining: 1.88s\n",
      "110:\tlearn: 0.6604348\ttotal: 234ms\tremaining: 1.87s\n",
      "111:\tlearn: 0.6603608\ttotal: 235ms\tremaining: 1.86s\n",
      "112:\tlearn: 0.6602966\ttotal: 237ms\tremaining: 1.86s\n",
      "113:\tlearn: 0.6602432\ttotal: 238ms\tremaining: 1.85s\n",
      "114:\tlearn: 0.6601495\ttotal: 240ms\tremaining: 1.85s\n",
      "115:\tlearn: 0.6600709\ttotal: 242ms\tremaining: 1.84s\n",
      "116:\tlearn: 0.6600003\ttotal: 243ms\tremaining: 1.83s\n",
      "117:\tlearn: 0.6598993\ttotal: 245ms\tremaining: 1.83s\n",
      "118:\tlearn: 0.6597388\ttotal: 247ms\tremaining: 1.82s\n",
      "119:\tlearn: 0.6595723\ttotal: 249ms\tremaining: 1.82s\n",
      "120:\tlearn: 0.6595404\ttotal: 250ms\tremaining: 1.82s\n",
      "121:\tlearn: 0.6594251\ttotal: 252ms\tremaining: 1.81s\n",
      "122:\tlearn: 0.6593843\ttotal: 254ms\tremaining: 1.81s\n",
      "123:\tlearn: 0.6593100\ttotal: 256ms\tremaining: 1.8s\n",
      "124:\tlearn: 0.6592595\ttotal: 257ms\tremaining: 1.8s\n",
      "125:\tlearn: 0.6592005\ttotal: 259ms\tremaining: 1.79s\n",
      "126:\tlearn: 0.6591615\ttotal: 260ms\tremaining: 1.79s\n",
      "127:\tlearn: 0.6590352\ttotal: 261ms\tremaining: 1.78s\n",
      "128:\tlearn: 0.6589087\ttotal: 263ms\tremaining: 1.78s\n",
      "129:\tlearn: 0.6588515\ttotal: 265ms\tremaining: 1.77s\n",
      "130:\tlearn: 0.6587628\ttotal: 266ms\tremaining: 1.77s\n",
      "131:\tlearn: 0.6586263\ttotal: 268ms\tremaining: 1.76s\n",
      "132:\tlearn: 0.6585954\ttotal: 269ms\tremaining: 1.75s\n",
      "133:\tlearn: 0.6584058\ttotal: 271ms\tremaining: 1.75s\n",
      "134:\tlearn: 0.6583257\ttotal: 272ms\tremaining: 1.74s\n",
      "135:\tlearn: 0.6582394\ttotal: 273ms\tremaining: 1.74s\n",
      "136:\tlearn: 0.6581677\ttotal: 275ms\tremaining: 1.73s\n",
      "137:\tlearn: 0.6581200\ttotal: 276ms\tremaining: 1.72s\n",
      "138:\tlearn: 0.6579454\ttotal: 277ms\tremaining: 1.72s\n",
      "139:\tlearn: 0.6578014\ttotal: 279ms\tremaining: 1.71s\n",
      "140:\tlearn: 0.6576554\ttotal: 281ms\tremaining: 1.71s\n",
      "141:\tlearn: 0.6576235\ttotal: 282ms\tremaining: 1.7s\n",
      "142:\tlearn: 0.6575824\ttotal: 284ms\tremaining: 1.7s\n",
      "143:\tlearn: 0.6575298\ttotal: 285ms\tremaining: 1.69s\n",
      "144:\tlearn: 0.6574149\ttotal: 286ms\tremaining: 1.69s\n",
      "145:\tlearn: 0.6572952\ttotal: 288ms\tremaining: 1.68s\n",
      "146:\tlearn: 0.6572193\ttotal: 289ms\tremaining: 1.68s\n",
      "147:\tlearn: 0.6571480\ttotal: 291ms\tremaining: 1.67s\n",
      "148:\tlearn: 0.6570811\ttotal: 292ms\tremaining: 1.67s\n",
      "149:\tlearn: 0.6570280\ttotal: 293ms\tremaining: 1.66s\n",
      "150:\tlearn: 0.6569091\ttotal: 295ms\tremaining: 1.66s\n",
      "151:\tlearn: 0.6568610\ttotal: 296ms\tremaining: 1.65s\n",
      "152:\tlearn: 0.6567685\ttotal: 298ms\tremaining: 1.65s\n",
      "153:\tlearn: 0.6566676\ttotal: 299ms\tremaining: 1.64s\n",
      "154:\tlearn: 0.6565375\ttotal: 301ms\tremaining: 1.64s\n",
      "155:\tlearn: 0.6564192\ttotal: 302ms\tremaining: 1.63s\n",
      "156:\tlearn: 0.6563617\ttotal: 303ms\tremaining: 1.63s\n",
      "157:\tlearn: 0.6561982\ttotal: 305ms\tremaining: 1.62s\n",
      "158:\tlearn: 0.6560788\ttotal: 306ms\tremaining: 1.62s\n",
      "159:\tlearn: 0.6559882\ttotal: 308ms\tremaining: 1.61s\n",
      "160:\tlearn: 0.6558655\ttotal: 309ms\tremaining: 1.61s\n",
      "161:\tlearn: 0.6557639\ttotal: 310ms\tremaining: 1.6s\n",
      "162:\tlearn: 0.6557392\ttotal: 312ms\tremaining: 1.6s\n",
      "163:\tlearn: 0.6556550\ttotal: 314ms\tremaining: 1.6s\n",
      "164:\tlearn: 0.6556089\ttotal: 315ms\tremaining: 1.59s\n",
      "165:\tlearn: 0.6554987\ttotal: 317ms\tremaining: 1.59s\n",
      "166:\tlearn: 0.6554528\ttotal: 318ms\tremaining: 1.59s\n",
      "167:\tlearn: 0.6553634\ttotal: 319ms\tremaining: 1.58s\n",
      "168:\tlearn: 0.6553115\ttotal: 321ms\tremaining: 1.58s\n",
      "169:\tlearn: 0.6552408\ttotal: 322ms\tremaining: 1.57s\n",
      "170:\tlearn: 0.6551764\ttotal: 324ms\tremaining: 1.57s\n",
      "171:\tlearn: 0.6550735\ttotal: 325ms\tremaining: 1.56s\n",
      "172:\tlearn: 0.6549785\ttotal: 327ms\tremaining: 1.56s\n",
      "173:\tlearn: 0.6549406\ttotal: 328ms\tremaining: 1.56s\n",
      "174:\tlearn: 0.6548412\ttotal: 330ms\tremaining: 1.55s\n",
      "175:\tlearn: 0.6547919\ttotal: 331ms\tremaining: 1.55s\n",
      "176:\tlearn: 0.6547055\ttotal: 333ms\tremaining: 1.55s\n",
      "177:\tlearn: 0.6546621\ttotal: 334ms\tremaining: 1.54s\n",
      "178:\tlearn: 0.6546134\ttotal: 335ms\tremaining: 1.54s\n",
      "179:\tlearn: 0.6545036\ttotal: 337ms\tremaining: 1.53s\n",
      "180:\tlearn: 0.6544798\ttotal: 338ms\tremaining: 1.53s\n",
      "181:\tlearn: 0.6544148\ttotal: 339ms\tremaining: 1.52s\n",
      "182:\tlearn: 0.6543024\ttotal: 341ms\tremaining: 1.52s\n",
      "183:\tlearn: 0.6542647\ttotal: 342ms\tremaining: 1.52s\n",
      "184:\tlearn: 0.6542187\ttotal: 344ms\tremaining: 1.51s\n",
      "185:\tlearn: 0.6541342\ttotal: 345ms\tremaining: 1.51s\n",
      "186:\tlearn: 0.6540555\ttotal: 347ms\tremaining: 1.51s\n",
      "187:\tlearn: 0.6539746\ttotal: 348ms\tremaining: 1.5s\n",
      "188:\tlearn: 0.6539080\ttotal: 350ms\tremaining: 1.5s\n",
      "189:\tlearn: 0.6538562\ttotal: 351ms\tremaining: 1.5s\n",
      "190:\tlearn: 0.6537725\ttotal: 353ms\tremaining: 1.49s\n",
      "191:\tlearn: 0.6537335\ttotal: 354ms\tremaining: 1.49s\n",
      "192:\tlearn: 0.6536254\ttotal: 356ms\tremaining: 1.49s\n",
      "193:\tlearn: 0.6535855\ttotal: 357ms\tremaining: 1.48s\n",
      "194:\tlearn: 0.6535362\ttotal: 359ms\tremaining: 1.48s\n",
      "195:\tlearn: 0.6534885\ttotal: 361ms\tremaining: 1.48s\n",
      "196:\tlearn: 0.6534155\ttotal: 362ms\tremaining: 1.48s\n",
      "197:\tlearn: 0.6532279\ttotal: 364ms\tremaining: 1.47s\n",
      "198:\tlearn: 0.6532195\ttotal: 365ms\tremaining: 1.47s\n",
      "199:\tlearn: 0.6531658\ttotal: 367ms\tremaining: 1.47s\n",
      "200:\tlearn: 0.6530877\ttotal: 368ms\tremaining: 1.46s\n",
      "201:\tlearn: 0.6529379\ttotal: 370ms\tremaining: 1.46s\n",
      "202:\tlearn: 0.6528748\ttotal: 371ms\tremaining: 1.46s\n",
      "203:\tlearn: 0.6527753\ttotal: 372ms\tremaining: 1.45s\n",
      "204:\tlearn: 0.6527421\ttotal: 374ms\tremaining: 1.45s\n",
      "205:\tlearn: 0.6527241\ttotal: 376ms\tremaining: 1.45s\n",
      "206:\tlearn: 0.6526729\ttotal: 377ms\tremaining: 1.44s\n",
      "207:\tlearn: 0.6526301\ttotal: 379ms\tremaining: 1.44s\n",
      "208:\tlearn: 0.6524955\ttotal: 380ms\tremaining: 1.44s\n",
      "209:\tlearn: 0.6524024\ttotal: 382ms\tremaining: 1.44s\n",
      "210:\tlearn: 0.6523558\ttotal: 383ms\tremaining: 1.43s\n",
      "211:\tlearn: 0.6522785\ttotal: 385ms\tremaining: 1.43s\n",
      "212:\tlearn: 0.6522669\ttotal: 387ms\tremaining: 1.43s\n",
      "213:\tlearn: 0.6522167\ttotal: 388ms\tremaining: 1.43s\n",
      "214:\tlearn: 0.6520920\ttotal: 390ms\tremaining: 1.42s\n",
      "215:\tlearn: 0.6520044\ttotal: 391ms\tremaining: 1.42s\n",
      "216:\tlearn: 0.6518736\ttotal: 393ms\tremaining: 1.42s\n",
      "217:\tlearn: 0.6518413\ttotal: 394ms\tremaining: 1.41s\n",
      "218:\tlearn: 0.6518058\ttotal: 395ms\tremaining: 1.41s\n",
      "219:\tlearn: 0.6516738\ttotal: 397ms\tremaining: 1.41s\n",
      "220:\tlearn: 0.6516347\ttotal: 398ms\tremaining: 1.4s\n",
      "221:\tlearn: 0.6515439\ttotal: 400ms\tremaining: 1.4s\n",
      "222:\tlearn: 0.6514523\ttotal: 401ms\tremaining: 1.4s\n",
      "223:\tlearn: 0.6513885\ttotal: 403ms\tremaining: 1.39s\n",
      "224:\tlearn: 0.6513688\ttotal: 404ms\tremaining: 1.39s\n",
      "225:\tlearn: 0.6513293\ttotal: 405ms\tremaining: 1.39s\n",
      "226:\tlearn: 0.6512129\ttotal: 407ms\tremaining: 1.39s\n",
      "227:\tlearn: 0.6510862\ttotal: 409ms\tremaining: 1.38s\n",
      "228:\tlearn: 0.6510171\ttotal: 410ms\tremaining: 1.38s\n",
      "229:\tlearn: 0.6509804\ttotal: 411ms\tremaining: 1.38s\n",
      "230:\tlearn: 0.6508885\ttotal: 413ms\tremaining: 1.37s\n",
      "231:\tlearn: 0.6508093\ttotal: 414ms\tremaining: 1.37s\n",
      "232:\tlearn: 0.6507410\ttotal: 416ms\tremaining: 1.37s\n",
      "233:\tlearn: 0.6506395\ttotal: 417ms\tremaining: 1.36s\n",
      "234:\tlearn: 0.6505432\ttotal: 418ms\tremaining: 1.36s\n",
      "235:\tlearn: 0.6503952\ttotal: 420ms\tremaining: 1.36s\n",
      "236:\tlearn: 0.6503650\ttotal: 422ms\tremaining: 1.36s\n",
      "237:\tlearn: 0.6502877\ttotal: 423ms\tremaining: 1.35s\n",
      "238:\tlearn: 0.6502087\ttotal: 424ms\tremaining: 1.35s\n",
      "239:\tlearn: 0.6501745\ttotal: 426ms\tremaining: 1.35s\n",
      "240:\tlearn: 0.6501137\ttotal: 427ms\tremaining: 1.34s\n",
      "241:\tlearn: 0.6500787\ttotal: 428ms\tremaining: 1.34s\n",
      "242:\tlearn: 0.6499774\ttotal: 430ms\tremaining: 1.34s\n",
      "243:\tlearn: 0.6499461\ttotal: 431ms\tremaining: 1.33s\n",
      "244:\tlearn: 0.6498440\ttotal: 432ms\tremaining: 1.33s\n",
      "245:\tlearn: 0.6497413\ttotal: 434ms\tremaining: 1.33s\n",
      "246:\tlearn: 0.6496914\ttotal: 435ms\tremaining: 1.33s\n",
      "247:\tlearn: 0.6496259\ttotal: 437ms\tremaining: 1.32s\n",
      "248:\tlearn: 0.6495524\ttotal: 438ms\tremaining: 1.32s\n",
      "249:\tlearn: 0.6495270\ttotal: 440ms\tremaining: 1.32s\n",
      "250:\tlearn: 0.6494207\ttotal: 441ms\tremaining: 1.31s\n",
      "251:\tlearn: 0.6493723\ttotal: 442ms\tremaining: 1.31s\n",
      "252:\tlearn: 0.6492248\ttotal: 444ms\tremaining: 1.31s\n",
      "253:\tlearn: 0.6491907\ttotal: 445ms\tremaining: 1.31s\n",
      "254:\tlearn: 0.6491217\ttotal: 446ms\tremaining: 1.3s\n",
      "255:\tlearn: 0.6490153\ttotal: 448ms\tremaining: 1.3s\n",
      "256:\tlearn: 0.6488946\ttotal: 449ms\tremaining: 1.3s\n",
      "257:\tlearn: 0.6488042\ttotal: 451ms\tremaining: 1.29s\n",
      "258:\tlearn: 0.6487701\ttotal: 452ms\tremaining: 1.29s\n",
      "259:\tlearn: 0.6486660\ttotal: 454ms\tremaining: 1.29s\n",
      "260:\tlearn: 0.6486429\ttotal: 455ms\tremaining: 1.29s\n",
      "261:\tlearn: 0.6485623\ttotal: 456ms\tremaining: 1.28s\n",
      "262:\tlearn: 0.6485246\ttotal: 458ms\tremaining: 1.28s\n",
      "263:\tlearn: 0.6484410\ttotal: 459ms\tremaining: 1.28s\n",
      "264:\tlearn: 0.6483167\ttotal: 460ms\tremaining: 1.28s\n",
      "265:\tlearn: 0.6482925\ttotal: 462ms\tremaining: 1.27s\n",
      "266:\tlearn: 0.6482555\ttotal: 463ms\tremaining: 1.27s\n",
      "267:\tlearn: 0.6481533\ttotal: 465ms\tremaining: 1.27s\n",
      "268:\tlearn: 0.6481325\ttotal: 467ms\tremaining: 1.27s\n",
      "269:\tlearn: 0.6480738\ttotal: 468ms\tremaining: 1.26s\n",
      "270:\tlearn: 0.6479463\ttotal: 470ms\tremaining: 1.26s\n",
      "271:\tlearn: 0.6479062\ttotal: 472ms\tremaining: 1.26s\n",
      "272:\tlearn: 0.6478223\ttotal: 473ms\tremaining: 1.26s\n",
      "273:\tlearn: 0.6477609\ttotal: 474ms\tremaining: 1.26s\n",
      "274:\tlearn: 0.6477170\ttotal: 476ms\tremaining: 1.25s\n",
      "275:\tlearn: 0.6476939\ttotal: 477ms\tremaining: 1.25s\n",
      "276:\tlearn: 0.6476834\ttotal: 479ms\tremaining: 1.25s\n",
      "277:\tlearn: 0.6476262\ttotal: 480ms\tremaining: 1.25s\n",
      "278:\tlearn: 0.6475216\ttotal: 482ms\tremaining: 1.24s\n",
      "279:\tlearn: 0.6474362\ttotal: 483ms\tremaining: 1.24s\n",
      "280:\tlearn: 0.6474023\ttotal: 485ms\tremaining: 1.24s\n",
      "281:\tlearn: 0.6473279\ttotal: 486ms\tremaining: 1.24s\n",
      "282:\tlearn: 0.6472620\ttotal: 488ms\tremaining: 1.24s\n",
      "283:\tlearn: 0.6472437\ttotal: 489ms\tremaining: 1.23s\n",
      "284:\tlearn: 0.6471589\ttotal: 490ms\tremaining: 1.23s\n",
      "285:\tlearn: 0.6471188\ttotal: 492ms\tremaining: 1.23s\n",
      "286:\tlearn: 0.6470429\ttotal: 493ms\tremaining: 1.22s\n",
      "287:\tlearn: 0.6469907\ttotal: 494ms\tremaining: 1.22s\n",
      "288:\tlearn: 0.6469465\ttotal: 496ms\tremaining: 1.22s\n",
      "289:\tlearn: 0.6468660\ttotal: 497ms\tremaining: 1.22s\n",
      "290:\tlearn: 0.6467911\ttotal: 499ms\tremaining: 1.22s\n",
      "291:\tlearn: 0.6467603\ttotal: 500ms\tremaining: 1.21s\n",
      "292:\tlearn: 0.6467322\ttotal: 502ms\tremaining: 1.21s\n",
      "293:\tlearn: 0.6467026\ttotal: 504ms\tremaining: 1.21s\n",
      "294:\tlearn: 0.6465928\ttotal: 505ms\tremaining: 1.21s\n",
      "295:\tlearn: 0.6465426\ttotal: 506ms\tremaining: 1.2s\n",
      "296:\tlearn: 0.6464917\ttotal: 508ms\tremaining: 1.2s\n",
      "297:\tlearn: 0.6464209\ttotal: 509ms\tremaining: 1.2s\n",
      "298:\tlearn: 0.6463399\ttotal: 510ms\tremaining: 1.2s\n",
      "299:\tlearn: 0.6462915\ttotal: 511ms\tremaining: 1.19s\n",
      "300:\tlearn: 0.6462589\ttotal: 513ms\tremaining: 1.19s\n",
      "301:\tlearn: 0.6462047\ttotal: 514ms\tremaining: 1.19s\n",
      "302:\tlearn: 0.6461669\ttotal: 515ms\tremaining: 1.19s\n",
      "303:\tlearn: 0.6460877\ttotal: 517ms\tremaining: 1.18s\n",
      "304:\tlearn: 0.6459946\ttotal: 519ms\tremaining: 1.18s\n",
      "305:\tlearn: 0.6459499\ttotal: 520ms\tremaining: 1.18s\n",
      "306:\tlearn: 0.6458303\ttotal: 521ms\tremaining: 1.18s\n",
      "307:\tlearn: 0.6458112\ttotal: 523ms\tremaining: 1.17s\n",
      "308:\tlearn: 0.6457541\ttotal: 524ms\tremaining: 1.17s\n",
      "309:\tlearn: 0.6457239\ttotal: 525ms\tremaining: 1.17s\n",
      "310:\tlearn: 0.6456456\ttotal: 527ms\tremaining: 1.17s\n",
      "311:\tlearn: 0.6456116\ttotal: 528ms\tremaining: 1.16s\n",
      "312:\tlearn: 0.6455857\ttotal: 529ms\tremaining: 1.16s\n",
      "313:\tlearn: 0.6455499\ttotal: 531ms\tremaining: 1.16s\n",
      "314:\tlearn: 0.6454981\ttotal: 532ms\tremaining: 1.16s\n",
      "315:\tlearn: 0.6453701\ttotal: 534ms\tremaining: 1.16s\n",
      "316:\tlearn: 0.6453188\ttotal: 536ms\tremaining: 1.15s\n",
      "317:\tlearn: 0.6452595\ttotal: 537ms\tremaining: 1.15s\n",
      "318:\tlearn: 0.6451818\ttotal: 538ms\tremaining: 1.15s\n",
      "319:\tlearn: 0.6451744\ttotal: 540ms\tremaining: 1.15s\n",
      "320:\tlearn: 0.6451372\ttotal: 541ms\tremaining: 1.14s\n",
      "321:\tlearn: 0.6450764\ttotal: 543ms\tremaining: 1.14s\n",
      "322:\tlearn: 0.6450496\ttotal: 544ms\tremaining: 1.14s\n",
      "323:\tlearn: 0.6449584\ttotal: 546ms\tremaining: 1.14s\n",
      "324:\tlearn: 0.6448382\ttotal: 547ms\tremaining: 1.14s\n",
      "325:\tlearn: 0.6447879\ttotal: 549ms\tremaining: 1.14s\n",
      "326:\tlearn: 0.6446800\ttotal: 550ms\tremaining: 1.13s\n",
      "327:\tlearn: 0.6444976\ttotal: 552ms\tremaining: 1.13s\n",
      "328:\tlearn: 0.6444451\ttotal: 553ms\tremaining: 1.13s\n",
      "329:\tlearn: 0.6443957\ttotal: 554ms\tremaining: 1.13s\n",
      "330:\tlearn: 0.6443409\ttotal: 556ms\tremaining: 1.12s\n",
      "331:\tlearn: 0.6442604\ttotal: 557ms\tremaining: 1.12s\n",
      "332:\tlearn: 0.6442312\ttotal: 559ms\tremaining: 1.12s\n",
      "333:\tlearn: 0.6441788\ttotal: 560ms\tremaining: 1.12s\n",
      "334:\tlearn: 0.6441220\ttotal: 561ms\tremaining: 1.11s\n",
      "335:\tlearn: 0.6440285\ttotal: 563ms\tremaining: 1.11s\n",
      "336:\tlearn: 0.6439355\ttotal: 564ms\tremaining: 1.11s\n",
      "337:\tlearn: 0.6439160\ttotal: 566ms\tremaining: 1.11s\n",
      "338:\tlearn: 0.6438805\ttotal: 568ms\tremaining: 1.11s\n",
      "339:\tlearn: 0.6438383\ttotal: 569ms\tremaining: 1.1s\n",
      "340:\tlearn: 0.6438161\ttotal: 570ms\tremaining: 1.1s\n",
      "341:\tlearn: 0.6437628\ttotal: 572ms\tremaining: 1.1s\n",
      "342:\tlearn: 0.6437040\ttotal: 573ms\tremaining: 1.1s\n",
      "343:\tlearn: 0.6436770\ttotal: 575ms\tremaining: 1.1s\n",
      "344:\tlearn: 0.6436453\ttotal: 577ms\tremaining: 1.09s\n",
      "345:\tlearn: 0.6435975\ttotal: 578ms\tremaining: 1.09s\n",
      "346:\tlearn: 0.6435233\ttotal: 581ms\tremaining: 1.09s\n",
      "347:\tlearn: 0.6433914\ttotal: 582ms\tremaining: 1.09s\n",
      "348:\tlearn: 0.6433560\ttotal: 584ms\tremaining: 1.09s\n",
      "349:\tlearn: 0.6432931\ttotal: 586ms\tremaining: 1.09s\n",
      "350:\tlearn: 0.6432171\ttotal: 587ms\tremaining: 1.08s\n",
      "351:\tlearn: 0.6431707\ttotal: 588ms\tremaining: 1.08s\n",
      "352:\tlearn: 0.6431423\ttotal: 589ms\tremaining: 1.08s\n",
      "353:\tlearn: 0.6431082\ttotal: 591ms\tremaining: 1.08s\n",
      "354:\tlearn: 0.6430175\ttotal: 592ms\tremaining: 1.08s\n",
      "355:\tlearn: 0.6429650\ttotal: 594ms\tremaining: 1.07s\n",
      "356:\tlearn: 0.6428724\ttotal: 595ms\tremaining: 1.07s\n",
      "357:\tlearn: 0.6427270\ttotal: 597ms\tremaining: 1.07s\n",
      "358:\tlearn: 0.6426817\ttotal: 599ms\tremaining: 1.07s\n",
      "359:\tlearn: 0.6425997\ttotal: 600ms\tremaining: 1.07s\n",
      "360:\tlearn: 0.6425591\ttotal: 602ms\tremaining: 1.06s\n",
      "361:\tlearn: 0.6425237\ttotal: 603ms\tremaining: 1.06s\n",
      "362:\tlearn: 0.6424689\ttotal: 605ms\tremaining: 1.06s\n",
      "363:\tlearn: 0.6424045\ttotal: 606ms\tremaining: 1.06s\n",
      "364:\tlearn: 0.6422992\ttotal: 607ms\tremaining: 1.06s\n",
      "365:\tlearn: 0.6422541\ttotal: 609ms\tremaining: 1.05s\n",
      "366:\tlearn: 0.6421442\ttotal: 610ms\tremaining: 1.05s\n",
      "367:\tlearn: 0.6420759\ttotal: 612ms\tremaining: 1.05s\n",
      "368:\tlearn: 0.6420039\ttotal: 613ms\tremaining: 1.05s\n",
      "369:\tlearn: 0.6419041\ttotal: 615ms\tremaining: 1.05s\n",
      "370:\tlearn: 0.6418603\ttotal: 616ms\tremaining: 1.04s\n",
      "371:\tlearn: 0.6418237\ttotal: 618ms\tremaining: 1.04s\n",
      "372:\tlearn: 0.6417812\ttotal: 619ms\tremaining: 1.04s\n",
      "373:\tlearn: 0.6417184\ttotal: 621ms\tremaining: 1.04s\n",
      "374:\tlearn: 0.6416773\ttotal: 622ms\tremaining: 1.04s\n",
      "375:\tlearn: 0.6416020\ttotal: 623ms\tremaining: 1.03s\n",
      "376:\tlearn: 0.6414701\ttotal: 625ms\tremaining: 1.03s\n",
      "377:\tlearn: 0.6414016\ttotal: 626ms\tremaining: 1.03s\n",
      "378:\tlearn: 0.6412881\ttotal: 628ms\tremaining: 1.03s\n",
      "379:\tlearn: 0.6412345\ttotal: 629ms\tremaining: 1.03s\n",
      "380:\tlearn: 0.6411935\ttotal: 631ms\tremaining: 1.02s\n",
      "381:\tlearn: 0.6411321\ttotal: 632ms\tremaining: 1.02s\n",
      "382:\tlearn: 0.6410689\ttotal: 633ms\tremaining: 1.02s\n",
      "383:\tlearn: 0.6410171\ttotal: 635ms\tremaining: 1.02s\n",
      "384:\tlearn: 0.6408987\ttotal: 636ms\tremaining: 1.02s\n",
      "385:\tlearn: 0.6408278\ttotal: 638ms\tremaining: 1.01s\n",
      "386:\tlearn: 0.6407836\ttotal: 639ms\tremaining: 1.01s\n",
      "387:\tlearn: 0.6407350\ttotal: 641ms\tremaining: 1.01s\n",
      "388:\tlearn: 0.6406915\ttotal: 642ms\tremaining: 1.01s\n",
      "389:\tlearn: 0.6406073\ttotal: 644ms\tremaining: 1.01s\n",
      "390:\tlearn: 0.6405398\ttotal: 645ms\tremaining: 1s\n",
      "391:\tlearn: 0.6404922\ttotal: 647ms\tremaining: 1s\n",
      "392:\tlearn: 0.6404175\ttotal: 648ms\tremaining: 1s\n",
      "393:\tlearn: 0.6403444\ttotal: 650ms\tremaining: 1000ms\n",
      "394:\tlearn: 0.6402695\ttotal: 651ms\tremaining: 997ms\n",
      "395:\tlearn: 0.6402202\ttotal: 653ms\tremaining: 996ms\n",
      "396:\tlearn: 0.6401313\ttotal: 655ms\tremaining: 994ms\n",
      "397:\tlearn: 0.6400419\ttotal: 656ms\tremaining: 992ms\n",
      "398:\tlearn: 0.6399583\ttotal: 658ms\tremaining: 991ms\n",
      "399:\tlearn: 0.6399304\ttotal: 660ms\tremaining: 989ms\n",
      "400:\tlearn: 0.6398954\ttotal: 661ms\tremaining: 987ms\n",
      "401:\tlearn: 0.6398605\ttotal: 662ms\tremaining: 985ms\n",
      "402:\tlearn: 0.6397730\ttotal: 663ms\tremaining: 983ms\n",
      "403:\tlearn: 0.6397372\ttotal: 665ms\tremaining: 981ms\n",
      "404:\tlearn: 0.6396264\ttotal: 666ms\tremaining: 979ms\n",
      "405:\tlearn: 0.6395717\ttotal: 667ms\tremaining: 977ms\n",
      "406:\tlearn: 0.6394952\ttotal: 669ms\tremaining: 974ms\n",
      "407:\tlearn: 0.6394561\ttotal: 670ms\tremaining: 972ms\n",
      "408:\tlearn: 0.6393740\ttotal: 671ms\tremaining: 970ms\n",
      "409:\tlearn: 0.6392606\ttotal: 673ms\tremaining: 968ms\n",
      "410:\tlearn: 0.6391979\ttotal: 675ms\tremaining: 967ms\n",
      "411:\tlearn: 0.6390576\ttotal: 676ms\tremaining: 965ms\n",
      "412:\tlearn: 0.6389674\ttotal: 678ms\tremaining: 963ms\n",
      "413:\tlearn: 0.6388805\ttotal: 679ms\tremaining: 961ms\n",
      "414:\tlearn: 0.6388083\ttotal: 681ms\tremaining: 959ms\n",
      "415:\tlearn: 0.6387643\ttotal: 682ms\tremaining: 957ms\n",
      "416:\tlearn: 0.6387052\ttotal: 684ms\tremaining: 956ms\n",
      "417:\tlearn: 0.6385828\ttotal: 686ms\tremaining: 954ms\n",
      "418:\tlearn: 0.6384918\ttotal: 688ms\tremaining: 953ms\n",
      "419:\tlearn: 0.6384186\ttotal: 689ms\tremaining: 952ms\n",
      "420:\tlearn: 0.6383852\ttotal: 691ms\tremaining: 950ms\n",
      "421:\tlearn: 0.6382928\ttotal: 693ms\tremaining: 949ms\n",
      "422:\tlearn: 0.6382098\ttotal: 694ms\tremaining: 947ms\n",
      "423:\tlearn: 0.6381432\ttotal: 695ms\tremaining: 945ms\n",
      "424:\tlearn: 0.6380602\ttotal: 697ms\tremaining: 943ms\n",
      "425:\tlearn: 0.6380001\ttotal: 698ms\tremaining: 941ms\n",
      "426:\tlearn: 0.6379202\ttotal: 699ms\tremaining: 939ms\n",
      "427:\tlearn: 0.6378296\ttotal: 701ms\tremaining: 937ms\n",
      "428:\tlearn: 0.6377111\ttotal: 702ms\tremaining: 934ms\n",
      "429:\tlearn: 0.6376025\ttotal: 703ms\tremaining: 932ms\n",
      "430:\tlearn: 0.6374336\ttotal: 705ms\tremaining: 931ms\n",
      "431:\tlearn: 0.6373347\ttotal: 707ms\tremaining: 929ms\n",
      "432:\tlearn: 0.6371940\ttotal: 709ms\tremaining: 928ms\n",
      "433:\tlearn: 0.6371081\ttotal: 710ms\tremaining: 926ms\n",
      "434:\tlearn: 0.6370315\ttotal: 711ms\tremaining: 924ms\n",
      "435:\tlearn: 0.6369076\ttotal: 713ms\tremaining: 922ms\n",
      "436:\tlearn: 0.6368107\ttotal: 715ms\tremaining: 921ms\n",
      "437:\tlearn: 0.6367052\ttotal: 716ms\tremaining: 919ms\n",
      "438:\tlearn: 0.6366008\ttotal: 717ms\tremaining: 917ms\n",
      "439:\tlearn: 0.6364230\ttotal: 719ms\tremaining: 915ms\n",
      "440:\tlearn: 0.6363461\ttotal: 720ms\tremaining: 913ms\n",
      "441:\tlearn: 0.6362827\ttotal: 722ms\tremaining: 912ms\n",
      "442:\tlearn: 0.6362108\ttotal: 724ms\tremaining: 910ms\n",
      "443:\tlearn: 0.6361442\ttotal: 725ms\tremaining: 908ms\n",
      "444:\tlearn: 0.6361054\ttotal: 727ms\tremaining: 906ms\n",
      "445:\tlearn: 0.6360335\ttotal: 728ms\tremaining: 904ms\n",
      "446:\tlearn: 0.6359237\ttotal: 729ms\tremaining: 902ms\n",
      "447:\tlearn: 0.6358754\ttotal: 731ms\tremaining: 900ms\n",
      "448:\tlearn: 0.6357897\ttotal: 732ms\tremaining: 898ms\n",
      "449:\tlearn: 0.6357023\ttotal: 733ms\tremaining: 896ms\n",
      "450:\tlearn: 0.6356402\ttotal: 735ms\tremaining: 894ms\n",
      "451:\tlearn: 0.6356243\ttotal: 736ms\tremaining: 892ms\n",
      "452:\tlearn: 0.6355302\ttotal: 738ms\tremaining: 891ms\n",
      "453:\tlearn: 0.6354409\ttotal: 740ms\tremaining: 890ms\n",
      "454:\tlearn: 0.6353666\ttotal: 742ms\tremaining: 888ms\n",
      "455:\tlearn: 0.6352881\ttotal: 743ms\tremaining: 887ms\n",
      "456:\tlearn: 0.6352086\ttotal: 745ms\tremaining: 885ms\n",
      "457:\tlearn: 0.6351195\ttotal: 746ms\tremaining: 883ms\n",
      "458:\tlearn: 0.6350486\ttotal: 748ms\tremaining: 881ms\n",
      "459:\tlearn: 0.6349806\ttotal: 749ms\tremaining: 879ms\n",
      "460:\tlearn: 0.6349476\ttotal: 750ms\tremaining: 877ms\n",
      "461:\tlearn: 0.6348702\ttotal: 752ms\tremaining: 875ms\n",
      "462:\tlearn: 0.6347282\ttotal: 753ms\tremaining: 874ms\n",
      "463:\tlearn: 0.6346714\ttotal: 755ms\tremaining: 872ms\n",
      "464:\tlearn: 0.6345712\ttotal: 757ms\tremaining: 871ms\n",
      "465:\tlearn: 0.6344588\ttotal: 758ms\tremaining: 869ms\n",
      "466:\tlearn: 0.6343746\ttotal: 760ms\tremaining: 867ms\n",
      "467:\tlearn: 0.6343056\ttotal: 761ms\tremaining: 865ms\n",
      "468:\tlearn: 0.6342432\ttotal: 762ms\tremaining: 863ms\n",
      "469:\tlearn: 0.6341648\ttotal: 764ms\tremaining: 861ms\n",
      "470:\tlearn: 0.6340613\ttotal: 765ms\tremaining: 859ms\n",
      "471:\tlearn: 0.6339660\ttotal: 767ms\tremaining: 858ms\n",
      "472:\tlearn: 0.6338733\ttotal: 769ms\tremaining: 857ms\n",
      "473:\tlearn: 0.6337555\ttotal: 771ms\tremaining: 856ms\n",
      "474:\tlearn: 0.6336257\ttotal: 773ms\tremaining: 854ms\n",
      "475:\tlearn: 0.6335503\ttotal: 774ms\tremaining: 852ms\n",
      "476:\tlearn: 0.6334582\ttotal: 776ms\tremaining: 851ms\n",
      "477:\tlearn: 0.6333672\ttotal: 777ms\tremaining: 849ms\n",
      "478:\tlearn: 0.6333049\ttotal: 779ms\tremaining: 847ms\n",
      "479:\tlearn: 0.6332595\ttotal: 780ms\tremaining: 845ms\n",
      "480:\tlearn: 0.6331973\ttotal: 782ms\tremaining: 843ms\n",
      "481:\tlearn: 0.6331096\ttotal: 784ms\tremaining: 842ms\n",
      "482:\tlearn: 0.6330128\ttotal: 785ms\tremaining: 841ms\n",
      "483:\tlearn: 0.6329539\ttotal: 787ms\tremaining: 839ms\n",
      "484:\tlearn: 0.6328336\ttotal: 789ms\tremaining: 838ms\n",
      "485:\tlearn: 0.6327786\ttotal: 790ms\tremaining: 836ms\n",
      "486:\tlearn: 0.6327155\ttotal: 792ms\tremaining: 834ms\n",
      "487:\tlearn: 0.6326191\ttotal: 793ms\tremaining: 832ms\n",
      "488:\tlearn: 0.6325114\ttotal: 794ms\tremaining: 830ms\n",
      "489:\tlearn: 0.6323940\ttotal: 796ms\tremaining: 828ms\n",
      "490:\tlearn: 0.6323250\ttotal: 797ms\tremaining: 827ms\n",
      "491:\tlearn: 0.6322181\ttotal: 799ms\tremaining: 825ms\n",
      "492:\tlearn: 0.6321587\ttotal: 800ms\tremaining: 823ms\n",
      "493:\tlearn: 0.6320559\ttotal: 802ms\tremaining: 822ms\n",
      "494:\tlearn: 0.6319932\ttotal: 804ms\tremaining: 820ms\n",
      "495:\tlearn: 0.6318825\ttotal: 805ms\tremaining: 818ms\n",
      "496:\tlearn: 0.6317913\ttotal: 807ms\tremaining: 817ms\n",
      "497:\tlearn: 0.6317229\ttotal: 808ms\tremaining: 815ms\n",
      "498:\tlearn: 0.6315625\ttotal: 810ms\tremaining: 813ms\n",
      "499:\tlearn: 0.6314647\ttotal: 811ms\tremaining: 811ms\n",
      "500:\tlearn: 0.6313893\ttotal: 813ms\tremaining: 810ms\n",
      "501:\tlearn: 0.6312785\ttotal: 814ms\tremaining: 808ms\n",
      "502:\tlearn: 0.6312037\ttotal: 816ms\tremaining: 806ms\n",
      "503:\tlearn: 0.6310878\ttotal: 818ms\tremaining: 805ms\n",
      "504:\tlearn: 0.6310274\ttotal: 820ms\tremaining: 803ms\n",
      "505:\tlearn: 0.6309525\ttotal: 821ms\tremaining: 802ms\n",
      "506:\tlearn: 0.6308483\ttotal: 823ms\tremaining: 800ms\n",
      "507:\tlearn: 0.6307866\ttotal: 824ms\tremaining: 798ms\n",
      "508:\tlearn: 0.6306400\ttotal: 826ms\tremaining: 796ms\n",
      "509:\tlearn: 0.6306127\ttotal: 827ms\tremaining: 795ms\n",
      "510:\tlearn: 0.6304387\ttotal: 828ms\tremaining: 793ms\n",
      "511:\tlearn: 0.6303350\ttotal: 830ms\tremaining: 791ms\n",
      "512:\tlearn: 0.6301887\ttotal: 832ms\tremaining: 790ms\n",
      "513:\tlearn: 0.6300214\ttotal: 834ms\tremaining: 788ms\n",
      "514:\tlearn: 0.6298689\ttotal: 835ms\tremaining: 787ms\n",
      "515:\tlearn: 0.6297660\ttotal: 837ms\tremaining: 785ms\n",
      "516:\tlearn: 0.6296979\ttotal: 838ms\tremaining: 783ms\n",
      "517:\tlearn: 0.6296397\ttotal: 840ms\tremaining: 781ms\n",
      "518:\tlearn: 0.6295290\ttotal: 841ms\tremaining: 780ms\n",
      "519:\tlearn: 0.6294702\ttotal: 843ms\tremaining: 778ms\n",
      "520:\tlearn: 0.6294094\ttotal: 844ms\tremaining: 776ms\n",
      "521:\tlearn: 0.6293476\ttotal: 845ms\tremaining: 774ms\n",
      "522:\tlearn: 0.6292779\ttotal: 847ms\tremaining: 772ms\n",
      "523:\tlearn: 0.6292183\ttotal: 849ms\tremaining: 771ms\n",
      "524:\tlearn: 0.6291077\ttotal: 850ms\tremaining: 769ms\n",
      "525:\tlearn: 0.6289936\ttotal: 852ms\tremaining: 767ms\n",
      "526:\tlearn: 0.6288515\ttotal: 853ms\tremaining: 766ms\n",
      "527:\tlearn: 0.6288054\ttotal: 854ms\tremaining: 764ms\n",
      "528:\tlearn: 0.6286955\ttotal: 856ms\tremaining: 762ms\n",
      "529:\tlearn: 0.6285848\ttotal: 858ms\tremaining: 760ms\n",
      "530:\tlearn: 0.6284888\ttotal: 859ms\tremaining: 759ms\n",
      "531:\tlearn: 0.6283875\ttotal: 861ms\tremaining: 757ms\n",
      "532:\tlearn: 0.6283041\ttotal: 862ms\tremaining: 756ms\n",
      "533:\tlearn: 0.6281668\ttotal: 864ms\tremaining: 754ms\n",
      "534:\tlearn: 0.6281063\ttotal: 866ms\tremaining: 753ms\n",
      "535:\tlearn: 0.6280075\ttotal: 867ms\tremaining: 751ms\n",
      "536:\tlearn: 0.6279171\ttotal: 869ms\tremaining: 749ms\n",
      "537:\tlearn: 0.6278234\ttotal: 870ms\tremaining: 747ms\n",
      "538:\tlearn: 0.6277730\ttotal: 872ms\tremaining: 746ms\n",
      "539:\tlearn: 0.6277180\ttotal: 873ms\tremaining: 744ms\n",
      "540:\tlearn: 0.6276647\ttotal: 875ms\tremaining: 742ms\n",
      "541:\tlearn: 0.6276121\ttotal: 876ms\tremaining: 740ms\n",
      "542:\tlearn: 0.6275313\ttotal: 877ms\tremaining: 738ms\n",
      "543:\tlearn: 0.6274088\ttotal: 879ms\tremaining: 737ms\n",
      "544:\tlearn: 0.6273730\ttotal: 881ms\tremaining: 736ms\n",
      "545:\tlearn: 0.6272608\ttotal: 883ms\tremaining: 734ms\n",
      "546:\tlearn: 0.6272226\ttotal: 885ms\tremaining: 733ms\n",
      "547:\tlearn: 0.6271355\ttotal: 886ms\tremaining: 731ms\n",
      "548:\tlearn: 0.6270140\ttotal: 888ms\tremaining: 729ms\n",
      "549:\tlearn: 0.6269199\ttotal: 889ms\tremaining: 727ms\n",
      "550:\tlearn: 0.6268406\ttotal: 890ms\tremaining: 726ms\n",
      "551:\tlearn: 0.6268007\ttotal: 892ms\tremaining: 724ms\n",
      "552:\tlearn: 0.6266675\ttotal: 893ms\tremaining: 722ms\n",
      "553:\tlearn: 0.6265948\ttotal: 895ms\tremaining: 720ms\n",
      "554:\tlearn: 0.6264967\ttotal: 897ms\tremaining: 719ms\n",
      "555:\tlearn: 0.6263984\ttotal: 898ms\tremaining: 717ms\n",
      "556:\tlearn: 0.6262700\ttotal: 900ms\tremaining: 716ms\n",
      "557:\tlearn: 0.6261787\ttotal: 901ms\tremaining: 714ms\n",
      "558:\tlearn: 0.6261021\ttotal: 903ms\tremaining: 712ms\n",
      "559:\tlearn: 0.6259692\ttotal: 904ms\tremaining: 710ms\n",
      "560:\tlearn: 0.6258659\ttotal: 906ms\tremaining: 709ms\n",
      "561:\tlearn: 0.6257474\ttotal: 907ms\tremaining: 707ms\n",
      "562:\tlearn: 0.6256593\ttotal: 909ms\tremaining: 705ms\n",
      "563:\tlearn: 0.6256407\ttotal: 910ms\tremaining: 703ms\n",
      "564:\tlearn: 0.6255679\ttotal: 912ms\tremaining: 702ms\n",
      "565:\tlearn: 0.6255145\ttotal: 914ms\tremaining: 701ms\n",
      "566:\tlearn: 0.6253848\ttotal: 915ms\tremaining: 699ms\n",
      "567:\tlearn: 0.6253167\ttotal: 917ms\tremaining: 697ms\n",
      "568:\tlearn: 0.6252404\ttotal: 918ms\tremaining: 696ms\n",
      "569:\tlearn: 0.6251859\ttotal: 920ms\tremaining: 694ms\n",
      "570:\tlearn: 0.6251720\ttotal: 921ms\tremaining: 692ms\n",
      "571:\tlearn: 0.6250658\ttotal: 923ms\tremaining: 691ms\n",
      "572:\tlearn: 0.6249895\ttotal: 925ms\tremaining: 689ms\n",
      "573:\tlearn: 0.6249251\ttotal: 926ms\tremaining: 688ms\n",
      "574:\tlearn: 0.6248553\ttotal: 928ms\tremaining: 686ms\n",
      "575:\tlearn: 0.6247780\ttotal: 930ms\tremaining: 685ms\n",
      "576:\tlearn: 0.6246652\ttotal: 932ms\tremaining: 683ms\n",
      "577:\tlearn: 0.6246040\ttotal: 933ms\tremaining: 681ms\n",
      "578:\tlearn: 0.6245108\ttotal: 935ms\tremaining: 680ms\n",
      "579:\tlearn: 0.6244995\ttotal: 936ms\tremaining: 678ms\n",
      "580:\tlearn: 0.6244333\ttotal: 938ms\tremaining: 676ms\n",
      "581:\tlearn: 0.6243839\ttotal: 939ms\tremaining: 674ms\n",
      "582:\tlearn: 0.6242386\ttotal: 941ms\tremaining: 673ms\n",
      "583:\tlearn: 0.6241920\ttotal: 942ms\tremaining: 671ms\n",
      "584:\tlearn: 0.6240743\ttotal: 944ms\tremaining: 670ms\n",
      "585:\tlearn: 0.6240255\ttotal: 945ms\tremaining: 668ms\n",
      "586:\tlearn: 0.6239869\ttotal: 947ms\tremaining: 666ms\n",
      "587:\tlearn: 0.6239392\ttotal: 948ms\tremaining: 664ms\n",
      "588:\tlearn: 0.6238910\ttotal: 950ms\tremaining: 663ms\n",
      "589:\tlearn: 0.6238254\ttotal: 951ms\tremaining: 661ms\n",
      "590:\tlearn: 0.6237737\ttotal: 953ms\tremaining: 659ms\n",
      "591:\tlearn: 0.6237630\ttotal: 954ms\tremaining: 658ms\n",
      "592:\tlearn: 0.6236666\ttotal: 956ms\tremaining: 656ms\n",
      "593:\tlearn: 0.6235668\ttotal: 957ms\tremaining: 654ms\n",
      "594:\tlearn: 0.6235129\ttotal: 960ms\tremaining: 653ms\n",
      "595:\tlearn: 0.6234692\ttotal: 962ms\tremaining: 652ms\n",
      "596:\tlearn: 0.6234155\ttotal: 964ms\tremaining: 650ms\n",
      "597:\tlearn: 0.6233755\ttotal: 965ms\tremaining: 649ms\n",
      "598:\tlearn: 0.6232502\ttotal: 967ms\tremaining: 647ms\n",
      "599:\tlearn: 0.6231542\ttotal: 968ms\tremaining: 646ms\n",
      "600:\tlearn: 0.6230623\ttotal: 970ms\tremaining: 644ms\n",
      "601:\tlearn: 0.6229472\ttotal: 972ms\tremaining: 642ms\n",
      "602:\tlearn: 0.6228202\ttotal: 974ms\tremaining: 641ms\n",
      "603:\tlearn: 0.6227223\ttotal: 976ms\tremaining: 640ms\n",
      "604:\tlearn: 0.6226917\ttotal: 978ms\tremaining: 638ms\n",
      "605:\tlearn: 0.6226243\ttotal: 979ms\tremaining: 637ms\n",
      "606:\tlearn: 0.6225931\ttotal: 981ms\tremaining: 635ms\n",
      "607:\tlearn: 0.6225032\ttotal: 982ms\tremaining: 633ms\n",
      "608:\tlearn: 0.6223873\ttotal: 984ms\tremaining: 632ms\n",
      "609:\tlearn: 0.6222629\ttotal: 985ms\tremaining: 630ms\n",
      "610:\tlearn: 0.6221917\ttotal: 987ms\tremaining: 628ms\n",
      "611:\tlearn: 0.6220835\ttotal: 988ms\tremaining: 626ms\n",
      "612:\tlearn: 0.6219874\ttotal: 989ms\tremaining: 625ms\n",
      "613:\tlearn: 0.6218655\ttotal: 991ms\tremaining: 623ms\n",
      "614:\tlearn: 0.6218172\ttotal: 993ms\tremaining: 622ms\n",
      "615:\tlearn: 0.6217478\ttotal: 994ms\tremaining: 620ms\n",
      "616:\tlearn: 0.6217037\ttotal: 996ms\tremaining: 618ms\n",
      "617:\tlearn: 0.6216423\ttotal: 997ms\tremaining: 616ms\n",
      "618:\tlearn: 0.6215456\ttotal: 999ms\tremaining: 615ms\n",
      "619:\tlearn: 0.6215028\ttotal: 1s\tremaining: 613ms\n",
      "620:\tlearn: 0.6213763\ttotal: 1s\tremaining: 611ms\n",
      "621:\tlearn: 0.6213031\ttotal: 1s\tremaining: 610ms\n",
      "622:\tlearn: 0.6212390\ttotal: 1s\tremaining: 608ms\n",
      "623:\tlearn: 0.6212067\ttotal: 1.01s\tremaining: 606ms\n",
      "624:\tlearn: 0.6211725\ttotal: 1.01s\tremaining: 605ms\n",
      "625:\tlearn: 0.6210503\ttotal: 1.01s\tremaining: 603ms\n",
      "626:\tlearn: 0.6209461\ttotal: 1.01s\tremaining: 602ms\n",
      "627:\tlearn: 0.6209113\ttotal: 1.01s\tremaining: 600ms\n",
      "628:\tlearn: 0.6208620\ttotal: 1.01s\tremaining: 598ms\n",
      "629:\tlearn: 0.6208218\ttotal: 1.01s\tremaining: 597ms\n",
      "630:\tlearn: 0.6207794\ttotal: 1.02s\tremaining: 595ms\n",
      "631:\tlearn: 0.6207369\ttotal: 1.02s\tremaining: 593ms\n",
      "632:\tlearn: 0.6206109\ttotal: 1.02s\tremaining: 591ms\n",
      "633:\tlearn: 0.6205120\ttotal: 1.02s\tremaining: 590ms\n",
      "634:\tlearn: 0.6204682\ttotal: 1.02s\tremaining: 588ms\n",
      "635:\tlearn: 0.6204176\ttotal: 1.02s\tremaining: 587ms\n",
      "636:\tlearn: 0.6203631\ttotal: 1.03s\tremaining: 585ms\n",
      "637:\tlearn: 0.6203366\ttotal: 1.03s\tremaining: 583ms\n",
      "638:\tlearn: 0.6202888\ttotal: 1.03s\tremaining: 582ms\n",
      "639:\tlearn: 0.6202613\ttotal: 1.03s\tremaining: 580ms\n",
      "640:\tlearn: 0.6201571\ttotal: 1.03s\tremaining: 578ms\n",
      "641:\tlearn: 0.6201179\ttotal: 1.03s\tremaining: 576ms\n",
      "642:\tlearn: 0.6200774\ttotal: 1.03s\tremaining: 575ms\n",
      "643:\tlearn: 0.6199747\ttotal: 1.04s\tremaining: 573ms\n",
      "644:\tlearn: 0.6198517\ttotal: 1.04s\tremaining: 572ms\n",
      "645:\tlearn: 0.6197310\ttotal: 1.04s\tremaining: 570ms\n",
      "646:\tlearn: 0.6196483\ttotal: 1.04s\tremaining: 568ms\n",
      "647:\tlearn: 0.6196038\ttotal: 1.04s\tremaining: 567ms\n",
      "648:\tlearn: 0.6195252\ttotal: 1.04s\tremaining: 565ms\n",
      "649:\tlearn: 0.6194305\ttotal: 1.05s\tremaining: 563ms\n",
      "650:\tlearn: 0.6193431\ttotal: 1.05s\tremaining: 562ms\n",
      "651:\tlearn: 0.6192978\ttotal: 1.05s\tremaining: 560ms\n",
      "652:\tlearn: 0.6192365\ttotal: 1.05s\tremaining: 558ms\n",
      "653:\tlearn: 0.6191760\ttotal: 1.05s\tremaining: 557ms\n",
      "654:\tlearn: 0.6191368\ttotal: 1.05s\tremaining: 555ms\n",
      "655:\tlearn: 0.6190942\ttotal: 1.05s\tremaining: 554ms\n",
      "656:\tlearn: 0.6189891\ttotal: 1.06s\tremaining: 552ms\n",
      "657:\tlearn: 0.6189431\ttotal: 1.06s\tremaining: 551ms\n",
      "658:\tlearn: 0.6189095\ttotal: 1.06s\tremaining: 549ms\n",
      "659:\tlearn: 0.6188369\ttotal: 1.06s\tremaining: 547ms\n",
      "660:\tlearn: 0.6187161\ttotal: 1.06s\tremaining: 545ms\n",
      "661:\tlearn: 0.6186595\ttotal: 1.06s\tremaining: 544ms\n",
      "662:\tlearn: 0.6186224\ttotal: 1.07s\tremaining: 542ms\n",
      "663:\tlearn: 0.6185474\ttotal: 1.07s\tremaining: 540ms\n",
      "664:\tlearn: 0.6184884\ttotal: 1.07s\tremaining: 539ms\n",
      "665:\tlearn: 0.6184709\ttotal: 1.07s\tremaining: 537ms\n",
      "666:\tlearn: 0.6183472\ttotal: 1.07s\tremaining: 536ms\n",
      "667:\tlearn: 0.6182681\ttotal: 1.07s\tremaining: 534ms\n",
      "668:\tlearn: 0.6182393\ttotal: 1.08s\tremaining: 533ms\n",
      "669:\tlearn: 0.6182309\ttotal: 1.08s\tremaining: 531ms\n",
      "670:\tlearn: 0.6181858\ttotal: 1.08s\tremaining: 529ms\n",
      "671:\tlearn: 0.6181148\ttotal: 1.08s\tremaining: 528ms\n",
      "672:\tlearn: 0.6180809\ttotal: 1.08s\tremaining: 526ms\n",
      "673:\tlearn: 0.6179954\ttotal: 1.08s\tremaining: 524ms\n",
      "674:\tlearn: 0.6178532\ttotal: 1.09s\tremaining: 523ms\n",
      "675:\tlearn: 0.6178409\ttotal: 1.09s\tremaining: 521ms\n",
      "676:\tlearn: 0.6177801\ttotal: 1.09s\tremaining: 520ms\n",
      "677:\tlearn: 0.6176700\ttotal: 1.09s\tremaining: 518ms\n",
      "678:\tlearn: 0.6175193\ttotal: 1.09s\tremaining: 517ms\n",
      "679:\tlearn: 0.6174094\ttotal: 1.09s\tremaining: 515ms\n",
      "680:\tlearn: 0.6173678\ttotal: 1.09s\tremaining: 513ms\n",
      "681:\tlearn: 0.6173390\ttotal: 1.1s\tremaining: 512ms\n",
      "682:\tlearn: 0.6172346\ttotal: 1.1s\tremaining: 510ms\n",
      "683:\tlearn: 0.6171908\ttotal: 1.1s\tremaining: 508ms\n",
      "684:\tlearn: 0.6171496\ttotal: 1.1s\tremaining: 507ms\n",
      "685:\tlearn: 0.6170629\ttotal: 1.1s\tremaining: 505ms\n",
      "686:\tlearn: 0.6169744\ttotal: 1.1s\tremaining: 503ms\n",
      "687:\tlearn: 0.6169050\ttotal: 1.11s\tremaining: 502ms\n",
      "688:\tlearn: 0.6168160\ttotal: 1.11s\tremaining: 500ms\n",
      "689:\tlearn: 0.6167072\ttotal: 1.11s\tremaining: 499ms\n",
      "690:\tlearn: 0.6165781\ttotal: 1.11s\tremaining: 497ms\n",
      "691:\tlearn: 0.6164771\ttotal: 1.11s\tremaining: 495ms\n",
      "692:\tlearn: 0.6163766\ttotal: 1.11s\tremaining: 494ms\n",
      "693:\tlearn: 0.6163326\ttotal: 1.11s\tremaining: 492ms\n",
      "694:\tlearn: 0.6162807\ttotal: 1.12s\tremaining: 490ms\n",
      "695:\tlearn: 0.6161862\ttotal: 1.12s\tremaining: 489ms\n",
      "696:\tlearn: 0.6161358\ttotal: 1.12s\tremaining: 487ms\n",
      "697:\tlearn: 0.6160472\ttotal: 1.12s\tremaining: 485ms\n",
      "698:\tlearn: 0.6159414\ttotal: 1.12s\tremaining: 484ms\n",
      "699:\tlearn: 0.6159110\ttotal: 1.12s\tremaining: 482ms\n",
      "700:\tlearn: 0.6158689\ttotal: 1.13s\tremaining: 480ms\n",
      "701:\tlearn: 0.6157292\ttotal: 1.13s\tremaining: 479ms\n",
      "702:\tlearn: 0.6157010\ttotal: 1.13s\tremaining: 477ms\n",
      "703:\tlearn: 0.6155850\ttotal: 1.13s\tremaining: 476ms\n",
      "704:\tlearn: 0.6155000\ttotal: 1.13s\tremaining: 474ms\n",
      "705:\tlearn: 0.6153826\ttotal: 1.13s\tremaining: 472ms\n",
      "706:\tlearn: 0.6153580\ttotal: 1.14s\tremaining: 471ms\n",
      "707:\tlearn: 0.6153148\ttotal: 1.14s\tremaining: 469ms\n",
      "708:\tlearn: 0.6152627\ttotal: 1.14s\tremaining: 468ms\n",
      "709:\tlearn: 0.6151455\ttotal: 1.14s\tremaining: 466ms\n",
      "710:\tlearn: 0.6150555\ttotal: 1.14s\tremaining: 464ms\n",
      "711:\tlearn: 0.6150255\ttotal: 1.14s\tremaining: 463ms\n",
      "712:\tlearn: 0.6149578\ttotal: 1.15s\tremaining: 461ms\n",
      "713:\tlearn: 0.6149223\ttotal: 1.15s\tremaining: 459ms\n",
      "714:\tlearn: 0.6148875\ttotal: 1.15s\tremaining: 458ms\n",
      "715:\tlearn: 0.6148104\ttotal: 1.15s\tremaining: 456ms\n",
      "716:\tlearn: 0.6147248\ttotal: 1.15s\tremaining: 455ms\n",
      "717:\tlearn: 0.6146151\ttotal: 1.16s\tremaining: 454ms\n",
      "718:\tlearn: 0.6145197\ttotal: 1.16s\tremaining: 452ms\n",
      "719:\tlearn: 0.6144739\ttotal: 1.16s\tremaining: 451ms\n",
      "720:\tlearn: 0.6144329\ttotal: 1.16s\tremaining: 449ms\n",
      "721:\tlearn: 0.6143832\ttotal: 1.16s\tremaining: 448ms\n",
      "722:\tlearn: 0.6143031\ttotal: 1.16s\tremaining: 446ms\n",
      "723:\tlearn: 0.6142673\ttotal: 1.17s\tremaining: 445ms\n",
      "724:\tlearn: 0.6142246\ttotal: 1.17s\tremaining: 443ms\n",
      "725:\tlearn: 0.6141099\ttotal: 1.17s\tremaining: 441ms\n",
      "726:\tlearn: 0.6140280\ttotal: 1.17s\tremaining: 440ms\n",
      "727:\tlearn: 0.6140074\ttotal: 1.17s\tremaining: 438ms\n",
      "728:\tlearn: 0.6139653\ttotal: 1.18s\tremaining: 437ms\n",
      "729:\tlearn: 0.6139304\ttotal: 1.18s\tremaining: 435ms\n",
      "730:\tlearn: 0.6138362\ttotal: 1.18s\tremaining: 434ms\n",
      "731:\tlearn: 0.6137429\ttotal: 1.18s\tremaining: 432ms\n",
      "732:\tlearn: 0.6136340\ttotal: 1.18s\tremaining: 431ms\n",
      "733:\tlearn: 0.6135356\ttotal: 1.18s\tremaining: 429ms\n",
      "734:\tlearn: 0.6134879\ttotal: 1.19s\tremaining: 428ms\n",
      "735:\tlearn: 0.6134739\ttotal: 1.19s\tremaining: 426ms\n",
      "736:\tlearn: 0.6134093\ttotal: 1.19s\tremaining: 425ms\n",
      "737:\tlearn: 0.6133287\ttotal: 1.19s\tremaining: 423ms\n",
      "738:\tlearn: 0.6133112\ttotal: 1.19s\tremaining: 421ms\n",
      "739:\tlearn: 0.6132379\ttotal: 1.2s\tremaining: 420ms\n",
      "740:\tlearn: 0.6132118\ttotal: 1.2s\tremaining: 418ms\n",
      "741:\tlearn: 0.6131233\ttotal: 1.2s\tremaining: 417ms\n",
      "742:\tlearn: 0.6131055\ttotal: 1.2s\tremaining: 415ms\n",
      "743:\tlearn: 0.6130679\ttotal: 1.2s\tremaining: 414ms\n",
      "744:\tlearn: 0.6129947\ttotal: 1.2s\tremaining: 412ms\n",
      "745:\tlearn: 0.6129066\ttotal: 1.21s\tremaining: 410ms\n",
      "746:\tlearn: 0.6128024\ttotal: 1.21s\tremaining: 409ms\n",
      "747:\tlearn: 0.6127590\ttotal: 1.21s\tremaining: 407ms\n",
      "748:\tlearn: 0.6127196\ttotal: 1.21s\tremaining: 406ms\n",
      "749:\tlearn: 0.6126831\ttotal: 1.21s\tremaining: 404ms\n",
      "750:\tlearn: 0.6125802\ttotal: 1.21s\tremaining: 403ms\n",
      "751:\tlearn: 0.6124580\ttotal: 1.22s\tremaining: 401ms\n",
      "752:\tlearn: 0.6123643\ttotal: 1.22s\tremaining: 400ms\n",
      "753:\tlearn: 0.6123052\ttotal: 1.22s\tremaining: 398ms\n",
      "754:\tlearn: 0.6122867\ttotal: 1.22s\tremaining: 397ms\n",
      "755:\tlearn: 0.6122220\ttotal: 1.23s\tremaining: 396ms\n",
      "756:\tlearn: 0.6121673\ttotal: 1.23s\tremaining: 394ms\n",
      "757:\tlearn: 0.6120770\ttotal: 1.23s\tremaining: 393ms\n",
      "758:\tlearn: 0.6120153\ttotal: 1.23s\tremaining: 391ms\n",
      "759:\tlearn: 0.6119057\ttotal: 1.23s\tremaining: 390ms\n",
      "760:\tlearn: 0.6117890\ttotal: 1.24s\tremaining: 389ms\n",
      "761:\tlearn: 0.6117309\ttotal: 1.24s\tremaining: 387ms\n",
      "762:\tlearn: 0.6116857\ttotal: 1.24s\tremaining: 385ms\n",
      "763:\tlearn: 0.6116533\ttotal: 1.24s\tremaining: 384ms\n",
      "764:\tlearn: 0.6115562\ttotal: 1.25s\tremaining: 383ms\n",
      "765:\tlearn: 0.6115111\ttotal: 1.25s\tremaining: 381ms\n",
      "766:\tlearn: 0.6114558\ttotal: 1.25s\tremaining: 379ms\n",
      "767:\tlearn: 0.6114440\ttotal: 1.25s\tremaining: 378ms\n",
      "768:\tlearn: 0.6112949\ttotal: 1.25s\tremaining: 376ms\n",
      "769:\tlearn: 0.6112549\ttotal: 1.25s\tremaining: 375ms\n",
      "770:\tlearn: 0.6111766\ttotal: 1.26s\tremaining: 373ms\n",
      "771:\tlearn: 0.6111408\ttotal: 1.26s\tremaining: 372ms\n",
      "772:\tlearn: 0.6110479\ttotal: 1.26s\tremaining: 370ms\n",
      "773:\tlearn: 0.6109955\ttotal: 1.26s\tremaining: 369ms\n",
      "774:\tlearn: 0.6109528\ttotal: 1.26s\tremaining: 367ms\n",
      "775:\tlearn: 0.6109054\ttotal: 1.27s\tremaining: 366ms\n",
      "776:\tlearn: 0.6108367\ttotal: 1.27s\tremaining: 364ms\n",
      "777:\tlearn: 0.6107826\ttotal: 1.27s\tremaining: 363ms\n",
      "778:\tlearn: 0.6107271\ttotal: 1.27s\tremaining: 361ms\n",
      "779:\tlearn: 0.6106481\ttotal: 1.27s\tremaining: 359ms\n",
      "780:\tlearn: 0.6106062\ttotal: 1.28s\tremaining: 358ms\n",
      "781:\tlearn: 0.6105010\ttotal: 1.28s\tremaining: 356ms\n",
      "782:\tlearn: 0.6104212\ttotal: 1.28s\tremaining: 355ms\n",
      "783:\tlearn: 0.6103772\ttotal: 1.28s\tremaining: 353ms\n",
      "784:\tlearn: 0.6103002\ttotal: 1.28s\tremaining: 352ms\n",
      "785:\tlearn: 0.6102220\ttotal: 1.28s\tremaining: 350ms\n",
      "786:\tlearn: 0.6101503\ttotal: 1.29s\tremaining: 348ms\n",
      "787:\tlearn: 0.6101347\ttotal: 1.29s\tremaining: 347ms\n",
      "788:\tlearn: 0.6100366\ttotal: 1.29s\tremaining: 345ms\n",
      "789:\tlearn: 0.6099368\ttotal: 1.29s\tremaining: 344ms\n",
      "790:\tlearn: 0.6098793\ttotal: 1.29s\tremaining: 342ms\n",
      "791:\tlearn: 0.6097674\ttotal: 1.3s\tremaining: 340ms\n",
      "792:\tlearn: 0.6097283\ttotal: 1.3s\tremaining: 339ms\n",
      "793:\tlearn: 0.6096641\ttotal: 1.3s\tremaining: 337ms\n",
      "794:\tlearn: 0.6095596\ttotal: 1.3s\tremaining: 336ms\n",
      "795:\tlearn: 0.6095319\ttotal: 1.3s\tremaining: 334ms\n",
      "796:\tlearn: 0.6094804\ttotal: 1.3s\tremaining: 332ms\n",
      "797:\tlearn: 0.6094400\ttotal: 1.31s\tremaining: 331ms\n",
      "798:\tlearn: 0.6094012\ttotal: 1.31s\tremaining: 329ms\n",
      "799:\tlearn: 0.6093930\ttotal: 1.31s\tremaining: 328ms\n",
      "800:\tlearn: 0.6092866\ttotal: 1.31s\tremaining: 326ms\n",
      "801:\tlearn: 0.6091919\ttotal: 1.31s\tremaining: 324ms\n",
      "802:\tlearn: 0.6091536\ttotal: 1.31s\tremaining: 323ms\n",
      "803:\tlearn: 0.6091136\ttotal: 1.32s\tremaining: 321ms\n",
      "804:\tlearn: 0.6090800\ttotal: 1.32s\tremaining: 320ms\n",
      "805:\tlearn: 0.6090431\ttotal: 1.32s\tremaining: 318ms\n",
      "806:\tlearn: 0.6089737\ttotal: 1.32s\tremaining: 316ms\n",
      "807:\tlearn: 0.6089492\ttotal: 1.32s\tremaining: 315ms\n",
      "808:\tlearn: 0.6088686\ttotal: 1.33s\tremaining: 313ms\n",
      "809:\tlearn: 0.6087586\ttotal: 1.33s\tremaining: 312ms\n",
      "810:\tlearn: 0.6086932\ttotal: 1.33s\tremaining: 310ms\n",
      "811:\tlearn: 0.6086239\ttotal: 1.33s\tremaining: 308ms\n",
      "812:\tlearn: 0.6085394\ttotal: 1.33s\tremaining: 307ms\n",
      "813:\tlearn: 0.6085175\ttotal: 1.33s\tremaining: 305ms\n",
      "814:\tlearn: 0.6084040\ttotal: 1.33s\tremaining: 303ms\n",
      "815:\tlearn: 0.6083855\ttotal: 1.34s\tremaining: 302ms\n",
      "816:\tlearn: 0.6082901\ttotal: 1.34s\tremaining: 300ms\n",
      "817:\tlearn: 0.6081984\ttotal: 1.34s\tremaining: 298ms\n",
      "818:\tlearn: 0.6080904\ttotal: 1.34s\tremaining: 297ms\n",
      "819:\tlearn: 0.6079933\ttotal: 1.34s\tremaining: 295ms\n",
      "820:\tlearn: 0.6078849\ttotal: 1.35s\tremaining: 294ms\n",
      "821:\tlearn: 0.6077507\ttotal: 1.35s\tremaining: 292ms\n",
      "822:\tlearn: 0.6076779\ttotal: 1.35s\tremaining: 290ms\n",
      "823:\tlearn: 0.6076231\ttotal: 1.35s\tremaining: 289ms\n",
      "824:\tlearn: 0.6076065\ttotal: 1.35s\tremaining: 287ms\n",
      "825:\tlearn: 0.6075549\ttotal: 1.35s\tremaining: 285ms\n",
      "826:\tlearn: 0.6074357\ttotal: 1.35s\tremaining: 284ms\n",
      "827:\tlearn: 0.6074041\ttotal: 1.36s\tremaining: 282ms\n",
      "828:\tlearn: 0.6073186\ttotal: 1.36s\tremaining: 280ms\n",
      "829:\tlearn: 0.6072749\ttotal: 1.36s\tremaining: 279ms\n",
      "830:\tlearn: 0.6072388\ttotal: 1.36s\tremaining: 277ms\n",
      "831:\tlearn: 0.6071682\ttotal: 1.36s\tremaining: 275ms\n",
      "832:\tlearn: 0.6070833\ttotal: 1.36s\tremaining: 274ms\n",
      "833:\tlearn: 0.6070224\ttotal: 1.37s\tremaining: 272ms\n",
      "834:\tlearn: 0.6069884\ttotal: 1.37s\tremaining: 270ms\n",
      "835:\tlearn: 0.6068779\ttotal: 1.37s\tremaining: 269ms\n",
      "836:\tlearn: 0.6068268\ttotal: 1.37s\tremaining: 267ms\n",
      "837:\tlearn: 0.6067916\ttotal: 1.37s\tremaining: 265ms\n",
      "838:\tlearn: 0.6067210\ttotal: 1.37s\tremaining: 264ms\n",
      "839:\tlearn: 0.6066523\ttotal: 1.38s\tremaining: 262ms\n",
      "840:\tlearn: 0.6066185\ttotal: 1.38s\tremaining: 260ms\n",
      "841:\tlearn: 0.6065731\ttotal: 1.38s\tremaining: 259ms\n",
      "842:\tlearn: 0.6065157\ttotal: 1.38s\tremaining: 257ms\n",
      "843:\tlearn: 0.6064432\ttotal: 1.38s\tremaining: 255ms\n",
      "844:\tlearn: 0.6063859\ttotal: 1.38s\tremaining: 254ms\n",
      "845:\tlearn: 0.6063770\ttotal: 1.39s\tremaining: 252ms\n",
      "846:\tlearn: 0.6063367\ttotal: 1.39s\tremaining: 250ms\n",
      "847:\tlearn: 0.6062171\ttotal: 1.39s\tremaining: 249ms\n",
      "848:\tlearn: 0.6061177\ttotal: 1.39s\tremaining: 247ms\n",
      "849:\tlearn: 0.6061075\ttotal: 1.39s\tremaining: 245ms\n",
      "850:\tlearn: 0.6060983\ttotal: 1.39s\tremaining: 244ms\n",
      "851:\tlearn: 0.6060274\ttotal: 1.39s\tremaining: 242ms\n",
      "852:\tlearn: 0.6059979\ttotal: 1.4s\tremaining: 240ms\n",
      "853:\tlearn: 0.6059393\ttotal: 1.4s\tremaining: 239ms\n",
      "854:\tlearn: 0.6059105\ttotal: 1.4s\tremaining: 237ms\n",
      "855:\tlearn: 0.6058830\ttotal: 1.4s\tremaining: 235ms\n",
      "856:\tlearn: 0.6058331\ttotal: 1.4s\tremaining: 234ms\n",
      "857:\tlearn: 0.6057771\ttotal: 1.4s\tremaining: 232ms\n",
      "858:\tlearn: 0.6056723\ttotal: 1.4s\tremaining: 231ms\n",
      "859:\tlearn: 0.6055707\ttotal: 1.41s\tremaining: 229ms\n",
      "860:\tlearn: 0.6054715\ttotal: 1.41s\tremaining: 227ms\n",
      "861:\tlearn: 0.6054362\ttotal: 1.41s\tremaining: 226ms\n",
      "862:\tlearn: 0.6053738\ttotal: 1.41s\tremaining: 224ms\n",
      "863:\tlearn: 0.6053267\ttotal: 1.41s\tremaining: 222ms\n",
      "864:\tlearn: 0.6052415\ttotal: 1.41s\tremaining: 221ms\n",
      "865:\tlearn: 0.6051270\ttotal: 1.41s\tremaining: 219ms\n",
      "866:\tlearn: 0.6050636\ttotal: 1.42s\tremaining: 217ms\n",
      "867:\tlearn: 0.6050302\ttotal: 1.42s\tremaining: 216ms\n",
      "868:\tlearn: 0.6049879\ttotal: 1.42s\tremaining: 214ms\n",
      "869:\tlearn: 0.6049273\ttotal: 1.42s\tremaining: 212ms\n",
      "870:\tlearn: 0.6048280\ttotal: 1.42s\tremaining: 211ms\n",
      "871:\tlearn: 0.6047742\ttotal: 1.42s\tremaining: 209ms\n",
      "872:\tlearn: 0.6047001\ttotal: 1.43s\tremaining: 207ms\n",
      "873:\tlearn: 0.6046175\ttotal: 1.43s\tremaining: 206ms\n",
      "874:\tlearn: 0.6045479\ttotal: 1.43s\tremaining: 204ms\n",
      "875:\tlearn: 0.6044831\ttotal: 1.43s\tremaining: 202ms\n",
      "876:\tlearn: 0.6044149\ttotal: 1.43s\tremaining: 201ms\n",
      "877:\tlearn: 0.6043296\ttotal: 1.43s\tremaining: 199ms\n",
      "878:\tlearn: 0.6042982\ttotal: 1.43s\tremaining: 197ms\n",
      "879:\tlearn: 0.6042714\ttotal: 1.44s\tremaining: 196ms\n",
      "880:\tlearn: 0.6042394\ttotal: 1.44s\tremaining: 194ms\n",
      "881:\tlearn: 0.6042339\ttotal: 1.44s\tremaining: 193ms\n",
      "882:\tlearn: 0.6041566\ttotal: 1.44s\tremaining: 191ms\n",
      "883:\tlearn: 0.6040622\ttotal: 1.44s\tremaining: 189ms\n",
      "884:\tlearn: 0.6040400\ttotal: 1.44s\tremaining: 188ms\n",
      "885:\tlearn: 0.6039789\ttotal: 1.45s\tremaining: 186ms\n",
      "886:\tlearn: 0.6039552\ttotal: 1.45s\tremaining: 184ms\n",
      "887:\tlearn: 0.6038393\ttotal: 1.45s\tremaining: 183ms\n",
      "888:\tlearn: 0.6038197\ttotal: 1.45s\tremaining: 181ms\n",
      "889:\tlearn: 0.6037695\ttotal: 1.45s\tremaining: 179ms\n",
      "890:\tlearn: 0.6036446\ttotal: 1.45s\tremaining: 178ms\n",
      "891:\tlearn: 0.6036017\ttotal: 1.45s\tremaining: 176ms\n",
      "892:\tlearn: 0.6035621\ttotal: 1.46s\tremaining: 174ms\n",
      "893:\tlearn: 0.6035051\ttotal: 1.46s\tremaining: 173ms\n",
      "894:\tlearn: 0.6034773\ttotal: 1.46s\tremaining: 171ms\n",
      "895:\tlearn: 0.6034685\ttotal: 1.46s\tremaining: 170ms\n",
      "896:\tlearn: 0.6033988\ttotal: 1.46s\tremaining: 168ms\n",
      "897:\tlearn: 0.6033799\ttotal: 1.46s\tremaining: 166ms\n",
      "898:\tlearn: 0.6032866\ttotal: 1.47s\tremaining: 165ms\n",
      "899:\tlearn: 0.6032546\ttotal: 1.47s\tremaining: 163ms\n",
      "900:\tlearn: 0.6032209\ttotal: 1.47s\tremaining: 161ms\n",
      "901:\tlearn: 0.6030958\ttotal: 1.47s\tremaining: 160ms\n",
      "902:\tlearn: 0.6030867\ttotal: 1.47s\tremaining: 158ms\n",
      "903:\tlearn: 0.6030156\ttotal: 1.47s\tremaining: 156ms\n",
      "904:\tlearn: 0.6029795\ttotal: 1.47s\tremaining: 155ms\n",
      "905:\tlearn: 0.6029636\ttotal: 1.48s\tremaining: 153ms\n",
      "906:\tlearn: 0.6029358\ttotal: 1.48s\tremaining: 152ms\n",
      "907:\tlearn: 0.6028745\ttotal: 1.48s\tremaining: 150ms\n",
      "908:\tlearn: 0.6027998\ttotal: 1.48s\tremaining: 148ms\n",
      "909:\tlearn: 0.6027115\ttotal: 1.48s\tremaining: 147ms\n",
      "910:\tlearn: 0.6026634\ttotal: 1.48s\tremaining: 145ms\n",
      "911:\tlearn: 0.6026523\ttotal: 1.49s\tremaining: 143ms\n",
      "912:\tlearn: 0.6026283\ttotal: 1.49s\tremaining: 142ms\n",
      "913:\tlearn: 0.6026107\ttotal: 1.49s\tremaining: 140ms\n",
      "914:\tlearn: 0.6025328\ttotal: 1.49s\tremaining: 138ms\n",
      "915:\tlearn: 0.6025215\ttotal: 1.49s\tremaining: 137ms\n",
      "916:\tlearn: 0.6024426\ttotal: 1.49s\tremaining: 135ms\n",
      "917:\tlearn: 0.6024129\ttotal: 1.49s\tremaining: 134ms\n",
      "918:\tlearn: 0.6023883\ttotal: 1.5s\tremaining: 132ms\n",
      "919:\tlearn: 0.6023707\ttotal: 1.5s\tremaining: 130ms\n",
      "920:\tlearn: 0.6022897\ttotal: 1.5s\tremaining: 129ms\n",
      "921:\tlearn: 0.6022153\ttotal: 1.5s\tremaining: 127ms\n",
      "922:\tlearn: 0.6021188\ttotal: 1.5s\tremaining: 125ms\n",
      "923:\tlearn: 0.6020746\ttotal: 1.5s\tremaining: 124ms\n",
      "924:\tlearn: 0.6020540\ttotal: 1.5s\tremaining: 122ms\n",
      "925:\tlearn: 0.6019763\ttotal: 1.51s\tremaining: 120ms\n",
      "926:\tlearn: 0.6019696\ttotal: 1.51s\tremaining: 119ms\n",
      "927:\tlearn: 0.6019013\ttotal: 1.51s\tremaining: 117ms\n",
      "928:\tlearn: 0.6018717\ttotal: 1.51s\tremaining: 116ms\n",
      "929:\tlearn: 0.6018342\ttotal: 1.51s\tremaining: 114ms\n",
      "930:\tlearn: 0.6017090\ttotal: 1.51s\tremaining: 112ms\n",
      "931:\tlearn: 0.6016163\ttotal: 1.52s\tremaining: 111ms\n",
      "932:\tlearn: 0.6015474\ttotal: 1.52s\tremaining: 109ms\n",
      "933:\tlearn: 0.6015163\ttotal: 1.52s\tremaining: 107ms\n",
      "934:\tlearn: 0.6014962\ttotal: 1.52s\tremaining: 106ms\n",
      "935:\tlearn: 0.6013936\ttotal: 1.52s\tremaining: 104ms\n",
      "936:\tlearn: 0.6013835\ttotal: 1.52s\tremaining: 102ms\n",
      "937:\tlearn: 0.6013037\ttotal: 1.52s\tremaining: 101ms\n",
      "938:\tlearn: 0.6012562\ttotal: 1.53s\tremaining: 99.2ms\n",
      "939:\tlearn: 0.6011696\ttotal: 1.53s\tremaining: 97.5ms\n",
      "940:\tlearn: 0.6011419\ttotal: 1.53s\tremaining: 95.9ms\n",
      "941:\tlearn: 0.6011007\ttotal: 1.53s\tremaining: 94.3ms\n",
      "942:\tlearn: 0.6010357\ttotal: 1.53s\tremaining: 92.7ms\n",
      "943:\tlearn: 0.6009532\ttotal: 1.53s\tremaining: 91.1ms\n",
      "944:\tlearn: 0.6009334\ttotal: 1.54s\tremaining: 89.4ms\n",
      "945:\tlearn: 0.6009026\ttotal: 1.54s\tremaining: 87.8ms\n",
      "946:\tlearn: 0.6008146\ttotal: 1.54s\tremaining: 86.2ms\n",
      "947:\tlearn: 0.6007838\ttotal: 1.54s\tremaining: 84.6ms\n",
      "948:\tlearn: 0.6007122\ttotal: 1.54s\tremaining: 82.9ms\n",
      "949:\tlearn: 0.6006383\ttotal: 1.54s\tremaining: 81.3ms\n",
      "950:\tlearn: 0.6005677\ttotal: 1.55s\tremaining: 79.7ms\n",
      "951:\tlearn: 0.6004973\ttotal: 1.55s\tremaining: 78.1ms\n",
      "952:\tlearn: 0.6004704\ttotal: 1.55s\tremaining: 76.4ms\n",
      "953:\tlearn: 0.6004169\ttotal: 1.55s\tremaining: 74.8ms\n",
      "954:\tlearn: 0.6003443\ttotal: 1.55s\tremaining: 73.2ms\n",
      "955:\tlearn: 0.6003056\ttotal: 1.55s\tremaining: 71.5ms\n",
      "956:\tlearn: 0.6002464\ttotal: 1.55s\tremaining: 69.9ms\n",
      "957:\tlearn: 0.6001325\ttotal: 1.56s\tremaining: 68.3ms\n",
      "958:\tlearn: 0.6001054\ttotal: 1.56s\tremaining: 66.7ms\n",
      "959:\tlearn: 0.6000930\ttotal: 1.56s\tremaining: 65ms\n",
      "960:\tlearn: 0.6000426\ttotal: 1.56s\tremaining: 63.4ms\n",
      "961:\tlearn: 0.5999581\ttotal: 1.56s\tremaining: 61.8ms\n",
      "962:\tlearn: 0.5999049\ttotal: 1.56s\tremaining: 60.2ms\n",
      "963:\tlearn: 0.5998774\ttotal: 1.57s\tremaining: 58.5ms\n",
      "964:\tlearn: 0.5998431\ttotal: 1.57s\tremaining: 56.9ms\n",
      "965:\tlearn: 0.5998040\ttotal: 1.57s\tremaining: 55.3ms\n",
      "966:\tlearn: 0.5997778\ttotal: 1.57s\tremaining: 53.6ms\n",
      "967:\tlearn: 0.5997181\ttotal: 1.57s\tremaining: 52ms\n",
      "968:\tlearn: 0.5996946\ttotal: 1.57s\tremaining: 50.4ms\n",
      "969:\tlearn: 0.5996804\ttotal: 1.58s\tremaining: 48.7ms\n",
      "970:\tlearn: 0.5996579\ttotal: 1.58s\tremaining: 47.1ms\n",
      "971:\tlearn: 0.5995704\ttotal: 1.58s\tremaining: 45.5ms\n",
      "972:\tlearn: 0.5994845\ttotal: 1.58s\tremaining: 43.9ms\n",
      "973:\tlearn: 0.5994322\ttotal: 1.58s\tremaining: 42.2ms\n",
      "974:\tlearn: 0.5993526\ttotal: 1.58s\tremaining: 40.6ms\n",
      "975:\tlearn: 0.5992908\ttotal: 1.58s\tremaining: 39ms\n",
      "976:\tlearn: 0.5992724\ttotal: 1.59s\tremaining: 37.4ms\n",
      "977:\tlearn: 0.5992341\ttotal: 1.59s\tremaining: 35.7ms\n",
      "978:\tlearn: 0.5991761\ttotal: 1.59s\tremaining: 34.1ms\n",
      "979:\tlearn: 0.5991465\ttotal: 1.59s\tremaining: 32.5ms\n",
      "980:\tlearn: 0.5990979\ttotal: 1.59s\tremaining: 30.9ms\n",
      "981:\tlearn: 0.5990378\ttotal: 1.59s\tremaining: 29.2ms\n",
      "982:\tlearn: 0.5989824\ttotal: 1.6s\tremaining: 27.6ms\n",
      "983:\tlearn: 0.5989745\ttotal: 1.6s\tremaining: 26ms\n",
      "984:\tlearn: 0.5988989\ttotal: 1.6s\tremaining: 24.4ms\n",
      "985:\tlearn: 0.5988759\ttotal: 1.6s\tremaining: 22.7ms\n",
      "986:\tlearn: 0.5987703\ttotal: 1.6s\tremaining: 21.1ms\n",
      "987:\tlearn: 0.5987030\ttotal: 1.6s\tremaining: 19.5ms\n",
      "988:\tlearn: 0.5986815\ttotal: 1.6s\tremaining: 17.9ms\n",
      "989:\tlearn: 0.5985889\ttotal: 1.61s\tremaining: 16.2ms\n",
      "990:\tlearn: 0.5984942\ttotal: 1.61s\tremaining: 14.6ms\n",
      "991:\tlearn: 0.5984734\ttotal: 1.61s\tremaining: 13ms\n",
      "992:\tlearn: 0.5984642\ttotal: 1.61s\tremaining: 11.4ms\n",
      "993:\tlearn: 0.5984452\ttotal: 1.61s\tremaining: 9.74ms\n",
      "994:\tlearn: 0.5983661\ttotal: 1.61s\tremaining: 8.12ms\n",
      "995:\tlearn: 0.5983390\ttotal: 1.62s\tremaining: 6.49ms\n",
      "996:\tlearn: 0.5983128\ttotal: 1.62s\tremaining: 4.87ms\n",
      "997:\tlearn: 0.5982861\ttotal: 1.62s\tremaining: 3.25ms\n",
      "998:\tlearn: 0.5982740\ttotal: 1.62s\tremaining: 1.62ms\n",
      "999:\tlearn: 0.5982454\ttotal: 1.62s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.642576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.621551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.570302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.642576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.624179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.630749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.634691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "0  Logistic Regression  0.642576\n",
       "1          Naive Bayes  0.621551\n",
       "2                  SVM  0.570302\n",
       "3        Random Forest  0.642576\n",
       "4    Gradient Boosting  0.624179\n",
       "5              XGBoost  0.630749\n",
       "6             CatBoost  0.634691"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1: Scikit-learn's Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "# Model 2: Scikit-learn's Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "# Model 3: Scikit-learn's SVM\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "# Model 4: Scikit-learn's Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "# Model 5: Scikit-learn's Gradient Boosting\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(x_train, y_train)\n",
    "y_pred = gb.predict(x_test)\n",
    "\n",
    "# Model 6: Scikit-learn's XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred = xgb.predict(x_test)\n",
    "\n",
    "# Model 8: Scikit-learn's CatBoost\n",
    "cb = CatBoostClassifier()\n",
    "cb.fit(x_train, y_train)\n",
    "y_pred = cb.predict(x_test)\n",
    "\n",
    "# compute the accuracy of the models on the validation set in a dataframe\n",
    "models = ['Logistic Regression', 'Naive Bayes', 'SVM', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'CatBoost']\n",
    "accuracies = [accuracy_score(y_val, lr.predict(x_val)), accuracy_score(y_val, nb.predict(x_val)), accuracy_score(y_val, svm.predict(x_val)), accuracy_score(y_val, rf.predict(x_val)), accuracy_score(y_val, gb.predict(x_val)), accuracy_score(y_val, xgb.predict(x_val)), accuracy_score(y_val, cb.predict(x_val))]\n",
    "pd.DataFrame({'Model': models, 'Accuracy': accuracies})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.6426 for {'C': 0.001, 'penalty': 'none'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 0.001, 'penalty': 'l2'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 0.01, 'penalty': 'none'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 0.01, 'penalty': 'l2'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 0.1, 'penalty': 'none'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 0.1, 'penalty': 'l2'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 1, 'penalty': 'none'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 1, 'penalty': 'l2'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 10, 'penalty': 'none'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 10, 'penalty': 'l2'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 100, 'penalty': 'none'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 100, 'penalty': 'l2'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 1000, 'penalty': 'none'}\n",
      "Accuracy on validation set: 0.6426 for {'C': 1000, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# logistic regression grid search, computing accuracy on validation set without cross-validation\n",
    "lr = LogisticRegression()\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['none', 'l2']}\n",
    "for params in ParameterGrid(param_grid):\n",
    "    lr.set_params(**params)\n",
    "    lr.fit(x_train, y_train)\n",
    "    print('Accuracy on validation set: {:.4f} for {}'.format(accuracy_score(y_val, lr.predict(x_val)), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.6216 for {'alpha': 0.001}\n",
      "Accuracy on validation set: 0.6216 for {'alpha': 0.01}\n",
      "Accuracy on validation set: 0.6216 for {'alpha': 0.1}\n",
      "Accuracy on validation set: 0.6216 for {'alpha': 1}\n",
      "Accuracy on validation set: 0.6216 for {'alpha': 10}\n",
      "Accuracy on validation set: 0.6216 for {'alpha': 100}\n",
      "Accuracy on validation set: 0.6216 for {'alpha': 1000}\n"
     ]
    }
   ],
   "source": [
    "# naive bayes grid search, computing accuracy on validation set\n",
    "nb = MultinomialNB()    \n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "for params in ParameterGrid(param_grid):\n",
    "    nb.set_params(**params)\n",
    "    nb.fit(x_train, y_train)\n",
    "    print('Accuracy on validation set: {:.4f} for {}'.format(accuracy_score(y_val, nb.predict(x_val)), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.5703 for {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 0.001, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.5716 for {'learning_rate': 0.001, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.5795 for {'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5716 for {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5769 for {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.5900 for {'learning_rate': 0.01, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6005 for {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6202 for {'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.5834 for {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6005 for {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6242 for {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6347 for {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6268 for {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6531 for {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.5861 for {'learning_rate': 1, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6189 for {'learning_rate': 1, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6110 for {'learning_rate': 1, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6110 for {'learning_rate': 1, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6176 for {'learning_rate': 1, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6268 for {'learning_rate': 1, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 10, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 10, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 10, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 10, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 10, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 10, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.4967 for {'learning_rate': 100, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.4967 for {'learning_rate': 100, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.4967 for {'learning_rate': 100, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.4967 for {'learning_rate': 100, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.4967 for {'learning_rate': 100, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.4967 for {'learning_rate': 100, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.5177 for {'learning_rate': 1000, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5177 for {'learning_rate': 1000, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5177 for {'learning_rate': 1000, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.5177 for {'learning_rate': 1000, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.5177 for {'learning_rate': 1000, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.5177 for {'learning_rate': 1000, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting grid search, computing accuracy on validation set\n",
    "gb = GradientBoostingClassifier()\n",
    "param_grid = {'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'n_estimators': [10, 50, 100, 200, 500, 1000]}\n",
    "for params in ParameterGrid(param_grid):\n",
    "    gb.set_params(**params)\n",
    "    gb.fit(x_train, y_train)\n",
    "    print('Accuracy on validation set: {:.4f} for {}'.format(accuracy_score(y_val, gb.predict(x_val)), params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.5861 for {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5808 for {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5979 for {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6005 for {'learning_rate': 0.001, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.5940 for {'learning_rate': 0.001, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6137 for {'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.5926 for {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5940 for {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6124 for {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6163 for {'learning_rate': 0.01, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6426 for {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6413 for {'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.6071 for {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6373 for {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6334 for {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6386 for {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6373 for {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6439 for {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.6097 for {'learning_rate': 1, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6334 for {'learning_rate': 1, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6413 for {'learning_rate': 1, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6373 for {'learning_rate': 1, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6321 for {'learning_rate': 1, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6347 for {'learning_rate': 1, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 10, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 10, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 10, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 10, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 10, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.5703 for {'learning_rate': 10, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 100, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 100, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 100, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 100, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 100, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 100, 'n_estimators': 1000}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 1000, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 1000, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 1000, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 1000, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 1000, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.4297 for {'learning_rate': 1000, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# xgboost grid search, computing accuracy on validation set\n",
    "xgb = XGBClassifier()\n",
    "param_grid = {'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'n_estimators': [10, 50, 100, 200, 500, 1000]}\n",
    "for params in ParameterGrid(param_grid):\n",
    "    xgb.set_params(**params)\n",
    "    xgb.fit(x_train, y_train)\n",
    "    print('Accuracy on validation set: {:.4f} for {}'.format(accuracy_score(y_val, xgb.predict(x_val)), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.5703 for {'max_depth': 2, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5703 for {'max_depth': 2, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5742 for {'max_depth': 2, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.5729 for {'max_depth': 2, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.5729 for {'max_depth': 2, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.5769 for {'max_depth': 3, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5834 for {'max_depth': 3, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5834 for {'max_depth': 3, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.5848 for {'max_depth': 3, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.5887 for {'max_depth': 3, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.5874 for {'max_depth': 4, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.5874 for {'max_depth': 4, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5861 for {'max_depth': 4, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.5887 for {'max_depth': 4, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.5926 for {'max_depth': 4, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6124 for {'max_depth': 5, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6071 for {'max_depth': 5, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.5966 for {'max_depth': 5, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.5940 for {'max_depth': 5, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.5940 for {'max_depth': 5, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.5979 for {'max_depth': 6, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6163 for {'max_depth': 6, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6084 for {'max_depth': 6, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6045 for {'max_depth': 6, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6045 for {'max_depth': 6, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.5887 for {'max_depth': 7, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6242 for {'max_depth': 7, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6163 for {'max_depth': 7, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6150 for {'max_depth': 7, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6255 for {'max_depth': 7, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6176 for {'max_depth': 8, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6386 for {'max_depth': 8, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6255 for {'max_depth': 8, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6255 for {'max_depth': 8, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6294 for {'max_depth': 8, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6176 for {'max_depth': 9, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6163 for {'max_depth': 9, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6281 for {'max_depth': 9, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6281 for {'max_depth': 9, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6189 for {'max_depth': 9, 'n_estimators': 500}\n",
      "Accuracy on validation set: 0.6216 for {'max_depth': 10, 'n_estimators': 10}\n",
      "Accuracy on validation set: 0.6189 for {'max_depth': 10, 'n_estimators': 50}\n",
      "Accuracy on validation set: 0.6307 for {'max_depth': 10, 'n_estimators': 100}\n",
      "Accuracy on validation set: 0.6281 for {'max_depth': 10, 'n_estimators': 200}\n",
      "Accuracy on validation set: 0.6294 for {'max_depth': 10, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# random forest grid search, computing accuracy on validation set \n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {'n_estimators': [10, 50, 100, 200, 500], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "for params in ParameterGrid(param_grid):\n",
    "    rf.set_params(**params)\n",
    "    rf.fit(x_train, y_train)\n",
    "    print('Accuracy on validation set: {:.4f} for {}'.format(accuracy_score(y_val, rf.predict(x_val)), params))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the best built-in model seems to be the baseline random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.6562\n"
     ]
    }
   ],
   "source": [
    "# training the best built-in model on training and validation set and computing accuracy on test set\n",
    "# the best built-in model seems to be the baseline random forest classifier\n",
    "\n",
    "best_built_in_model = RandomForestClassifier()\n",
    "best_built_in_model.fit(np.concatenate((x_train, x_val)), np.concatenate((y_train, y_val)))\n",
    "print('Accuracy on test set: {:.4f}'.format(accuracy_score(y_test, best_built_in_model.predict(x_test))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "65.62 % is the best accuracy we reached on a built-in model, let's try out manual logistic regression models byy implementing log_loss gradient descent and manual naive bayes classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing manual naive bayes model\n",
    "\n",
    "# building frequency dictionary using train_df\n",
    "freqs = build_freqs(train_df['text'], train_df['target'])\n",
    "\n",
    "# computing log prior\n",
    "log_prior = np.log(len(train_df[train_df['target'] == 1]) / len(train_df[train_df['target'] == 0]))\n",
    "\n",
    "# computing log likelihood using laplace smoothing\n",
    "def compute_log_likelihood(freqs, word, label):\n",
    "    n = freqs.get((word, label), 0)\n",
    "    d = sum([freqs.get((word, label), 0) for label in [0, 1]])\n",
    "    return np.log((n + 1) / (d + 2))\n",
    "\n",
    "# computing log likelihood for each word in the vocabulary\n",
    "def compute_log_likelihoods(freqs):\n",
    "    log_likelihoods = {}\n",
    "    for word in freqs.keys():\n",
    "        log_likelihoods[word] = compute_log_likelihood(freqs, word[0], word[1])\n",
    "    return log_likelihoods\n",
    "\n",
    "log_likelihoods = compute_log_likelihoods(freqs)\n",
    "\n",
    "# implementing naive bayes classifier\n",
    "def naive_bayes_predict(tweet, log_prior, log_likelihoods):\n",
    "    word_l = process_tweet(tweet)\n",
    "    p = 0\n",
    "    p += log_prior\n",
    "    for word in word_l:\n",
    "        if (word, 1) in log_likelihoods:\n",
    "            p += log_likelihoods[(word, 1)]\n",
    "        if (word, 0) in log_likelihoods:\n",
    "            p -= log_likelihoods[(word, 0)]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.5716\n"
     ]
    }
   ],
   "source": [
    "# testing naive bayes classifier on validation set\n",
    "y_val_pred = []\n",
    "for tweet in val_df['text']:\n",
    "    if naive_bayes_predict(tweet, log_prior, log_likelihoods) > 0:\n",
    "        y_val_pred.append(1)\n",
    "    else:\n",
    "        y_val_pred.append(0)\n",
    "print('Accuracy on validation set: {:.4f}'.format(accuracy_score(val_df['target'], y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing manual batch gradient descent logistic regression model\n",
    "\n",
    "# implementing sigmoid function\n",
    "def sigmoid(z):\n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    return h\n",
    "\n",
    "def log_loss(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    cost = -(1 / m) * (np.dot(y.T, np.log(y_hat)) + np.dot((1 - y).T, np.log(1 - y_hat)))\n",
    "    return cost\n",
    "\n",
    "def batch_gradient_descent(x, y, alpha, learning_rate, num_iter):\n",
    "    m = x.shape[0]\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    theta = np.zeros((x.shape[1], 1))\n",
    "    for i in range(num_iter):\n",
    "        z = x @ alpha\n",
    "        h = sigmoid(z)\n",
    "        cost = log_loss(y, h)\n",
    "        gradient = (1 / m) * x.T @ np.subtract(h, y)\n",
    "        alpha = alpha - learning_rate * gradient\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.76413793e-01],\n",
       "       [ 5.13691514e+03],\n",
       "       [-4.86944262e+03]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model and getting the optimal alpha\n",
    "alpha = np.zeros((x_train.shape[1], 1))\n",
    "learning_rate = 0.01\n",
    "num_iter = 1000\n",
    "optimal_alpha = batch_gradient_descent(x_train, y_train, alpha, learning_rate, num_iter)\n",
    "optimal_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5703022339027596"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting on validation set\n",
    "pre_results = sigmoid(x_val @ optimal_alpha)\n",
    "y_pred = np.where(pre_results > 0.5, 1, 0)\n",
    "\n",
    "# Computing accuracy\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.4297 for learning rate: 0.01 and number of iterations: 100\n",
      "Accuracy on validation set: 0.4297 for learning rate: 0.01 and number of iterations: 500\n",
      "Accuracy on validation set: 0.5703 for learning rate: 0.01 and number of iterations: 1000\n",
      "Accuracy on validation set: 0.4415 for learning rate: 0.01 and number of iterations: 5000\n",
      "Accuracy on validation set: 0.5151 for learning rate: 0.01 and number of iterations: 10000\n",
      "Accuracy on validation set: 0.4297 for learning rate: 0.05 and number of iterations: 100\n",
      "Accuracy on validation set: 0.4297 for learning rate: 0.05 and number of iterations: 500\n",
      "Accuracy on validation set: 0.5703 for learning rate: 0.05 and number of iterations: 1000\n",
      "Accuracy on validation set: 0.4415 for learning rate: 0.05 and number of iterations: 5000\n",
      "Accuracy on validation set: 0.5151 for learning rate: 0.05 and number of iterations: 10000\n",
      "Accuracy on validation set: 0.4297 for learning rate: 0.1 and number of iterations: 100\n",
      "Accuracy on validation set: 0.4297 for learning rate: 0.1 and number of iterations: 500\n",
      "Accuracy on validation set: 0.5703 for learning rate: 0.1 and number of iterations: 1000\n",
      "Accuracy on validation set: 0.4415 for learning rate: 0.1 and number of iterations: 5000\n",
      "Accuracy on validation set: 0.5151 for learning rate: 0.1 and number of iterations: 10000\n",
      "Accuracy on validation set: 0.4297 for learning rate: 0.5 and number of iterations: 100\n",
      "Accuracy on validation set: 0.4297 for learning rate: 0.5 and number of iterations: 500\n",
      "Accuracy on validation set: 0.5703 for learning rate: 0.5 and number of iterations: 1000\n",
      "Accuracy on validation set: 0.4415 for learning rate: 0.5 and number of iterations: 5000\n",
      "Accuracy on validation set: 0.5151 for learning rate: 0.5 and number of iterations: 10000\n",
      "Accuracy on validation set: 0.4297 for learning rate: 1 and number of iterations: 100\n",
      "Accuracy on validation set: 0.4297 for learning rate: 1 and number of iterations: 500\n",
      "Accuracy on validation set: 0.5703 for learning rate: 1 and number of iterations: 1000\n",
      "Accuracy on validation set: 0.4415 for learning rate: 1 and number of iterations: 5000\n",
      "Accuracy on validation set: 0.5151 for learning rate: 1 and number of iterations: 10000\n"
     ]
    }
   ],
   "source": [
    "# running grid search on learning rate and number of iterations\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "num_iters = [100, 500, 1000, 5000, 10000]\n",
    "for learning_rate in learning_rates:\n",
    "    for num_iter in num_iters:\n",
    "        alpha = np.zeros((x_train.shape[1], 1))\n",
    "        optimal_alpha = batch_gradient_descent(x_train, y_train, alpha, learning_rate, num_iter)\n",
    "        pre_results = sigmoid(x_val @ optimal_alpha)\n",
    "        y_pred = np.where(pre_results > 0.5, 1, 0)\n",
    "        print('Accuracy on validation set: {:.4f} for learning rate: {} and number of iterations: {}'.format(accuracy_score(y_val, y_pred), learning_rate, num_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5709\n"
     ]
    }
   ],
   "source": [
    "# training naive bayes model on training and validation set and computing accuracy on test set\n",
    "y_test_pred = []\n",
    "for tweet in test_df['text']:\n",
    "    if naive_bayes_predict(tweet, log_prior, log_likelihoods) > 0:\n",
    "        y_test_pred.append(1)\n",
    "    else:\n",
    "        y_test_pred.append(0)\n",
    "print('Accuracy on test set: {:.4f}'.format(accuracy_score(test_df['target'], y_test_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural network softmax regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6234    1\n",
       "326     0\n",
       "997     0\n",
       "7269    0\n",
       "2189    1\n",
       "       ..\n",
       "3386    1\n",
       "3280    1\n",
       "305     0\n",
       "1648    0\n",
       "7569    0\n",
       "Name: target, Length: 6090, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "191/191 [==============================] - 1s 2ms/step - loss: 1906.7773 - accuracy: 0.5194 - val_loss: 589.0330 - val_accuracy: 0.5637\n",
      "Epoch 2/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 506.5526 - accuracy: 0.5545 - val_loss: 293.0824 - val_accuracy: 0.4993\n",
      "Epoch 3/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 551.8194 - accuracy: 0.5371 - val_loss: 367.0710 - val_accuracy: 0.4691\n",
      "Epoch 4/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 532.2523 - accuracy: 0.5437 - val_loss: 793.6818 - val_accuracy: 0.5716\n",
      "Epoch 5/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 561.4923 - accuracy: 0.5323 - val_loss: 178.2969 - val_accuracy: 0.6360\n",
      "Epoch 6/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 646.3076 - accuracy: 0.5397 - val_loss: 979.0084 - val_accuracy: 0.5703\n",
      "Epoch 7/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 547.0388 - accuracy: 0.5458 - val_loss: 865.9180 - val_accuracy: 0.5703\n",
      "Epoch 8/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 700.1816 - accuracy: 0.5353 - val_loss: 697.2062 - val_accuracy: 0.5716\n",
      "Epoch 9/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 589.9191 - accuracy: 0.5494 - val_loss: 141.3336 - val_accuracy: 0.6465\n",
      "Epoch 10/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 743.3292 - accuracy: 0.5345 - val_loss: 534.8472 - val_accuracy: 0.4481\n",
      "Epoch 11/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 818.6498 - accuracy: 0.5238 - val_loss: 905.3594 - val_accuracy: 0.4323\n",
      "Epoch 12/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 632.6205 - accuracy: 0.5478 - val_loss: 591.7183 - val_accuracy: 0.5690\n",
      "Epoch 13/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 611.3372 - accuracy: 0.5394 - val_loss: 1627.8014 - val_accuracy: 0.5703\n",
      "Epoch 14/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 539.4871 - accuracy: 0.5286 - val_loss: 535.7982 - val_accuracy: 0.5690\n",
      "Epoch 15/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 736.5578 - accuracy: 0.5215 - val_loss: 780.7842 - val_accuracy: 0.4336\n",
      "Epoch 16/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 567.7891 - accuracy: 0.5456 - val_loss: 227.9654 - val_accuracy: 0.5821\n",
      "Epoch 17/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 522.9728 - accuracy: 0.5327 - val_loss: 852.2430 - val_accuracy: 0.5703\n",
      "Epoch 18/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 544.7598 - accuracy: 0.5422 - val_loss: 686.9672 - val_accuracy: 0.5716\n",
      "Epoch 19/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 637.6984 - accuracy: 0.5415 - val_loss: 1279.9750 - val_accuracy: 0.4297\n",
      "Epoch 20/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 374.6728 - accuracy: 0.5448 - val_loss: 143.4446 - val_accuracy: 0.6124\n",
      "Epoch 21/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 453.3419 - accuracy: 0.5351 - val_loss: 415.0120 - val_accuracy: 0.4481\n",
      "Epoch 22/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 497.6750 - accuracy: 0.5248 - val_loss: 106.2687 - val_accuracy: 0.5913\n",
      "Epoch 23/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 900.3417 - accuracy: 0.5141 - val_loss: 355.7830 - val_accuracy: 0.5664\n",
      "Epoch 24/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 646.9321 - accuracy: 0.5438 - val_loss: 811.9800 - val_accuracy: 0.4323\n",
      "Epoch 25/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 683.5208 - accuracy: 0.5355 - val_loss: 264.1306 - val_accuracy: 0.4678\n",
      "Epoch 26/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 617.0653 - accuracy: 0.5250 - val_loss: 196.4908 - val_accuracy: 0.5007\n",
      "Epoch 27/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 520.7421 - accuracy: 0.5415 - val_loss: 107.9865 - val_accuracy: 0.6150\n",
      "Epoch 28/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 566.4531 - accuracy: 0.5388 - val_loss: 1320.6195 - val_accuracy: 0.5703\n",
      "Epoch 29/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 892.6662 - accuracy: 0.5131 - val_loss: 167.3457 - val_accuracy: 0.6124\n",
      "Epoch 30/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 613.2576 - accuracy: 0.5340 - val_loss: 1664.2694 - val_accuracy: 0.5703\n",
      "Epoch 31/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 877.6680 - accuracy: 0.5273 - val_loss: 3114.0906 - val_accuracy: 0.5703\n",
      "Epoch 32/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 643.2352 - accuracy: 0.5345 - val_loss: 110.7024 - val_accuracy: 0.6426\n",
      "Epoch 33/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 594.7990 - accuracy: 0.5361 - val_loss: 1233.9822 - val_accuracy: 0.4297\n",
      "Epoch 34/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 589.4300 - accuracy: 0.5368 - val_loss: 586.1155 - val_accuracy: 0.5690\n",
      "Epoch 35/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 408.3144 - accuracy: 0.5530 - val_loss: 112.1682 - val_accuracy: 0.6478\n",
      "Epoch 36/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 552.5261 - accuracy: 0.5300 - val_loss: 143.6541 - val_accuracy: 0.5795\n",
      "Epoch 37/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 398.5984 - accuracy: 0.5524 - val_loss: 113.6687 - val_accuracy: 0.6452\n",
      "Epoch 38/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 493.6427 - accuracy: 0.5304 - val_loss: 860.6589 - val_accuracy: 0.4323\n",
      "Epoch 39/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 564.5339 - accuracy: 0.5468 - val_loss: 285.6392 - val_accuracy: 0.4717\n",
      "Epoch 40/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 640.1050 - accuracy: 0.5422 - val_loss: 111.5527 - val_accuracy: 0.6465\n",
      "Epoch 41/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 314.6422 - accuracy: 0.5547 - val_loss: 194.0217 - val_accuracy: 0.5283\n",
      "Epoch 42/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 639.0899 - accuracy: 0.5323 - val_loss: 1631.1936 - val_accuracy: 0.4297\n",
      "Epoch 43/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 806.9398 - accuracy: 0.5200 - val_loss: 582.0263 - val_accuracy: 0.4363\n",
      "Epoch 44/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 458.1585 - accuracy: 0.5565 - val_loss: 175.6068 - val_accuracy: 0.6202\n",
      "Epoch 45/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 449.0884 - accuracy: 0.5583 - val_loss: 233.9292 - val_accuracy: 0.4993\n",
      "Epoch 46/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 608.1196 - accuracy: 0.5411 - val_loss: 177.9376 - val_accuracy: 0.6124\n",
      "Epoch 47/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 443.1107 - accuracy: 0.5452 - val_loss: 165.4733 - val_accuracy: 0.6294\n",
      "Epoch 48/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 381.5882 - accuracy: 0.5586 - val_loss: 764.1186 - val_accuracy: 0.4323\n",
      "Epoch 49/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 481.6151 - accuracy: 0.5484 - val_loss: 546.3641 - val_accuracy: 0.5690\n",
      "Epoch 50/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 772.2673 - accuracy: 0.5264 - val_loss: 382.2808 - val_accuracy: 0.4468\n",
      "Epoch 51/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 341.2939 - accuracy: 0.5545 - val_loss: 283.3693 - val_accuracy: 0.4717\n",
      "Epoch 52/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 336.2785 - accuracy: 0.5506 - val_loss: 106.4639 - val_accuracy: 0.6255\n",
      "Epoch 53/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 493.0607 - accuracy: 0.5391 - val_loss: 299.9493 - val_accuracy: 0.5769\n",
      "Epoch 54/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 411.8225 - accuracy: 0.5573 - val_loss: 185.1933 - val_accuracy: 0.5283\n",
      "Epoch 55/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 424.5889 - accuracy: 0.5386 - val_loss: 593.7092 - val_accuracy: 0.5703\n",
      "Epoch 56/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 379.5085 - accuracy: 0.5468 - val_loss: 346.0590 - val_accuracy: 0.5664\n",
      "Epoch 57/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 636.3997 - accuracy: 0.5356 - val_loss: 716.5643 - val_accuracy: 0.4323\n",
      "Epoch 58/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 380.7648 - accuracy: 0.5511 - val_loss: 547.1282 - val_accuracy: 0.4363\n",
      "Epoch 59/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 501.7488 - accuracy: 0.5378 - val_loss: 156.5408 - val_accuracy: 0.5572\n",
      "Epoch 60/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 515.5529 - accuracy: 0.5424 - val_loss: 124.0532 - val_accuracy: 0.6491\n",
      "Epoch 61/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 348.0044 - accuracy: 0.5455 - val_loss: 391.2966 - val_accuracy: 0.4520\n",
      "Epoch 62/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 534.6360 - accuracy: 0.5355 - val_loss: 824.4836 - val_accuracy: 0.5703\n",
      "Epoch 63/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 380.1428 - accuracy: 0.5466 - val_loss: 359.5709 - val_accuracy: 0.4494\n",
      "Epoch 64/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 1000.1393 - accuracy: 0.5177 - val_loss: 326.1223 - val_accuracy: 0.4520\n",
      "Epoch 65/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 394.0048 - accuracy: 0.5476 - val_loss: 433.1268 - val_accuracy: 0.5664\n",
      "Epoch 66/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 758.9539 - accuracy: 0.5338 - val_loss: 304.7544 - val_accuracy: 0.5729\n",
      "Epoch 67/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 348.9692 - accuracy: 0.5548 - val_loss: 548.7872 - val_accuracy: 0.4363\n",
      "Epoch 68/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 683.5679 - accuracy: 0.5435 - val_loss: 720.1511 - val_accuracy: 0.5716\n",
      "Epoch 69/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 322.7095 - accuracy: 0.5596 - val_loss: 1049.6906 - val_accuracy: 0.5703\n",
      "Epoch 70/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 630.0374 - accuracy: 0.5171 - val_loss: 623.4497 - val_accuracy: 0.4336\n",
      "Epoch 71/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 353.1314 - accuracy: 0.5571 - val_loss: 668.3323 - val_accuracy: 0.5703\n",
      "Epoch 72/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 345.6598 - accuracy: 0.5479 - val_loss: 161.5233 - val_accuracy: 0.6216\n",
      "Epoch 73/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 597.1625 - accuracy: 0.5365 - val_loss: 510.8387 - val_accuracy: 0.5690\n",
      "Epoch 74/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 619.5157 - accuracy: 0.5325 - val_loss: 533.9504 - val_accuracy: 0.5677\n",
      "Epoch 75/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 320.0111 - accuracy: 0.5652 - val_loss: 113.4641 - val_accuracy: 0.6110\n",
      "Epoch 76/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 414.3028 - accuracy: 0.5499 - val_loss: 379.1479 - val_accuracy: 0.4507\n",
      "Epoch 77/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 533.1708 - accuracy: 0.5304 - val_loss: 174.6170 - val_accuracy: 0.6110\n",
      "Epoch 78/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 410.6112 - accuracy: 0.5461 - val_loss: 477.2301 - val_accuracy: 0.4415\n",
      "Epoch 79/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 331.5741 - accuracy: 0.5488 - val_loss: 99.8597 - val_accuracy: 0.6478\n",
      "Epoch 80/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 421.3230 - accuracy: 0.5471 - val_loss: 124.6246 - val_accuracy: 0.6426\n",
      "Epoch 81/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 430.0255 - accuracy: 0.5445 - val_loss: 408.7145 - val_accuracy: 0.5650\n",
      "Epoch 82/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 485.6713 - accuracy: 0.5402 - val_loss: 776.8470 - val_accuracy: 0.5716\n",
      "Epoch 83/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 472.1916 - accuracy: 0.5432 - val_loss: 312.5996 - val_accuracy: 0.4520\n",
      "Epoch 84/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 541.6298 - accuracy: 0.5337 - val_loss: 1228.1466 - val_accuracy: 0.4297\n",
      "Epoch 85/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 460.0011 - accuracy: 0.5598 - val_loss: 116.6989 - val_accuracy: 0.6032\n",
      "Epoch 86/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 257.7640 - accuracy: 0.5608 - val_loss: 475.4268 - val_accuracy: 0.5690\n",
      "Epoch 87/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 275.4203 - accuracy: 0.5498 - val_loss: 125.4174 - val_accuracy: 0.5716\n",
      "Epoch 88/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 532.7270 - accuracy: 0.5322 - val_loss: 672.6492 - val_accuracy: 0.4323\n",
      "Epoch 89/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 354.5697 - accuracy: 0.5563 - val_loss: 1449.6427 - val_accuracy: 0.5703\n",
      "Epoch 90/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 586.0878 - accuracy: 0.5240 - val_loss: 670.2019 - val_accuracy: 0.5716\n",
      "Epoch 91/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 325.2434 - accuracy: 0.5575 - val_loss: 539.5192 - val_accuracy: 0.5703\n",
      "Epoch 92/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 401.3592 - accuracy: 0.5507 - val_loss: 196.1279 - val_accuracy: 0.4980\n",
      "Epoch 93/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 428.2302 - accuracy: 0.5417 - val_loss: 933.7227 - val_accuracy: 0.4310\n",
      "Epoch 94/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 627.3586 - accuracy: 0.5340 - val_loss: 595.7620 - val_accuracy: 0.4336\n",
      "Epoch 95/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 379.8476 - accuracy: 0.5404 - val_loss: 436.9308 - val_accuracy: 0.5677\n",
      "Epoch 96/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 407.4552 - accuracy: 0.5637 - val_loss: 652.5100 - val_accuracy: 0.4323\n",
      "Epoch 97/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 439.0475 - accuracy: 0.5345 - val_loss: 389.4342 - val_accuracy: 0.4507\n",
      "Epoch 98/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 415.2033 - accuracy: 0.5345 - val_loss: 201.2314 - val_accuracy: 0.5874\n",
      "Epoch 99/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 384.2331 - accuracy: 0.5415 - val_loss: 898.2165 - val_accuracy: 0.5703\n",
      "Epoch 100/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 474.0264 - accuracy: 0.5535 - val_loss: 478.9956 - val_accuracy: 0.4376\n",
      "Epoch 101/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 520.7955 - accuracy: 0.5401 - val_loss: 97.4275 - val_accuracy: 0.6268\n",
      "Epoch 102/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 481.0295 - accuracy: 0.5438 - val_loss: 328.7036 - val_accuracy: 0.5664\n",
      "Epoch 103/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 483.7941 - accuracy: 0.5394 - val_loss: 735.2386 - val_accuracy: 0.5716\n",
      "Epoch 104/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 314.5255 - accuracy: 0.5567 - val_loss: 96.9118 - val_accuracy: 0.6452\n",
      "Epoch 105/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 354.5962 - accuracy: 0.5463 - val_loss: 390.5392 - val_accuracy: 0.5650\n",
      "Epoch 106/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 267.4335 - accuracy: 0.5567 - val_loss: 841.6273 - val_accuracy: 0.5703\n",
      "Epoch 107/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 310.5934 - accuracy: 0.5665 - val_loss: 255.5856 - val_accuracy: 0.5795\n",
      "Epoch 108/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 327.6271 - accuracy: 0.5516 - val_loss: 109.1784 - val_accuracy: 0.5913\n",
      "Epoch 109/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 516.0489 - accuracy: 0.5458 - val_loss: 958.9915 - val_accuracy: 0.5703\n",
      "Epoch 110/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 447.7792 - accuracy: 0.5374 - val_loss: 586.8602 - val_accuracy: 0.4323\n",
      "Epoch 111/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 558.3048 - accuracy: 0.5253 - val_loss: 585.8114 - val_accuracy: 0.4336\n",
      "Epoch 112/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 335.1940 - accuracy: 0.5461 - val_loss: 435.1281 - val_accuracy: 0.5690\n",
      "Epoch 113/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 373.8646 - accuracy: 0.5519 - val_loss: 196.9320 - val_accuracy: 0.4980\n",
      "Epoch 114/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 376.0435 - accuracy: 0.5438 - val_loss: 97.0064 - val_accuracy: 0.6452\n",
      "Epoch 115/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 603.9066 - accuracy: 0.5351 - val_loss: 219.5683 - val_accuracy: 0.4796\n",
      "Epoch 116/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 567.8382 - accuracy: 0.5478 - val_loss: 922.3511 - val_accuracy: 0.5703\n",
      "Epoch 117/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 320.9257 - accuracy: 0.5483 - val_loss: 141.3773 - val_accuracy: 0.5545\n",
      "Epoch 118/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 462.5327 - accuracy: 0.5445 - val_loss: 259.8234 - val_accuracy: 0.4625\n",
      "Epoch 119/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 299.3573 - accuracy: 0.5516 - val_loss: 192.2543 - val_accuracy: 0.4980\n",
      "Epoch 120/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 352.2675 - accuracy: 0.5601 - val_loss: 565.5022 - val_accuracy: 0.5703\n",
      "Epoch 121/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 573.9575 - accuracy: 0.5291 - val_loss: 182.9156 - val_accuracy: 0.4993\n",
      "Epoch 122/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 350.1290 - accuracy: 0.5442 - val_loss: 192.1385 - val_accuracy: 0.4980\n",
      "Epoch 123/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 497.1469 - accuracy: 0.5294 - val_loss: 2159.2686 - val_accuracy: 0.4297\n",
      "Epoch 124/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 615.0769 - accuracy: 0.5350 - val_loss: 479.9163 - val_accuracy: 0.4376\n",
      "Epoch 125/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 384.9066 - accuracy: 0.5545 - val_loss: 634.8596 - val_accuracy: 0.5716\n",
      "Epoch 126/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 315.0419 - accuracy: 0.5532 - val_loss: 114.2600 - val_accuracy: 0.5821\n",
      "Epoch 127/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 579.7829 - accuracy: 0.5263 - val_loss: 115.9473 - val_accuracy: 0.6439\n",
      "Epoch 128/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 548.3242 - accuracy: 0.5258 - val_loss: 297.6777 - val_accuracy: 0.4520\n",
      "Epoch 129/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 254.2200 - accuracy: 0.5657 - val_loss: 786.5576 - val_accuracy: 0.4323\n",
      "Epoch 130/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 543.0723 - accuracy: 0.5381 - val_loss: 189.1894 - val_accuracy: 0.5887\n",
      "Epoch 131/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 655.9947 - accuracy: 0.5195 - val_loss: 398.8595 - val_accuracy: 0.5664\n",
      "Epoch 132/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 306.8113 - accuracy: 0.5440 - val_loss: 138.5316 - val_accuracy: 0.6307\n",
      "Epoch 133/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 348.5382 - accuracy: 0.5369 - val_loss: 277.7085 - val_accuracy: 0.4573\n",
      "Epoch 134/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 251.0800 - accuracy: 0.5589 - val_loss: 121.2530 - val_accuracy: 0.6360\n",
      "Epoch 135/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 360.6064 - accuracy: 0.5455 - val_loss: 432.5438 - val_accuracy: 0.4442\n",
      "Epoch 136/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 452.2048 - accuracy: 0.5299 - val_loss: 726.1702 - val_accuracy: 0.5703\n",
      "Epoch 137/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 389.3541 - accuracy: 0.5366 - val_loss: 100.5061 - val_accuracy: 0.6465\n",
      "Epoch 138/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 434.7826 - accuracy: 0.5483 - val_loss: 97.4946 - val_accuracy: 0.6452\n",
      "Epoch 139/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 333.6006 - accuracy: 0.5425 - val_loss: 100.5979 - val_accuracy: 0.6478\n",
      "Epoch 140/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 457.9561 - accuracy: 0.5415 - val_loss: 151.5860 - val_accuracy: 0.6137\n",
      "Epoch 141/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 304.8402 - accuracy: 0.5568 - val_loss: 216.5492 - val_accuracy: 0.5874\n",
      "Epoch 142/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 421.1901 - accuracy: 0.5373 - val_loss: 569.4362 - val_accuracy: 0.5703\n",
      "Epoch 143/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 279.6084 - accuracy: 0.5596 - val_loss: 92.7363 - val_accuracy: 0.6465\n",
      "Epoch 144/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 351.1310 - accuracy: 0.5456 - val_loss: 355.3937 - val_accuracy: 0.4520\n",
      "Epoch 145/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 355.4973 - accuracy: 0.5343 - val_loss: 662.8450 - val_accuracy: 0.4323\n",
      "Epoch 146/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 277.6960 - accuracy: 0.5537 - val_loss: 334.6623 - val_accuracy: 0.5650\n",
      "Epoch 147/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 480.8282 - accuracy: 0.5498 - val_loss: 1796.8219 - val_accuracy: 0.5703\n",
      "Epoch 148/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 429.8864 - accuracy: 0.5568 - val_loss: 309.0533 - val_accuracy: 0.4468\n",
      "Epoch 149/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 338.8189 - accuracy: 0.5452 - val_loss: 628.8083 - val_accuracy: 0.5716\n",
      "Epoch 150/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 389.6146 - accuracy: 0.5366 - val_loss: 462.8831 - val_accuracy: 0.4376\n",
      "Epoch 151/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 412.4989 - accuracy: 0.5443 - val_loss: 528.7776 - val_accuracy: 0.4336\n",
      "Epoch 152/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 383.7136 - accuracy: 0.5433 - val_loss: 1264.4336 - val_accuracy: 0.5703\n",
      "Epoch 153/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 377.3109 - accuracy: 0.5483 - val_loss: 110.5853 - val_accuracy: 0.6465\n",
      "Epoch 154/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 471.7768 - accuracy: 0.5409 - val_loss: 506.9678 - val_accuracy: 0.5703\n",
      "Epoch 155/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 295.2918 - accuracy: 0.5612 - val_loss: 183.3655 - val_accuracy: 0.5900\n",
      "Epoch 156/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 327.4388 - accuracy: 0.5443 - val_loss: 348.5905 - val_accuracy: 0.5650\n",
      "Epoch 157/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 621.8455 - accuracy: 0.5433 - val_loss: 607.2219 - val_accuracy: 0.4323\n",
      "Epoch 158/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 569.5818 - accuracy: 0.5314 - val_loss: 130.8530 - val_accuracy: 0.5664\n",
      "Epoch 159/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 416.3027 - accuracy: 0.5420 - val_loss: 442.3858 - val_accuracy: 0.5690\n",
      "Epoch 160/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 452.8543 - accuracy: 0.5232 - val_loss: 582.4550 - val_accuracy: 0.4336\n",
      "Epoch 161/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 331.4911 - accuracy: 0.5552 - val_loss: 241.5253 - val_accuracy: 0.5795\n",
      "Epoch 162/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 210.5339 - accuracy: 0.5736 - val_loss: 99.3641 - val_accuracy: 0.5979\n",
      "Epoch 163/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 314.5863 - accuracy: 0.5586 - val_loss: 2279.6543 - val_accuracy: 0.4297\n",
      "Epoch 164/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 546.9152 - accuracy: 0.5458 - val_loss: 110.3111 - val_accuracy: 0.6347\n",
      "Epoch 165/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 439.0933 - accuracy: 0.5345 - val_loss: 88.2074 - val_accuracy: 0.6084\n",
      "Epoch 166/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 277.7225 - accuracy: 0.5445 - val_loss: 96.0112 - val_accuracy: 0.6491\n",
      "Epoch 167/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 442.1920 - accuracy: 0.5351 - val_loss: 641.2353 - val_accuracy: 0.5703\n",
      "Epoch 168/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 361.9177 - accuracy: 0.5475 - val_loss: 303.9673 - val_accuracy: 0.5650\n",
      "Epoch 169/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 364.5158 - accuracy: 0.5433 - val_loss: 101.6593 - val_accuracy: 0.5874\n",
      "Epoch 170/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 304.6427 - accuracy: 0.5507 - val_loss: 308.8001 - val_accuracy: 0.5677\n",
      "Epoch 171/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 500.8875 - accuracy: 0.5424 - val_loss: 417.5953 - val_accuracy: 0.5690\n",
      "Epoch 172/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 253.3884 - accuracy: 0.5631 - val_loss: 113.7985 - val_accuracy: 0.5677\n",
      "Epoch 173/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 429.1677 - accuracy: 0.5310 - val_loss: 909.0007 - val_accuracy: 0.4297\n",
      "Epoch 174/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 562.5986 - accuracy: 0.5120 - val_loss: 631.5683 - val_accuracy: 0.4323\n",
      "Epoch 175/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 444.8651 - accuracy: 0.5248 - val_loss: 698.0839 - val_accuracy: 0.4323\n",
      "Epoch 176/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 415.2504 - accuracy: 0.5484 - val_loss: 380.1325 - val_accuracy: 0.4455\n",
      "Epoch 177/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 325.7988 - accuracy: 0.5504 - val_loss: 494.9261 - val_accuracy: 0.4336\n",
      "Epoch 178/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 341.9348 - accuracy: 0.5532 - val_loss: 125.8755 - val_accuracy: 0.5545\n",
      "Epoch 179/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 309.6441 - accuracy: 0.5637 - val_loss: 820.3567 - val_accuracy: 0.4310\n",
      "Epoch 180/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 389.2965 - accuracy: 0.5425 - val_loss: 196.4238 - val_accuracy: 0.5834\n",
      "Epoch 181/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 474.3852 - accuracy: 0.5381 - val_loss: 444.4652 - val_accuracy: 0.5690\n",
      "Epoch 182/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 451.7318 - accuracy: 0.5310 - val_loss: 328.6370 - val_accuracy: 0.5650\n",
      "Epoch 183/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 451.1761 - accuracy: 0.5407 - val_loss: 1204.2313 - val_accuracy: 0.5703\n",
      "Epoch 184/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 349.1453 - accuracy: 0.5567 - val_loss: 1035.4309 - val_accuracy: 0.5703\n",
      "Epoch 185/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 311.0382 - accuracy: 0.5468 - val_loss: 494.5135 - val_accuracy: 0.5703\n",
      "Epoch 186/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 399.5679 - accuracy: 0.5369 - val_loss: 550.4135 - val_accuracy: 0.4323\n",
      "Epoch 187/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 241.3589 - accuracy: 0.5530 - val_loss: 567.2418 - val_accuracy: 0.5716\n",
      "Epoch 188/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 415.3799 - accuracy: 0.5246 - val_loss: 261.0999 - val_accuracy: 0.5690\n",
      "Epoch 189/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 428.2190 - accuracy: 0.5422 - val_loss: 958.2106 - val_accuracy: 0.4297\n",
      "Epoch 190/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 333.5009 - accuracy: 0.5542 - val_loss: 254.6018 - val_accuracy: 0.5690\n",
      "Epoch 191/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 289.3762 - accuracy: 0.5578 - val_loss: 691.5425 - val_accuracy: 0.4323\n",
      "Epoch 192/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 272.6578 - accuracy: 0.5517 - val_loss: 360.6221 - val_accuracy: 0.4428\n",
      "Epoch 193/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 284.1744 - accuracy: 0.5455 - val_loss: 120.0262 - val_accuracy: 0.5493\n",
      "Epoch 194/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 309.9373 - accuracy: 0.5599 - val_loss: 1287.3228 - val_accuracy: 0.4297\n",
      "Epoch 195/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 471.8444 - accuracy: 0.5263 - val_loss: 439.5374 - val_accuracy: 0.5703\n",
      "Epoch 196/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 345.2826 - accuracy: 0.5539 - val_loss: 630.2864 - val_accuracy: 0.4323\n",
      "Epoch 197/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 296.2710 - accuracy: 0.5438 - val_loss: 451.7435 - val_accuracy: 0.5703\n",
      "Epoch 198/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 456.9473 - accuracy: 0.5300 - val_loss: 501.0847 - val_accuracy: 0.5716\n",
      "Epoch 199/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 305.8571 - accuracy: 0.5456 - val_loss: 76.2111 - val_accuracy: 0.6294\n",
      "Epoch 200/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 240.1641 - accuracy: 0.5562 - val_loss: 112.1637 - val_accuracy: 0.6294\n",
      "Epoch 201/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 262.8565 - accuracy: 0.5529 - val_loss: 72.3518 - val_accuracy: 0.6505\n",
      "Epoch 202/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 331.8865 - accuracy: 0.5396 - val_loss: 214.9106 - val_accuracy: 0.5703\n",
      "Epoch 203/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 355.6782 - accuracy: 0.5373 - val_loss: 286.0995 - val_accuracy: 0.4520\n",
      "Epoch 204/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 223.8817 - accuracy: 0.5471 - val_loss: 1002.4869 - val_accuracy: 0.4297\n",
      "Epoch 205/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 274.0581 - accuracy: 0.5484 - val_loss: 129.7282 - val_accuracy: 0.5191\n",
      "Epoch 206/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 467.4279 - accuracy: 0.5250 - val_loss: 314.0097 - val_accuracy: 0.5677\n",
      "Epoch 207/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 267.8878 - accuracy: 0.5419 - val_loss: 404.4143 - val_accuracy: 0.5703\n",
      "Epoch 208/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 440.4005 - accuracy: 0.5356 - val_loss: 135.3267 - val_accuracy: 0.5191\n",
      "Epoch 209/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 289.7563 - accuracy: 0.5499 - val_loss: 1282.1658 - val_accuracy: 0.5703\n",
      "Epoch 210/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 271.9412 - accuracy: 0.5514 - val_loss: 311.8965 - val_accuracy: 0.5677\n",
      "Epoch 211/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 489.5788 - accuracy: 0.5461 - val_loss: 363.0904 - val_accuracy: 0.4415\n",
      "Epoch 212/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 226.4496 - accuracy: 0.5509 - val_loss: 80.1368 - val_accuracy: 0.6137\n",
      "Epoch 213/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 472.9636 - accuracy: 0.5315 - val_loss: 103.8575 - val_accuracy: 0.5690\n",
      "Epoch 214/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 307.7702 - accuracy: 0.5292 - val_loss: 570.6746 - val_accuracy: 0.4323\n",
      "Epoch 215/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 251.6065 - accuracy: 0.5611 - val_loss: 76.2570 - val_accuracy: 0.6505\n",
      "Epoch 216/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 191.5152 - accuracy: 0.5576 - val_loss: 96.6286 - val_accuracy: 0.5690\n",
      "Epoch 217/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 356.0855 - accuracy: 0.5365 - val_loss: 762.1631 - val_accuracy: 0.5703\n",
      "Epoch 218/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 329.3173 - accuracy: 0.5453 - val_loss: 142.7636 - val_accuracy: 0.5953\n",
      "Epoch 219/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 289.7509 - accuracy: 0.5529 - val_loss: 820.5558 - val_accuracy: 0.4297\n",
      "Epoch 220/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 284.5853 - accuracy: 0.5314 - val_loss: 121.3606 - val_accuracy: 0.5388\n",
      "Epoch 221/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 222.3589 - accuracy: 0.5535 - val_loss: 438.1391 - val_accuracy: 0.4336\n",
      "Epoch 222/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 214.4376 - accuracy: 0.5640 - val_loss: 376.7627 - val_accuracy: 0.4350\n",
      "Epoch 223/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 323.0494 - accuracy: 0.5440 - val_loss: 464.9571 - val_accuracy: 0.4323\n",
      "Epoch 224/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 553.4976 - accuracy: 0.5161 - val_loss: 828.5430 - val_accuracy: 0.5703\n",
      "Epoch 225/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 313.3516 - accuracy: 0.5335 - val_loss: 144.4500 - val_accuracy: 0.5007\n",
      "Epoch 226/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 291.8923 - accuracy: 0.5478 - val_loss: 409.9895 - val_accuracy: 0.4336\n",
      "Epoch 227/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 337.7875 - accuracy: 0.5429 - val_loss: 741.0023 - val_accuracy: 0.4323\n",
      "Epoch 228/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 226.6711 - accuracy: 0.5512 - val_loss: 569.0516 - val_accuracy: 0.5703\n",
      "Epoch 229/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 350.5359 - accuracy: 0.5558 - val_loss: 592.3785 - val_accuracy: 0.5703\n",
      "Epoch 230/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 346.8262 - accuracy: 0.5328 - val_loss: 221.6999 - val_accuracy: 0.5703\n",
      "Epoch 231/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 236.6044 - accuracy: 0.5654 - val_loss: 230.0069 - val_accuracy: 0.4560\n",
      "Epoch 232/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 378.6831 - accuracy: 0.5461 - val_loss: 95.2786 - val_accuracy: 0.6373\n",
      "Epoch 233/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 239.7380 - accuracy: 0.5522 - val_loss: 221.4983 - val_accuracy: 0.5690\n",
      "Epoch 234/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 301.2326 - accuracy: 0.5540 - val_loss: 89.5658 - val_accuracy: 0.5716\n",
      "Epoch 235/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 431.3731 - accuracy: 0.5415 - val_loss: 116.6926 - val_accuracy: 0.5361\n",
      "Epoch 236/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 233.7584 - accuracy: 0.5680 - val_loss: 294.1829 - val_accuracy: 0.5690\n",
      "Epoch 237/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 456.2944 - accuracy: 0.5276 - val_loss: 82.9583 - val_accuracy: 0.6505\n",
      "Epoch 238/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 207.3989 - accuracy: 0.5544 - val_loss: 595.9781 - val_accuracy: 0.4323\n",
      "Epoch 239/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 221.1459 - accuracy: 0.5562 - val_loss: 645.4737 - val_accuracy: 0.4323\n",
      "Epoch 240/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 273.9134 - accuracy: 0.5529 - val_loss: 154.8632 - val_accuracy: 0.5848\n",
      "Epoch 241/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 336.6709 - accuracy: 0.5540 - val_loss: 1359.5514 - val_accuracy: 0.5703\n",
      "Epoch 242/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 330.7602 - accuracy: 0.5463 - val_loss: 1124.2703 - val_accuracy: 0.4297\n",
      "Epoch 243/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 400.2653 - accuracy: 0.5539 - val_loss: 506.1627 - val_accuracy: 0.5703\n",
      "Epoch 244/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 389.5187 - accuracy: 0.5392 - val_loss: 231.8562 - val_accuracy: 0.4468\n",
      "Epoch 245/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 219.3188 - accuracy: 0.5483 - val_loss: 269.8182 - val_accuracy: 0.4507\n",
      "Epoch 246/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 203.7536 - accuracy: 0.5696 - val_loss: 206.3746 - val_accuracy: 0.4520\n",
      "Epoch 247/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 262.9778 - accuracy: 0.5315 - val_loss: 171.0078 - val_accuracy: 0.5795\n",
      "Epoch 248/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 292.0102 - accuracy: 0.5366 - val_loss: 305.1928 - val_accuracy: 0.5703\n",
      "Epoch 249/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 323.3253 - accuracy: 0.5466 - val_loss: 554.7101 - val_accuracy: 0.5703\n",
      "Epoch 250/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 350.2035 - accuracy: 0.5204 - val_loss: 196.0316 - val_accuracy: 0.5729\n",
      "Epoch 251/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 230.4768 - accuracy: 0.5502 - val_loss: 551.7168 - val_accuracy: 0.4323\n",
      "Epoch 252/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 175.6744 - accuracy: 0.5589 - val_loss: 342.8368 - val_accuracy: 0.4376\n",
      "Epoch 253/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 266.5938 - accuracy: 0.5450 - val_loss: 716.3801 - val_accuracy: 0.5703\n",
      "Epoch 254/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 379.1821 - accuracy: 0.5304 - val_loss: 65.8407 - val_accuracy: 0.6518\n",
      "Epoch 255/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 173.3961 - accuracy: 0.5519 - val_loss: 285.0021 - val_accuracy: 0.5690\n",
      "Epoch 256/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 237.7787 - accuracy: 0.5404 - val_loss: 413.6512 - val_accuracy: 0.5716\n",
      "Epoch 257/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 277.1435 - accuracy: 0.5389 - val_loss: 562.8896 - val_accuracy: 0.5703\n",
      "Epoch 258/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 234.9791 - accuracy: 0.5483 - val_loss: 162.1991 - val_accuracy: 0.4744\n",
      "Epoch 259/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 295.4817 - accuracy: 0.5335 - val_loss: 398.3733 - val_accuracy: 0.5703\n",
      "Epoch 260/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 315.1104 - accuracy: 0.5402 - val_loss: 74.5133 - val_accuracy: 0.6491\n",
      "Epoch 261/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 243.8326 - accuracy: 0.5537 - val_loss: 348.9337 - val_accuracy: 0.4376\n",
      "Epoch 262/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 181.7584 - accuracy: 0.5611 - val_loss: 92.8223 - val_accuracy: 0.5585\n",
      "Epoch 263/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 249.7125 - accuracy: 0.5323 - val_loss: 68.2489 - val_accuracy: 0.6518\n",
      "Epoch 264/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 435.2884 - accuracy: 0.5452 - val_loss: 484.8799 - val_accuracy: 0.5703\n",
      "Epoch 265/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 155.3512 - accuracy: 0.5849 - val_loss: 57.4675 - val_accuracy: 0.6505\n",
      "Epoch 266/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 256.0872 - accuracy: 0.5455 - val_loss: 59.4234 - val_accuracy: 0.6518\n",
      "Epoch 267/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 292.5181 - accuracy: 0.5540 - val_loss: 61.2693 - val_accuracy: 0.6452\n",
      "Epoch 268/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 337.7557 - accuracy: 0.5381 - val_loss: 65.1360 - val_accuracy: 0.6505\n",
      "Epoch 269/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 133.9726 - accuracy: 0.5749 - val_loss: 55.6903 - val_accuracy: 0.6491\n",
      "Epoch 270/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 210.4182 - accuracy: 0.5471 - val_loss: 181.7868 - val_accuracy: 0.4560\n",
      "Epoch 271/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 261.2719 - accuracy: 0.5388 - val_loss: 276.5952 - val_accuracy: 0.5690\n",
      "Epoch 272/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 210.4938 - accuracy: 0.5479 - val_loss: 60.4013 - val_accuracy: 0.6465\n",
      "Epoch 273/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 241.3450 - accuracy: 0.5481 - val_loss: 226.7132 - val_accuracy: 0.5664\n",
      "Epoch 274/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 377.1630 - accuracy: 0.5411 - val_loss: 77.6828 - val_accuracy: 0.6399\n",
      "Epoch 275/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 167.8874 - accuracy: 0.5591 - val_loss: 193.6884 - val_accuracy: 0.5664\n",
      "Epoch 276/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 239.1248 - accuracy: 0.5491 - val_loss: 468.5280 - val_accuracy: 0.4323\n",
      "Epoch 277/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 138.0620 - accuracy: 0.5708 - val_loss: 609.6079 - val_accuracy: 0.5703\n",
      "Epoch 278/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 195.8075 - accuracy: 0.5578 - val_loss: 87.2463 - val_accuracy: 0.6150\n",
      "Epoch 279/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 275.5421 - accuracy: 0.5460 - val_loss: 113.6228 - val_accuracy: 0.5913\n",
      "Epoch 280/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 188.8341 - accuracy: 0.5465 - val_loss: 336.9118 - val_accuracy: 0.5716\n",
      "Epoch 281/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 206.3993 - accuracy: 0.5537 - val_loss: 75.7931 - val_accuracy: 0.6360\n",
      "Epoch 282/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 207.6904 - accuracy: 0.5507 - val_loss: 257.3587 - val_accuracy: 0.5690\n",
      "Epoch 283/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 415.2005 - accuracy: 0.5353 - val_loss: 157.1917 - val_accuracy: 0.5703\n",
      "Epoch 284/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 255.3230 - accuracy: 0.5580 - val_loss: 110.0300 - val_accuracy: 0.5940\n",
      "Epoch 285/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 146.8777 - accuracy: 0.5599 - val_loss: 494.1499 - val_accuracy: 0.5703\n",
      "Epoch 286/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 272.8744 - accuracy: 0.5384 - val_loss: 143.5062 - val_accuracy: 0.4691\n",
      "Epoch 287/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 173.4113 - accuracy: 0.5611 - val_loss: 289.1217 - val_accuracy: 0.5716\n",
      "Epoch 288/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 231.1813 - accuracy: 0.5404 - val_loss: 477.2002 - val_accuracy: 0.5703\n",
      "Epoch 289/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 185.9286 - accuracy: 0.5537 - val_loss: 203.5956 - val_accuracy: 0.5703\n",
      "Epoch 290/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 228.7577 - accuracy: 0.5453 - val_loss: 97.8783 - val_accuracy: 0.5940\n",
      "Epoch 291/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 241.7003 - accuracy: 0.5386 - val_loss: 765.4634 - val_accuracy: 0.4297\n",
      "Epoch 292/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 312.3723 - accuracy: 0.5325 - val_loss: 621.6847 - val_accuracy: 0.4310\n",
      "Epoch 293/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 224.7926 - accuracy: 0.5425 - val_loss: 444.3114 - val_accuracy: 0.5703\n",
      "Epoch 294/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 221.2104 - accuracy: 0.5437 - val_loss: 457.3540 - val_accuracy: 0.4323\n",
      "Epoch 295/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 291.1115 - accuracy: 0.5319 - val_loss: 255.1163 - val_accuracy: 0.4402\n",
      "Epoch 296/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 229.6559 - accuracy: 0.5517 - val_loss: 121.2001 - val_accuracy: 0.5861\n",
      "Epoch 297/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 184.2935 - accuracy: 0.5524 - val_loss: 304.7959 - val_accuracy: 0.5716\n",
      "Epoch 298/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 221.7975 - accuracy: 0.5430 - val_loss: 240.9883 - val_accuracy: 0.5690\n",
      "Epoch 299/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 213.7401 - accuracy: 0.5450 - val_loss: 85.0978 - val_accuracy: 0.5992\n",
      "Epoch 300/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 363.0765 - accuracy: 0.5217 - val_loss: 62.0607 - val_accuracy: 0.6399\n",
      "Epoch 301/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 220.8647 - accuracy: 0.5417 - val_loss: 254.3378 - val_accuracy: 0.5703\n",
      "Epoch 302/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 259.7547 - accuracy: 0.5402 - val_loss: 461.0493 - val_accuracy: 0.5703\n",
      "Epoch 303/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 371.6785 - accuracy: 0.5322 - val_loss: 85.6645 - val_accuracy: 0.5388\n",
      "Epoch 304/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 406.6652 - accuracy: 0.5279 - val_loss: 1091.0350 - val_accuracy: 0.4297\n",
      "Epoch 305/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 209.4017 - accuracy: 0.5494 - val_loss: 396.7603 - val_accuracy: 0.4323\n",
      "Epoch 306/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 212.6071 - accuracy: 0.5575 - val_loss: 51.6938 - val_accuracy: 0.6189\n",
      "Epoch 307/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 223.3434 - accuracy: 0.5560 - val_loss: 392.5923 - val_accuracy: 0.4323\n",
      "Epoch 308/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 335.3869 - accuracy: 0.5205 - val_loss: 64.8187 - val_accuracy: 0.6399\n",
      "Epoch 309/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 141.8982 - accuracy: 0.5635 - val_loss: 43.9766 - val_accuracy: 0.6386\n",
      "Epoch 310/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 138.0359 - accuracy: 0.5645 - val_loss: 245.1910 - val_accuracy: 0.4350\n",
      "Epoch 311/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 185.5074 - accuracy: 0.5397 - val_loss: 144.0612 - val_accuracy: 0.4520\n",
      "Epoch 312/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 237.6167 - accuracy: 0.5255 - val_loss: 65.0168 - val_accuracy: 0.5677\n",
      "Epoch 313/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 250.6897 - accuracy: 0.5394 - val_loss: 90.9158 - val_accuracy: 0.5874\n",
      "Epoch 314/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 323.4085 - accuracy: 0.5335 - val_loss: 626.3074 - val_accuracy: 0.4297\n",
      "Epoch 315/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 287.2871 - accuracy: 0.5396 - val_loss: 272.2812 - val_accuracy: 0.5703\n",
      "Epoch 316/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 164.1993 - accuracy: 0.5539 - val_loss: 215.8480 - val_accuracy: 0.4402\n",
      "Epoch 317/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 310.8674 - accuracy: 0.5296 - val_loss: 44.5713 - val_accuracy: 0.6465\n",
      "Epoch 318/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 165.3736 - accuracy: 0.5460 - val_loss: 120.0720 - val_accuracy: 0.5703\n",
      "Epoch 319/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 178.0070 - accuracy: 0.5445 - val_loss: 201.0544 - val_accuracy: 0.5716\n",
      "Epoch 320/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 166.9141 - accuracy: 0.5435 - val_loss: 382.5914 - val_accuracy: 0.5703\n",
      "Epoch 321/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 231.8701 - accuracy: 0.5325 - val_loss: 374.4977 - val_accuracy: 0.4323\n",
      "Epoch 322/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 185.2704 - accuracy: 0.5424 - val_loss: 812.1564 - val_accuracy: 0.5703\n",
      "Epoch 323/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 504.1508 - accuracy: 0.5128 - val_loss: 94.6081 - val_accuracy: 0.5940\n",
      "Epoch 324/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 164.6500 - accuracy: 0.5568 - val_loss: 342.4535 - val_accuracy: 0.5703\n",
      "Epoch 325/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 207.7468 - accuracy: 0.5412 - val_loss: 38.7178 - val_accuracy: 0.6150\n",
      "Epoch 326/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 200.6826 - accuracy: 0.5355 - val_loss: 69.4692 - val_accuracy: 0.6137\n",
      "Epoch 327/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 180.6674 - accuracy: 0.5368 - val_loss: 66.5926 - val_accuracy: 0.6189\n",
      "Epoch 328/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 253.4596 - accuracy: 0.5309 - val_loss: 188.6831 - val_accuracy: 0.5690\n",
      "Epoch 329/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 202.7311 - accuracy: 0.5348 - val_loss: 289.9611 - val_accuracy: 0.4350\n",
      "Epoch 330/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 275.4581 - accuracy: 0.5363 - val_loss: 118.7592 - val_accuracy: 0.4783\n",
      "Epoch 331/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 139.4440 - accuracy: 0.5568 - val_loss: 43.2893 - val_accuracy: 0.6176\n",
      "Epoch 332/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 247.5461 - accuracy: 0.5317 - val_loss: 118.4971 - val_accuracy: 0.4625\n",
      "Epoch 333/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 262.2836 - accuracy: 0.5207 - val_loss: 120.1257 - val_accuracy: 0.4783\n",
      "Epoch 334/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 131.5117 - accuracy: 0.5571 - val_loss: 192.8840 - val_accuracy: 0.5703\n",
      "Epoch 335/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 247.2203 - accuracy: 0.5366 - val_loss: 76.4436 - val_accuracy: 0.5230\n",
      "Epoch 336/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 187.0250 - accuracy: 0.5476 - val_loss: 45.5580 - val_accuracy: 0.6491\n",
      "Epoch 337/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 202.4616 - accuracy: 0.5376 - val_loss: 45.5560 - val_accuracy: 0.6176\n",
      "Epoch 338/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 168.1523 - accuracy: 0.5491 - val_loss: 46.4436 - val_accuracy: 0.6176\n",
      "Epoch 339/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 185.2931 - accuracy: 0.5437 - val_loss: 83.0488 - val_accuracy: 0.5979\n",
      "Epoch 340/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 137.8649 - accuracy: 0.5581 - val_loss: 152.5939 - val_accuracy: 0.4520\n",
      "Epoch 341/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 298.5511 - accuracy: 0.5328 - val_loss: 248.7201 - val_accuracy: 0.4350\n",
      "Epoch 342/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 140.4928 - accuracy: 0.5624 - val_loss: 104.9491 - val_accuracy: 0.4783\n",
      "Epoch 343/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 201.1102 - accuracy: 0.5479 - val_loss: 125.6479 - val_accuracy: 0.5729\n",
      "Epoch 344/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 151.7474 - accuracy: 0.5535 - val_loss: 254.8513 - val_accuracy: 0.5716\n",
      "Epoch 345/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 248.5576 - accuracy: 0.5381 - val_loss: 130.7405 - val_accuracy: 0.4547\n",
      "Epoch 346/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 204.4682 - accuracy: 0.5539 - val_loss: 56.0645 - val_accuracy: 0.5716\n",
      "Epoch 347/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 219.9250 - accuracy: 0.5488 - val_loss: 60.3521 - val_accuracy: 0.6386\n",
      "Epoch 348/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 124.2823 - accuracy: 0.5539 - val_loss: 239.6164 - val_accuracy: 0.4376\n",
      "Epoch 349/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 222.9723 - accuracy: 0.5468 - val_loss: 94.6523 - val_accuracy: 0.4980\n",
      "Epoch 350/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 179.4234 - accuracy: 0.5494 - val_loss: 1250.5493 - val_accuracy: 0.5703\n",
      "Epoch 351/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 280.6568 - accuracy: 0.5337 - val_loss: 390.6945 - val_accuracy: 0.5703\n",
      "Epoch 352/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 136.9062 - accuracy: 0.5709 - val_loss: 55.6808 - val_accuracy: 0.5834\n",
      "Epoch 353/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 200.3230 - accuracy: 0.5481 - val_loss: 43.6949 - val_accuracy: 0.6294\n",
      "Epoch 354/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 113.1778 - accuracy: 0.5617 - val_loss: 153.8067 - val_accuracy: 0.4520\n",
      "Epoch 355/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 247.0667 - accuracy: 0.5443 - val_loss: 148.6556 - val_accuracy: 0.4534\n",
      "Epoch 356/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 237.3589 - accuracy: 0.5338 - val_loss: 127.1309 - val_accuracy: 0.4652\n",
      "Epoch 357/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 173.1753 - accuracy: 0.5384 - val_loss: 202.4827 - val_accuracy: 0.5690\n",
      "Epoch 358/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 152.7349 - accuracy: 0.5502 - val_loss: 205.8201 - val_accuracy: 0.4455\n",
      "Epoch 359/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 207.1634 - accuracy: 0.5519 - val_loss: 176.9929 - val_accuracy: 0.5677\n",
      "Epoch 360/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 145.6629 - accuracy: 0.5563 - val_loss: 65.1043 - val_accuracy: 0.5690\n",
      "Epoch 361/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 137.3839 - accuracy: 0.5670 - val_loss: 311.3489 - val_accuracy: 0.5703\n",
      "Epoch 362/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 244.7619 - accuracy: 0.5494 - val_loss: 54.6405 - val_accuracy: 0.5874\n",
      "Epoch 363/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 267.8546 - accuracy: 0.5371 - val_loss: 144.2215 - val_accuracy: 0.4534\n",
      "Epoch 364/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 299.8597 - accuracy: 0.5342 - val_loss: 318.3090 - val_accuracy: 0.5703\n",
      "Epoch 365/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 155.6793 - accuracy: 0.5594 - val_loss: 144.3488 - val_accuracy: 0.5690\n",
      "Epoch 366/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 254.2052 - accuracy: 0.5425 - val_loss: 56.3213 - val_accuracy: 0.5940\n",
      "Epoch 367/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 148.8977 - accuracy: 0.5627 - val_loss: 360.7732 - val_accuracy: 0.5703\n",
      "Epoch 368/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 201.6096 - accuracy: 0.5542 - val_loss: 241.6072 - val_accuracy: 0.5690\n",
      "Epoch 369/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 221.4529 - accuracy: 0.5374 - val_loss: 262.5180 - val_accuracy: 0.4389\n",
      "Epoch 370/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 149.9688 - accuracy: 0.5545 - val_loss: 246.5756 - val_accuracy: 0.4402\n",
      "Epoch 371/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 185.1719 - accuracy: 0.5483 - val_loss: 282.6675 - val_accuracy: 0.5716\n",
      "Epoch 372/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 190.6711 - accuracy: 0.5461 - val_loss: 145.3399 - val_accuracy: 0.5703\n",
      "Epoch 373/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 135.0805 - accuracy: 0.5667 - val_loss: 361.4901 - val_accuracy: 0.4323\n",
      "Epoch 374/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 179.7156 - accuracy: 0.5458 - val_loss: 48.6700 - val_accuracy: 0.6137\n",
      "Epoch 375/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 126.3842 - accuracy: 0.5581 - val_loss: 45.4455 - val_accuracy: 0.6189\n",
      "Epoch 376/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 134.2119 - accuracy: 0.5581 - val_loss: 73.7257 - val_accuracy: 0.6124\n",
      "Epoch 377/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 179.5579 - accuracy: 0.5425 - val_loss: 108.9299 - val_accuracy: 0.4783\n",
      "Epoch 378/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 99.7923 - accuracy: 0.5644 - val_loss: 67.4551 - val_accuracy: 0.6163\n",
      "Epoch 379/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 199.4845 - accuracy: 0.5392 - val_loss: 50.6587 - val_accuracy: 0.6045\n",
      "Epoch 380/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 251.9381 - accuracy: 0.5409 - val_loss: 901.9487 - val_accuracy: 0.4297\n",
      "Epoch 381/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 222.4851 - accuracy: 0.5589 - val_loss: 128.5582 - val_accuracy: 0.5756\n",
      "Epoch 382/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 121.2175 - accuracy: 0.5688 - val_loss: 211.1309 - val_accuracy: 0.5690\n",
      "Epoch 383/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 159.2023 - accuracy: 0.5639 - val_loss: 70.5210 - val_accuracy: 0.5506\n",
      "Epoch 384/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 142.8397 - accuracy: 0.5700 - val_loss: 482.9181 - val_accuracy: 0.4323\n",
      "Epoch 385/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 203.7245 - accuracy: 0.5466 - val_loss: 244.1106 - val_accuracy: 0.5703\n",
      "Epoch 386/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 174.0270 - accuracy: 0.5412 - val_loss: 97.3092 - val_accuracy: 0.5913\n",
      "Epoch 387/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 157.3028 - accuracy: 0.5476 - val_loss: 86.4215 - val_accuracy: 0.5072\n",
      "Epoch 388/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 133.2646 - accuracy: 0.5688 - val_loss: 237.4057 - val_accuracy: 0.5703\n",
      "Epoch 389/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 145.6490 - accuracy: 0.5534 - val_loss: 400.6425 - val_accuracy: 0.5703\n",
      "Epoch 390/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 243.2948 - accuracy: 0.5325 - val_loss: 42.1063 - val_accuracy: 0.6544\n",
      "Epoch 391/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 173.9605 - accuracy: 0.5586 - val_loss: 434.1909 - val_accuracy: 0.5703\n",
      "Epoch 392/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 214.3278 - accuracy: 0.5493 - val_loss: 234.3896 - val_accuracy: 0.5703\n",
      "Epoch 393/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 299.2406 - accuracy: 0.5383 - val_loss: 105.5722 - val_accuracy: 0.4836\n",
      "Epoch 394/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 134.0600 - accuracy: 0.5517 - val_loss: 288.2978 - val_accuracy: 0.4323\n",
      "Epoch 395/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 131.2702 - accuracy: 0.5539 - val_loss: 64.8238 - val_accuracy: 0.6163\n",
      "Epoch 396/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 172.4713 - accuracy: 0.5496 - val_loss: 69.4573 - val_accuracy: 0.6018\n",
      "Epoch 397/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 165.2124 - accuracy: 0.5537 - val_loss: 182.7217 - val_accuracy: 0.4389\n",
      "Epoch 398/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 185.6153 - accuracy: 0.5402 - val_loss: 859.6840 - val_accuracy: 0.4297\n",
      "Epoch 399/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 177.2257 - accuracy: 0.5460 - val_loss: 65.4221 - val_accuracy: 0.5414\n",
      "Epoch 400/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 109.3719 - accuracy: 0.5498 - val_loss: 346.8771 - val_accuracy: 0.5703\n",
      "Epoch 401/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 143.6888 - accuracy: 0.5512 - val_loss: 150.0692 - val_accuracy: 0.5703\n",
      "Epoch 402/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 155.1009 - accuracy: 0.5499 - val_loss: 277.9664 - val_accuracy: 0.5703\n",
      "Epoch 403/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 235.1503 - accuracy: 0.5489 - val_loss: 92.4929 - val_accuracy: 0.5887\n",
      "Epoch 404/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 184.4342 - accuracy: 0.5488 - val_loss: 93.0943 - val_accuracy: 0.5900\n",
      "Epoch 405/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 171.4774 - accuracy: 0.5388 - val_loss: 151.6498 - val_accuracy: 0.5703\n",
      "Epoch 406/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 168.0411 - accuracy: 0.5414 - val_loss: 51.6326 - val_accuracy: 0.5716\n",
      "Epoch 407/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 282.6332 - accuracy: 0.5256 - val_loss: 41.2329 - val_accuracy: 0.6491\n",
      "Epoch 408/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 229.8027 - accuracy: 0.5350 - val_loss: 714.2274 - val_accuracy: 0.5703\n",
      "Epoch 409/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 143.8988 - accuracy: 0.5626 - val_loss: 69.0988 - val_accuracy: 0.6018\n",
      "Epoch 410/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 97.3397 - accuracy: 0.5690 - val_loss: 124.4799 - val_accuracy: 0.5677\n",
      "Epoch 411/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 216.4552 - accuracy: 0.5388 - val_loss: 61.0213 - val_accuracy: 0.6150\n",
      "Epoch 412/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 123.0259 - accuracy: 0.5565 - val_loss: 403.7252 - val_accuracy: 0.4323\n",
      "Epoch 413/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 317.4715 - accuracy: 0.5284 - val_loss: 35.4694 - val_accuracy: 0.6294\n",
      "Epoch 414/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 127.9173 - accuracy: 0.5616 - val_loss: 278.5928 - val_accuracy: 0.5703\n",
      "Epoch 415/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 188.6523 - accuracy: 0.5429 - val_loss: 39.5339 - val_accuracy: 0.6505\n",
      "Epoch 416/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 157.8661 - accuracy: 0.5662 - val_loss: 189.8237 - val_accuracy: 0.4389\n",
      "Epoch 417/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 158.5139 - accuracy: 0.5429 - val_loss: 194.3612 - val_accuracy: 0.4389\n",
      "Epoch 418/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 144.1542 - accuracy: 0.5419 - val_loss: 34.3351 - val_accuracy: 0.6544\n",
      "Epoch 419/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 194.6082 - accuracy: 0.5417 - val_loss: 84.9961 - val_accuracy: 0.5874\n",
      "Epoch 420/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 171.8445 - accuracy: 0.5337 - val_loss: 97.8061 - val_accuracy: 0.4744\n",
      "Epoch 421/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 126.4829 - accuracy: 0.5544 - val_loss: 84.2425 - val_accuracy: 0.4783\n",
      "Epoch 422/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 149.4169 - accuracy: 0.5415 - val_loss: 53.8295 - val_accuracy: 0.5558\n",
      "Epoch 423/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 136.8176 - accuracy: 0.5489 - val_loss: 43.0879 - val_accuracy: 0.6386\n",
      "Epoch 424/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 114.2874 - accuracy: 0.5578 - val_loss: 202.7062 - val_accuracy: 0.4350\n",
      "Epoch 425/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 119.3279 - accuracy: 0.5580 - val_loss: 97.4468 - val_accuracy: 0.4625\n",
      "Epoch 426/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 160.1669 - accuracy: 0.5435 - val_loss: 66.0844 - val_accuracy: 0.5953\n",
      "Epoch 427/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 89.1348 - accuracy: 0.5665 - val_loss: 137.3464 - val_accuracy: 0.4507\n",
      "Epoch 428/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 183.6835 - accuracy: 0.5294 - val_loss: 351.9716 - val_accuracy: 0.4323\n",
      "Epoch 429/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 195.4508 - accuracy: 0.5366 - val_loss: 419.6740 - val_accuracy: 0.4310\n",
      "Epoch 430/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 124.0863 - accuracy: 0.5550 - val_loss: 102.5305 - val_accuracy: 0.4573\n",
      "Epoch 431/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 177.8497 - accuracy: 0.5394 - val_loss: 392.2060 - val_accuracy: 0.4323\n",
      "Epoch 432/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 216.0566 - accuracy: 0.5299 - val_loss: 169.3328 - val_accuracy: 0.5703\n",
      "Epoch 433/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 170.1140 - accuracy: 0.5379 - val_loss: 359.5732 - val_accuracy: 0.5703\n",
      "Epoch 434/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 122.3314 - accuracy: 0.5550 - val_loss: 114.5060 - val_accuracy: 0.4547\n",
      "Epoch 435/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 198.0393 - accuracy: 0.5488 - val_loss: 370.7555 - val_accuracy: 0.4323\n",
      "Epoch 436/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 142.3613 - accuracy: 0.5386 - val_loss: 31.0320 - val_accuracy: 0.6281\n",
      "Epoch 437/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 162.3137 - accuracy: 0.5427 - val_loss: 396.5904 - val_accuracy: 0.4310\n",
      "Epoch 438/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 91.4708 - accuracy: 0.5665 - val_loss: 32.8531 - val_accuracy: 0.6110\n",
      "Epoch 439/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 117.0329 - accuracy: 0.5358 - val_loss: 189.9807 - val_accuracy: 0.4350\n",
      "Epoch 440/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 146.1471 - accuracy: 0.5381 - val_loss: 30.2682 - val_accuracy: 0.6557\n",
      "Epoch 441/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 240.8084 - accuracy: 0.5463 - val_loss: 281.5506 - val_accuracy: 0.5703\n",
      "Epoch 442/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 276.2526 - accuracy: 0.5212 - val_loss: 118.2035 - val_accuracy: 0.5703\n",
      "Epoch 443/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 132.7534 - accuracy: 0.5437 - val_loss: 600.5273 - val_accuracy: 0.5703\n",
      "Epoch 444/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 123.3107 - accuracy: 0.5550 - val_loss: 94.7793 - val_accuracy: 0.5703\n",
      "Epoch 445/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 165.2919 - accuracy: 0.5202 - val_loss: 81.5790 - val_accuracy: 0.5782\n",
      "Epoch 446/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 227.8304 - accuracy: 0.5312 - val_loss: 169.8425 - val_accuracy: 0.5703\n",
      "Epoch 447/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 141.8416 - accuracy: 0.5409 - val_loss: 416.0437 - val_accuracy: 0.4310\n",
      "Epoch 448/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 133.9292 - accuracy: 0.5350 - val_loss: 142.4655 - val_accuracy: 0.5690\n",
      "Epoch 449/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 218.8421 - accuracy: 0.5417 - val_loss: 61.4139 - val_accuracy: 0.5979\n",
      "Epoch 450/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 88.0183 - accuracy: 0.5645 - val_loss: 222.3139 - val_accuracy: 0.5703\n",
      "Epoch 451/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 196.4402 - accuracy: 0.5282 - val_loss: 37.6054 - val_accuracy: 0.5742\n",
      "Epoch 452/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 145.3624 - accuracy: 0.5470 - val_loss: 29.1159 - val_accuracy: 0.6229\n",
      "Epoch 453/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 93.7936 - accuracy: 0.5489 - val_loss: 232.0478 - val_accuracy: 0.5703\n",
      "Epoch 454/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 125.6552 - accuracy: 0.5445 - val_loss: 343.1857 - val_accuracy: 0.4310\n",
      "Epoch 455/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 144.7063 - accuracy: 0.5409 - val_loss: 67.9396 - val_accuracy: 0.5874\n",
      "Epoch 456/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 113.5816 - accuracy: 0.5596 - val_loss: 54.0622 - val_accuracy: 0.5112\n",
      "Epoch 457/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 183.6775 - accuracy: 0.5433 - val_loss: 152.5023 - val_accuracy: 0.5703\n",
      "Epoch 458/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 123.9465 - accuracy: 0.5539 - val_loss: 287.5641 - val_accuracy: 0.4323\n",
      "Epoch 459/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 111.3887 - accuracy: 0.5397 - val_loss: 108.0530 - val_accuracy: 0.5716\n",
      "Epoch 460/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 136.9141 - accuracy: 0.5402 - val_loss: 174.5161 - val_accuracy: 0.4350\n",
      "Epoch 461/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 164.1248 - accuracy: 0.5435 - val_loss: 40.0781 - val_accuracy: 0.6216\n",
      "Epoch 462/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 178.3130 - accuracy: 0.5337 - val_loss: 458.6141 - val_accuracy: 0.4297\n",
      "Epoch 463/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 120.4809 - accuracy: 0.5342 - val_loss: 35.5731 - val_accuracy: 0.5703\n",
      "Epoch 464/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 122.6446 - accuracy: 0.5350 - val_loss: 336.3334 - val_accuracy: 0.4310\n",
      "Epoch 465/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 152.3597 - accuracy: 0.5420 - val_loss: 94.9137 - val_accuracy: 0.4573\n",
      "Epoch 466/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 148.0050 - accuracy: 0.5557 - val_loss: 63.9907 - val_accuracy: 0.5808\n",
      "Epoch 467/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 140.3290 - accuracy: 0.5407 - val_loss: 137.8759 - val_accuracy: 0.4389\n",
      "Epoch 468/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 173.6953 - accuracy: 0.5282 - val_loss: 25.9250 - val_accuracy: 0.6281\n",
      "Epoch 469/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 115.9713 - accuracy: 0.5475 - val_loss: 178.9229 - val_accuracy: 0.4350\n",
      "Epoch 470/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 117.6382 - accuracy: 0.5502 - val_loss: 111.3973 - val_accuracy: 0.4507\n",
      "Epoch 471/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 136.1715 - accuracy: 0.5356 - val_loss: 380.0334 - val_accuracy: 0.4310\n",
      "Epoch 472/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 130.6638 - accuracy: 0.5470 - val_loss: 263.8571 - val_accuracy: 0.5703\n",
      "Epoch 473/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 263.0825 - accuracy: 0.5264 - val_loss: 182.0662 - val_accuracy: 0.5703\n",
      "Epoch 474/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 77.2000 - accuracy: 0.5591 - val_loss: 30.7037 - val_accuracy: 0.6360\n",
      "Epoch 475/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 103.3284 - accuracy: 0.5519 - val_loss: 23.3626 - val_accuracy: 0.6110\n",
      "Epoch 476/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 80.9890 - accuracy: 0.5540 - val_loss: 289.2929 - val_accuracy: 0.4323\n",
      "Epoch 477/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 131.9651 - accuracy: 0.5432 - val_loss: 389.9693 - val_accuracy: 0.5703\n",
      "Epoch 478/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 104.2918 - accuracy: 0.5384 - val_loss: 34.5194 - val_accuracy: 0.6189\n",
      "Epoch 479/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 105.6753 - accuracy: 0.5553 - val_loss: 22.7610 - val_accuracy: 0.6531\n",
      "Epoch 480/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 135.7431 - accuracy: 0.5348 - val_loss: 244.9376 - val_accuracy: 0.5703\n",
      "Epoch 481/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 103.0647 - accuracy: 0.5392 - val_loss: 193.8986 - val_accuracy: 0.4323\n",
      "Epoch 482/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 121.7049 - accuracy: 0.5422 - val_loss: 72.2124 - val_accuracy: 0.5716\n",
      "Epoch 483/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 167.8772 - accuracy: 0.5498 - val_loss: 143.5089 - val_accuracy: 0.4363\n",
      "Epoch 484/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 217.2288 - accuracy: 0.5333 - val_loss: 39.0097 - val_accuracy: 0.5650\n",
      "Epoch 485/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 87.3569 - accuracy: 0.5488 - val_loss: 58.2630 - val_accuracy: 0.5900\n",
      "Epoch 486/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 110.9533 - accuracy: 0.5450 - val_loss: 138.5935 - val_accuracy: 0.5703\n",
      "Epoch 487/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 129.0620 - accuracy: 0.5414 - val_loss: 327.9081 - val_accuracy: 0.5703\n",
      "Epoch 488/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 101.8066 - accuracy: 0.5560 - val_loss: 58.3901 - val_accuracy: 0.5926\n",
      "Epoch 489/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 75.1260 - accuracy: 0.5658 - val_loss: 31.3493 - val_accuracy: 0.6413\n",
      "Epoch 490/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 84.8438 - accuracy: 0.5634 - val_loss: 147.9383 - val_accuracy: 0.5703\n",
      "Epoch 491/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 181.2191 - accuracy: 0.5376 - val_loss: 94.0094 - val_accuracy: 0.4586\n",
      "Epoch 492/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 116.5326 - accuracy: 0.5397 - val_loss: 237.0934 - val_accuracy: 0.5703\n",
      "Epoch 493/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 107.1618 - accuracy: 0.5453 - val_loss: 98.0663 - val_accuracy: 0.5690\n",
      "Epoch 494/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 77.1596 - accuracy: 0.5609 - val_loss: 62.0367 - val_accuracy: 0.5900\n",
      "Epoch 495/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 100.0098 - accuracy: 0.5496 - val_loss: 143.5232 - val_accuracy: 0.4402\n",
      "Epoch 496/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 147.8125 - accuracy: 0.5514 - val_loss: 25.1662 - val_accuracy: 0.6413\n",
      "Epoch 497/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 97.1401 - accuracy: 0.5507 - val_loss: 92.6798 - val_accuracy: 0.4586\n",
      "Epoch 498/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 90.0566 - accuracy: 0.5489 - val_loss: 137.6966 - val_accuracy: 0.5716\n",
      "Epoch 499/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 100.1191 - accuracy: 0.5483 - val_loss: 27.6812 - val_accuracy: 0.6491\n",
      "Epoch 500/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 87.7706 - accuracy: 0.5440 - val_loss: 45.3186 - val_accuracy: 0.5414\n",
      "Epoch 501/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 208.0156 - accuracy: 0.5300 - val_loss: 32.4871 - val_accuracy: 0.6478\n",
      "Epoch 502/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 91.1020 - accuracy: 0.5718 - val_loss: 145.9149 - val_accuracy: 0.4389\n",
      "Epoch 503/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 84.9627 - accuracy: 0.5655 - val_loss: 74.7629 - val_accuracy: 0.4757\n",
      "Epoch 504/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 127.3847 - accuracy: 0.5384 - val_loss: 452.7389 - val_accuracy: 0.4297\n",
      "Epoch 505/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 103.8837 - accuracy: 0.5409 - val_loss: 41.5168 - val_accuracy: 0.6307\n",
      "Epoch 506/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 124.4813 - accuracy: 0.5609 - val_loss: 87.3337 - val_accuracy: 0.4547\n",
      "Epoch 507/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 76.6437 - accuracy: 0.5529 - val_loss: 136.3629 - val_accuracy: 0.5690\n",
      "Epoch 508/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 115.6667 - accuracy: 0.5522 - val_loss: 202.5267 - val_accuracy: 0.5703\n",
      "Epoch 509/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 90.6148 - accuracy: 0.5550 - val_loss: 69.9501 - val_accuracy: 0.4783\n",
      "Epoch 510/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 89.0055 - accuracy: 0.5585 - val_loss: 74.3547 - val_accuracy: 0.5782\n",
      "Epoch 511/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 82.7856 - accuracy: 0.5621 - val_loss: 235.8454 - val_accuracy: 0.5703\n",
      "Epoch 512/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 127.1042 - accuracy: 0.5296 - val_loss: 33.0628 - val_accuracy: 0.5992\n",
      "Epoch 513/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 95.2399 - accuracy: 0.5560 - val_loss: 42.6534 - val_accuracy: 0.6307\n",
      "Epoch 514/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 70.5680 - accuracy: 0.5714 - val_loss: 111.8193 - val_accuracy: 0.5703\n",
      "Epoch 515/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 93.1381 - accuracy: 0.5594 - val_loss: 51.5718 - val_accuracy: 0.6005\n",
      "Epoch 516/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 116.7637 - accuracy: 0.5452 - val_loss: 208.5901 - val_accuracy: 0.5703\n",
      "Epoch 517/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 125.6210 - accuracy: 0.5435 - val_loss: 158.7353 - val_accuracy: 0.4389\n",
      "Epoch 518/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 123.9412 - accuracy: 0.5460 - val_loss: 72.0782 - val_accuracy: 0.4796\n",
      "Epoch 519/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 120.8176 - accuracy: 0.5483 - val_loss: 174.4872 - val_accuracy: 0.4350\n",
      "Epoch 520/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 105.5042 - accuracy: 0.5496 - val_loss: 73.0066 - val_accuracy: 0.4783\n",
      "Epoch 521/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 62.6007 - accuracy: 0.5864 - val_loss: 44.3151 - val_accuracy: 0.6216\n",
      "Epoch 522/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 87.3924 - accuracy: 0.5567 - val_loss: 140.4812 - val_accuracy: 0.5690\n",
      "Epoch 523/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 85.2194 - accuracy: 0.5673 - val_loss: 29.7808 - val_accuracy: 0.6137\n",
      "Epoch 524/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 119.3561 - accuracy: 0.5475 - val_loss: 95.9477 - val_accuracy: 0.5677\n",
      "Epoch 525/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 91.3759 - accuracy: 0.5673 - val_loss: 43.9468 - val_accuracy: 0.5545\n",
      "Epoch 526/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 78.2466 - accuracy: 0.5624 - val_loss: 226.9489 - val_accuracy: 0.5703\n",
      "Epoch 527/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 177.1808 - accuracy: 0.5327 - val_loss: 337.8359 - val_accuracy: 0.4323\n",
      "Epoch 528/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 80.7169 - accuracy: 0.5642 - val_loss: 43.2540 - val_accuracy: 0.6229\n",
      "Epoch 529/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 112.3043 - accuracy: 0.5468 - val_loss: 228.4364 - val_accuracy: 0.4323\n",
      "Epoch 530/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 79.8554 - accuracy: 0.5634 - val_loss: 32.1730 - val_accuracy: 0.6465\n",
      "Epoch 531/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 91.4285 - accuracy: 0.5555 - val_loss: 40.3840 - val_accuracy: 0.6307\n",
      "Epoch 532/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 80.3450 - accuracy: 0.5599 - val_loss: 37.0262 - val_accuracy: 0.6386\n",
      "Epoch 533/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 77.8280 - accuracy: 0.5624 - val_loss: 27.5742 - val_accuracy: 0.6557\n",
      "Epoch 534/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 63.2369 - accuracy: 0.5757 - val_loss: 62.3539 - val_accuracy: 0.5861\n",
      "Epoch 535/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 68.4628 - accuracy: 0.5575 - val_loss: 153.5657 - val_accuracy: 0.4376\n",
      "Epoch 536/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 148.8147 - accuracy: 0.5343 - val_loss: 134.0807 - val_accuracy: 0.4402\n",
      "Epoch 537/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 83.3762 - accuracy: 0.5606 - val_loss: 75.1091 - val_accuracy: 0.4757\n",
      "Epoch 538/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 108.7400 - accuracy: 0.5593 - val_loss: 82.3121 - val_accuracy: 0.5729\n",
      "Epoch 539/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 99.5503 - accuracy: 0.5440 - val_loss: 93.7623 - val_accuracy: 0.4573\n",
      "Epoch 540/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 92.9323 - accuracy: 0.5534 - val_loss: 149.7674 - val_accuracy: 0.5703\n",
      "Epoch 541/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 73.1343 - accuracy: 0.5739 - val_loss: 64.5021 - val_accuracy: 0.4783\n",
      "Epoch 542/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 94.2418 - accuracy: 0.5596 - val_loss: 30.3876 - val_accuracy: 0.6452\n",
      "Epoch 543/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 88.8512 - accuracy: 0.5529 - val_loss: 40.6879 - val_accuracy: 0.5558\n",
      "Epoch 544/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 94.8737 - accuracy: 0.5438 - val_loss: 28.0580 - val_accuracy: 0.6150\n",
      "Epoch 545/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 114.7980 - accuracy: 0.5493 - val_loss: 192.1443 - val_accuracy: 0.4323\n",
      "Epoch 546/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 87.1004 - accuracy: 0.5499 - val_loss: 42.6652 - val_accuracy: 0.5493\n",
      "Epoch 547/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 71.4125 - accuracy: 0.5681 - val_loss: 80.6545 - val_accuracy: 0.4573\n",
      "Epoch 548/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 65.1698 - accuracy: 0.5722 - val_loss: 123.0324 - val_accuracy: 0.4389\n",
      "Epoch 549/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 62.4201 - accuracy: 0.5609 - val_loss: 37.0849 - val_accuracy: 0.5690\n",
      "Epoch 550/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 70.7967 - accuracy: 0.5593 - val_loss: 65.5174 - val_accuracy: 0.5795\n",
      "Epoch 551/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 83.5287 - accuracy: 0.5567 - val_loss: 90.2217 - val_accuracy: 0.5690\n",
      "Epoch 552/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 127.0181 - accuracy: 0.5547 - val_loss: 170.8279 - val_accuracy: 0.5703\n",
      "Epoch 553/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 115.5296 - accuracy: 0.5453 - val_loss: 210.5643 - val_accuracy: 0.5703\n",
      "Epoch 554/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 68.9842 - accuracy: 0.5552 - val_loss: 113.2621 - val_accuracy: 0.4468\n",
      "Epoch 555/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 114.2336 - accuracy: 0.5504 - val_loss: 29.7238 - val_accuracy: 0.5913\n",
      "Epoch 556/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 101.9858 - accuracy: 0.5443 - val_loss: 225.5572 - val_accuracy: 0.4323\n",
      "Epoch 557/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 83.9241 - accuracy: 0.5704 - val_loss: 60.9632 - val_accuracy: 0.5900\n",
      "Epoch 558/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.8437 - accuracy: 0.5860 - val_loss: 43.9261 - val_accuracy: 0.5309\n",
      "Epoch 559/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 85.0224 - accuracy: 0.5690 - val_loss: 82.1114 - val_accuracy: 0.4520\n",
      "Epoch 560/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 58.8483 - accuracy: 0.5765 - val_loss: 31.1265 - val_accuracy: 0.6413\n",
      "Epoch 561/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 87.1183 - accuracy: 0.5530 - val_loss: 38.2274 - val_accuracy: 0.6189\n",
      "Epoch 562/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 122.3778 - accuracy: 0.5430 - val_loss: 174.2088 - val_accuracy: 0.4336\n",
      "Epoch 563/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 166.6257 - accuracy: 0.5248 - val_loss: 78.8826 - val_accuracy: 0.4573\n",
      "Epoch 564/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 64.0483 - accuracy: 0.5695 - val_loss: 110.6251 - val_accuracy: 0.4468\n",
      "Epoch 565/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 66.1039 - accuracy: 0.5675 - val_loss: 29.6060 - val_accuracy: 0.5913\n",
      "Epoch 566/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 50.4122 - accuracy: 0.5734 - val_loss: 35.6774 - val_accuracy: 0.6294\n",
      "Epoch 567/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 70.7164 - accuracy: 0.5614 - val_loss: 143.8888 - val_accuracy: 0.5703\n",
      "Epoch 568/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 72.7089 - accuracy: 0.5719 - val_loss: 27.2952 - val_accuracy: 0.6465\n",
      "Epoch 569/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 88.9896 - accuracy: 0.5621 - val_loss: 78.8718 - val_accuracy: 0.4520\n",
      "Epoch 570/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 95.4384 - accuracy: 0.5542 - val_loss: 256.8349 - val_accuracy: 0.4323\n",
      "Epoch 571/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 99.3110 - accuracy: 0.5571 - val_loss: 57.1565 - val_accuracy: 0.4809\n",
      "Epoch 572/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 62.4917 - accuracy: 0.5811 - val_loss: 31.5099 - val_accuracy: 0.6386\n",
      "Epoch 573/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 69.0990 - accuracy: 0.5677 - val_loss: 25.8994 - val_accuracy: 0.6005\n",
      "Epoch 574/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 60.6795 - accuracy: 0.5745 - val_loss: 24.0675 - val_accuracy: 0.6163\n",
      "Epoch 575/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 87.6617 - accuracy: 0.5519 - val_loss: 45.6419 - val_accuracy: 0.5979\n",
      "Epoch 576/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 98.5804 - accuracy: 0.5691 - val_loss: 55.4283 - val_accuracy: 0.4823\n",
      "Epoch 577/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 115.9710 - accuracy: 0.5345 - val_loss: 74.5611 - val_accuracy: 0.4586\n",
      "Epoch 578/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 108.4652 - accuracy: 0.5493 - val_loss: 32.8426 - val_accuracy: 0.5690\n",
      "Epoch 579/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 102.7154 - accuracy: 0.5422 - val_loss: 212.5083 - val_accuracy: 0.4323\n",
      "Epoch 580/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 89.1648 - accuracy: 0.5481 - val_loss: 35.1963 - val_accuracy: 0.5650\n",
      "Epoch 581/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 86.8274 - accuracy: 0.5547 - val_loss: 88.6016 - val_accuracy: 0.4586\n",
      "Epoch 582/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 62.0796 - accuracy: 0.5637 - val_loss: 31.9506 - val_accuracy: 0.6373\n",
      "Epoch 583/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 93.3043 - accuracy: 0.5511 - val_loss: 110.9692 - val_accuracy: 0.5690\n",
      "Epoch 584/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 52.4768 - accuracy: 0.5703 - val_loss: 27.6685 - val_accuracy: 0.5926\n",
      "Epoch 585/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 113.2629 - accuracy: 0.5284 - val_loss: 144.6621 - val_accuracy: 0.4350\n",
      "Epoch 586/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 125.4317 - accuracy: 0.5383 - val_loss: 193.9566 - val_accuracy: 0.5703\n",
      "Epoch 587/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 81.1529 - accuracy: 0.5580 - val_loss: 23.0507 - val_accuracy: 0.6518\n",
      "Epoch 588/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 70.8374 - accuracy: 0.5652 - val_loss: 22.5220 - val_accuracy: 0.6491\n",
      "Epoch 589/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 70.2380 - accuracy: 0.5777 - val_loss: 88.6862 - val_accuracy: 0.5703\n",
      "Epoch 590/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 81.8270 - accuracy: 0.5499 - val_loss: 43.0064 - val_accuracy: 0.5191\n",
      "Epoch 591/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 69.0520 - accuracy: 0.5644 - val_loss: 151.5981 - val_accuracy: 0.5703\n",
      "Epoch 592/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 82.9846 - accuracy: 0.5460 - val_loss: 35.6097 - val_accuracy: 0.6242\n",
      "Epoch 593/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 49.9485 - accuracy: 0.5760 - val_loss: 29.9334 - val_accuracy: 0.6439\n",
      "Epoch 594/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 58.2630 - accuracy: 0.5734 - val_loss: 193.4695 - val_accuracy: 0.4323\n",
      "Epoch 595/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 59.1666 - accuracy: 0.5612 - val_loss: 67.7321 - val_accuracy: 0.5729\n",
      "Epoch 596/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 120.8851 - accuracy: 0.5361 - val_loss: 131.6340 - val_accuracy: 0.4376\n",
      "Epoch 597/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 62.4532 - accuracy: 0.5785 - val_loss: 60.2769 - val_accuracy: 0.4796\n",
      "Epoch 598/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 66.3121 - accuracy: 0.5555 - val_loss: 57.1312 - val_accuracy: 0.5848\n",
      "Epoch 599/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 65.6795 - accuracy: 0.5580 - val_loss: 83.0910 - val_accuracy: 0.5690\n",
      "Epoch 600/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 51.0820 - accuracy: 0.5768 - val_loss: 34.0682 - val_accuracy: 0.6229\n",
      "Epoch 601/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.9737 - accuracy: 0.5826 - val_loss: 202.2935 - val_accuracy: 0.5703\n",
      "Epoch 602/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 63.4376 - accuracy: 0.5645 - val_loss: 88.4310 - val_accuracy: 0.5716\n",
      "Epoch 603/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 145.7802 - accuracy: 0.5297 - val_loss: 32.3833 - val_accuracy: 0.6321\n",
      "Epoch 604/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 75.1986 - accuracy: 0.5647 - val_loss: 21.1777 - val_accuracy: 0.6321\n",
      "Epoch 605/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 70.7849 - accuracy: 0.5698 - val_loss: 22.5440 - val_accuracy: 0.6216\n",
      "Epoch 606/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 56.4180 - accuracy: 0.5708 - val_loss: 46.9080 - val_accuracy: 0.5979\n",
      "Epoch 607/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 68.6303 - accuracy: 0.5721 - val_loss: 21.5644 - val_accuracy: 0.6255\n",
      "Epoch 608/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 62.8016 - accuracy: 0.5642 - val_loss: 107.2769 - val_accuracy: 0.5703\n",
      "Epoch 609/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 48.3517 - accuracy: 0.5742 - val_loss: 77.4755 - val_accuracy: 0.5690\n",
      "Epoch 610/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.5129 - accuracy: 0.5742 - val_loss: 104.7392 - val_accuracy: 0.5703\n",
      "Epoch 611/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 63.0593 - accuracy: 0.5557 - val_loss: 119.5044 - val_accuracy: 0.4402\n",
      "Epoch 612/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 67.7539 - accuracy: 0.5534 - val_loss: 107.6002 - val_accuracy: 0.4389\n",
      "Epoch 613/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 79.7380 - accuracy: 0.5478 - val_loss: 33.1378 - val_accuracy: 0.6189\n",
      "Epoch 614/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 68.2265 - accuracy: 0.5612 - val_loss: 201.9113 - val_accuracy: 0.4323\n",
      "Epoch 615/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 48.2058 - accuracy: 0.5713 - val_loss: 31.6294 - val_accuracy: 0.6216\n",
      "Epoch 616/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 76.9789 - accuracy: 0.5563 - val_loss: 66.1674 - val_accuracy: 0.4586\n",
      "Epoch 617/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 49.9861 - accuracy: 0.5754 - val_loss: 42.9804 - val_accuracy: 0.6005\n",
      "Epoch 618/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 63.9642 - accuracy: 0.5617 - val_loss: 54.3880 - val_accuracy: 0.4783\n",
      "Epoch 619/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 91.9527 - accuracy: 0.5458 - val_loss: 211.4969 - val_accuracy: 0.5703\n",
      "Epoch 620/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 92.3180 - accuracy: 0.5530 - val_loss: 38.3340 - val_accuracy: 0.5256\n",
      "Epoch 621/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 81.4962 - accuracy: 0.5447 - val_loss: 58.0095 - val_accuracy: 0.5795\n",
      "Epoch 622/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 79.5083 - accuracy: 0.5404 - val_loss: 26.9679 - val_accuracy: 0.5821\n",
      "Epoch 623/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 73.0314 - accuracy: 0.5626 - val_loss: 30.1561 - val_accuracy: 0.5677\n",
      "Epoch 624/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 60.4019 - accuracy: 0.5765 - val_loss: 36.2447 - val_accuracy: 0.6110\n",
      "Epoch 625/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 44.5499 - accuracy: 0.5762 - val_loss: 39.5627 - val_accuracy: 0.5979\n",
      "Epoch 626/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 81.4203 - accuracy: 0.5289 - val_loss: 62.1571 - val_accuracy: 0.5742\n",
      "Epoch 627/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 71.1501 - accuracy: 0.5747 - val_loss: 41.8385 - val_accuracy: 0.5138\n",
      "Epoch 628/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 73.2312 - accuracy: 0.5452 - val_loss: 21.2967 - val_accuracy: 0.6557\n",
      "Epoch 629/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.6170 - accuracy: 0.5759 - val_loss: 22.9726 - val_accuracy: 0.5992\n",
      "Epoch 630/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 58.7328 - accuracy: 0.5545 - val_loss: 24.3530 - val_accuracy: 0.5966\n",
      "Epoch 631/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 61.2862 - accuracy: 0.5772 - val_loss: 230.6011 - val_accuracy: 0.5703\n",
      "Epoch 632/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.8311 - accuracy: 0.5732 - val_loss: 25.3895 - val_accuracy: 0.5887\n",
      "Epoch 633/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 50.6217 - accuracy: 0.5734 - val_loss: 30.5077 - val_accuracy: 0.6229\n",
      "Epoch 634/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 66.1888 - accuracy: 0.5529 - val_loss: 29.9586 - val_accuracy: 0.5637\n",
      "Epoch 635/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.0031 - accuracy: 0.5782 - val_loss: 28.6262 - val_accuracy: 0.6347\n",
      "Epoch 636/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 73.4484 - accuracy: 0.5493 - val_loss: 55.8329 - val_accuracy: 0.4757\n",
      "Epoch 637/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 38.5693 - accuracy: 0.5857 - val_loss: 34.4878 - val_accuracy: 0.5348\n",
      "Epoch 638/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.8865 - accuracy: 0.5736 - val_loss: 18.7407 - val_accuracy: 0.6544\n",
      "Epoch 639/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 79.9812 - accuracy: 0.5627 - val_loss: 53.7195 - val_accuracy: 0.4770\n",
      "Epoch 640/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 64.6562 - accuracy: 0.5665 - val_loss: 21.2679 - val_accuracy: 0.6544\n",
      "Epoch 641/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 36.8051 - accuracy: 0.5780 - val_loss: 57.6408 - val_accuracy: 0.4625\n",
      "Epoch 642/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 49.5635 - accuracy: 0.5711 - val_loss: 21.0044 - val_accuracy: 0.5979\n",
      "Epoch 643/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 73.8444 - accuracy: 0.5548 - val_loss: 247.9620 - val_accuracy: 0.5703\n",
      "Epoch 644/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 77.0552 - accuracy: 0.5806 - val_loss: 30.1921 - val_accuracy: 0.5677\n",
      "Epoch 645/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 69.8770 - accuracy: 0.5644 - val_loss: 238.4210 - val_accuracy: 0.5703\n",
      "Epoch 646/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 54.5565 - accuracy: 0.5673 - val_loss: 22.0666 - val_accuracy: 0.6478\n",
      "Epoch 647/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 61.9981 - accuracy: 0.5612 - val_loss: 145.9553 - val_accuracy: 0.4336\n",
      "Epoch 648/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 51.1440 - accuracy: 0.5683 - val_loss: 86.1316 - val_accuracy: 0.4468\n",
      "Epoch 649/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.6428 - accuracy: 0.5609 - val_loss: 79.3195 - val_accuracy: 0.5677\n",
      "Epoch 650/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 69.1941 - accuracy: 0.5645 - val_loss: 51.2534 - val_accuracy: 0.5887\n",
      "Epoch 651/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 64.9989 - accuracy: 0.5714 - val_loss: 19.1487 - val_accuracy: 0.6439\n",
      "Epoch 652/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 57.0440 - accuracy: 0.5683 - val_loss: 66.3387 - val_accuracy: 0.5703\n",
      "Epoch 653/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 55.7272 - accuracy: 0.5719 - val_loss: 92.1729 - val_accuracy: 0.4442\n",
      "Epoch 654/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 50.8430 - accuracy: 0.5780 - val_loss: 25.0089 - val_accuracy: 0.6360\n",
      "Epoch 655/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 93.0362 - accuracy: 0.5578 - val_loss: 29.2521 - val_accuracy: 0.5677\n",
      "Epoch 656/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 54.7597 - accuracy: 0.5606 - val_loss: 52.0700 - val_accuracy: 0.5808\n",
      "Epoch 657/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 54.1096 - accuracy: 0.5755 - val_loss: 28.0372 - val_accuracy: 0.6347\n",
      "Epoch 658/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 35.1582 - accuracy: 0.5933 - val_loss: 43.3837 - val_accuracy: 0.5848\n",
      "Epoch 659/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 83.8157 - accuracy: 0.5427 - val_loss: 18.5943 - val_accuracy: 0.6321\n",
      "Epoch 660/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.2928 - accuracy: 0.5644 - val_loss: 104.4049 - val_accuracy: 0.5703\n",
      "Epoch 661/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 95.2907 - accuracy: 0.5443 - val_loss: 62.8746 - val_accuracy: 0.5716\n",
      "Epoch 662/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 102.3250 - accuracy: 0.5376 - val_loss: 19.7319 - val_accuracy: 0.6570\n",
      "Epoch 663/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 56.7886 - accuracy: 0.5787 - val_loss: 19.9200 - val_accuracy: 0.6531\n",
      "Epoch 664/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 37.5009 - accuracy: 0.5842 - val_loss: 74.9579 - val_accuracy: 0.5716\n",
      "Epoch 665/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.4951 - accuracy: 0.5675 - val_loss: 65.9660 - val_accuracy: 0.4573\n",
      "Epoch 666/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 76.3081 - accuracy: 0.5696 - val_loss: 49.6120 - val_accuracy: 0.5795\n",
      "Epoch 667/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 57.8519 - accuracy: 0.5573 - val_loss: 85.2933 - val_accuracy: 0.4468\n",
      "Epoch 668/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 86.8882 - accuracy: 0.5525 - val_loss: 22.0555 - val_accuracy: 0.6452\n",
      "Epoch 669/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 42.4083 - accuracy: 0.5706 - val_loss: 25.3569 - val_accuracy: 0.5703\n",
      "Epoch 670/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 38.6952 - accuracy: 0.5841 - val_loss: 17.1352 - val_accuracy: 0.6334\n",
      "Epoch 671/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 60.9716 - accuracy: 0.5544 - val_loss: 152.2461 - val_accuracy: 0.5703\n",
      "Epoch 672/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 57.9717 - accuracy: 0.5639 - val_loss: 26.9613 - val_accuracy: 0.6216\n",
      "Epoch 673/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 43.4749 - accuracy: 0.5828 - val_loss: 21.2587 - val_accuracy: 0.5940\n",
      "Epoch 674/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 58.9027 - accuracy: 0.5677 - val_loss: 16.4786 - val_accuracy: 0.6360\n",
      "Epoch 675/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 56.6972 - accuracy: 0.5563 - val_loss: 26.3080 - val_accuracy: 0.5558\n",
      "Epoch 676/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 42.2114 - accuracy: 0.5829 - val_loss: 66.9444 - val_accuracy: 0.4612\n",
      "Epoch 677/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 59.0550 - accuracy: 0.5665 - val_loss: 160.7782 - val_accuracy: 0.4323\n",
      "Epoch 678/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 61.2416 - accuracy: 0.5555 - val_loss: 16.2440 - val_accuracy: 0.6557\n",
      "Epoch 679/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 39.5008 - accuracy: 0.5677 - val_loss: 66.0814 - val_accuracy: 0.5703\n",
      "Epoch 680/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 65.1105 - accuracy: 0.5631 - val_loss: 16.3497 - val_accuracy: 0.6544\n",
      "Epoch 681/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 37.6634 - accuracy: 0.5852 - val_loss: 16.7959 - val_accuracy: 0.6531\n",
      "Epoch 682/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 40.8604 - accuracy: 0.5706 - val_loss: 16.3459 - val_accuracy: 0.6242\n",
      "Epoch 683/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 52.2712 - accuracy: 0.5604 - val_loss: 94.4749 - val_accuracy: 0.5703\n",
      "Epoch 684/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 78.8951 - accuracy: 0.5368 - val_loss: 47.7800 - val_accuracy: 0.4639\n",
      "Epoch 685/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 59.8064 - accuracy: 0.5644 - val_loss: 16.1455 - val_accuracy: 0.6610\n",
      "Epoch 686/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 38.3537 - accuracy: 0.5724 - val_loss: 15.1182 - val_accuracy: 0.6347\n",
      "Epoch 687/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 35.8506 - accuracy: 0.5872 - val_loss: 52.6062 - val_accuracy: 0.4547\n",
      "Epoch 688/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 45.2001 - accuracy: 0.5670 - val_loss: 18.1932 - val_accuracy: 0.6478\n",
      "Epoch 689/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 92.8359 - accuracy: 0.5378 - val_loss: 18.7711 - val_accuracy: 0.5953\n",
      "Epoch 690/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 48.8283 - accuracy: 0.5654 - val_loss: 14.4924 - val_accuracy: 0.6426\n",
      "Epoch 691/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 51.2921 - accuracy: 0.5718 - val_loss: 64.3513 - val_accuracy: 0.4599\n",
      "Epoch 692/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.0841 - accuracy: 0.5568 - val_loss: 22.8383 - val_accuracy: 0.6242\n",
      "Epoch 693/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.4356 - accuracy: 0.5849 - val_loss: 44.2632 - val_accuracy: 0.5729\n",
      "Epoch 694/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 50.7307 - accuracy: 0.5612 - val_loss: 84.4006 - val_accuracy: 0.5703\n",
      "Epoch 695/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 61.9398 - accuracy: 0.5425 - val_loss: 29.5335 - val_accuracy: 0.5191\n",
      "Epoch 696/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.3975 - accuracy: 0.5629 - val_loss: 30.2738 - val_accuracy: 0.6071\n",
      "Epoch 697/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.3592 - accuracy: 0.5713 - val_loss: 14.6257 - val_accuracy: 0.6583\n",
      "Epoch 698/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 39.7333 - accuracy: 0.5713 - val_loss: 55.1465 - val_accuracy: 0.5703\n",
      "Epoch 699/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 57.9416 - accuracy: 0.5552 - val_loss: 13.6872 - val_accuracy: 0.6452\n",
      "Epoch 700/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 52.0706 - accuracy: 0.5484 - val_loss: 21.1739 - val_accuracy: 0.5664\n",
      "Epoch 701/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 48.2128 - accuracy: 0.5732 - val_loss: 121.7880 - val_accuracy: 0.4336\n",
      "Epoch 702/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 52.2716 - accuracy: 0.5770 - val_loss: 14.6555 - val_accuracy: 0.6544\n",
      "Epoch 703/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 79.8139 - accuracy: 0.5534 - val_loss: 212.2356 - val_accuracy: 0.5703\n",
      "Epoch 704/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 123.4434 - accuracy: 0.5202 - val_loss: 20.0659 - val_accuracy: 0.5742\n",
      "Epoch 705/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 45.1896 - accuracy: 0.5627 - val_loss: 66.2562 - val_accuracy: 0.5703\n",
      "Epoch 706/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 54.4411 - accuracy: 0.5547 - val_loss: 63.8034 - val_accuracy: 0.4560\n",
      "Epoch 707/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.0188 - accuracy: 0.5882 - val_loss: 32.5566 - val_accuracy: 0.4888\n",
      "Epoch 708/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 113.8937 - accuracy: 0.5396 - val_loss: 164.5828 - val_accuracy: 0.5703\n",
      "Epoch 709/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 67.5188 - accuracy: 0.5407 - val_loss: 39.0344 - val_accuracy: 0.5782\n",
      "Epoch 710/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.6246 - accuracy: 0.5588 - val_loss: 29.9195 - val_accuracy: 0.5072\n",
      "Epoch 711/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 54.0704 - accuracy: 0.5560 - val_loss: 143.9944 - val_accuracy: 0.5703\n",
      "Epoch 712/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.7179 - accuracy: 0.5466 - val_loss: 28.0049 - val_accuracy: 0.5125\n",
      "Epoch 713/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.5747 - accuracy: 0.5570 - val_loss: 15.7253 - val_accuracy: 0.6032\n",
      "Epoch 714/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 50.6730 - accuracy: 0.5521 - val_loss: 28.8412 - val_accuracy: 0.5099\n",
      "Epoch 715/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 54.2255 - accuracy: 0.5688 - val_loss: 25.3863 - val_accuracy: 0.5191\n",
      "Epoch 716/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.6141 - accuracy: 0.5629 - val_loss: 20.2855 - val_accuracy: 0.5664\n",
      "Epoch 717/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 66.3841 - accuracy: 0.5539 - val_loss: 15.4739 - val_accuracy: 0.6045\n",
      "Epoch 718/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.7957 - accuracy: 0.5548 - val_loss: 41.2791 - val_accuracy: 0.5729\n",
      "Epoch 719/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 56.7334 - accuracy: 0.5626 - val_loss: 43.6425 - val_accuracy: 0.5729\n",
      "Epoch 720/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 49.5843 - accuracy: 0.5678 - val_loss: 13.2687 - val_accuracy: 0.6636\n",
      "Epoch 721/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 69.3537 - accuracy: 0.5404 - val_loss: 21.0851 - val_accuracy: 0.6242\n",
      "Epoch 722/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 42.2206 - accuracy: 0.5734 - val_loss: 27.8247 - val_accuracy: 0.5085\n",
      "Epoch 723/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 64.5889 - accuracy: 0.5540 - val_loss: 72.1265 - val_accuracy: 0.5703\n",
      "Epoch 724/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 106.9562 - accuracy: 0.5325 - val_loss: 107.4412 - val_accuracy: 0.5703\n",
      "Epoch 725/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 43.0872 - accuracy: 0.5660 - val_loss: 26.2216 - val_accuracy: 0.6058\n",
      "Epoch 726/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 43.5770 - accuracy: 0.5724 - val_loss: 40.4089 - val_accuracy: 0.4678\n",
      "Epoch 727/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 52.2742 - accuracy: 0.5498 - val_loss: 94.2180 - val_accuracy: 0.5703\n",
      "Epoch 728/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 76.5314 - accuracy: 0.5432 - val_loss: 13.4618 - val_accuracy: 0.6255\n",
      "Epoch 729/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 41.9972 - accuracy: 0.5593 - val_loss: 45.7644 - val_accuracy: 0.4599\n",
      "Epoch 730/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.0321 - accuracy: 0.5749 - val_loss: 26.7991 - val_accuracy: 0.5099\n",
      "Epoch 731/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 82.0418 - accuracy: 0.5414 - val_loss: 54.1271 - val_accuracy: 0.5690\n",
      "Epoch 732/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 60.0718 - accuracy: 0.5409 - val_loss: 73.0699 - val_accuracy: 0.4442\n",
      "Epoch 733/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 59.7190 - accuracy: 0.5386 - val_loss: 12.5048 - val_accuracy: 0.6491\n",
      "Epoch 734/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 50.7990 - accuracy: 0.5624 - val_loss: 43.8788 - val_accuracy: 0.4612\n",
      "Epoch 735/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 52.3538 - accuracy: 0.5530 - val_loss: 12.4177 - val_accuracy: 0.6491\n",
      "Epoch 736/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.7690 - accuracy: 0.5453 - val_loss: 13.2991 - val_accuracy: 0.6623\n",
      "Epoch 737/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 40.5274 - accuracy: 0.5614 - val_loss: 78.6628 - val_accuracy: 0.5703\n",
      "Epoch 738/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 71.2550 - accuracy: 0.5437 - val_loss: 160.2781 - val_accuracy: 0.4323\n",
      "Epoch 739/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 69.2878 - accuracy: 0.5494 - val_loss: 113.5035 - val_accuracy: 0.5703\n",
      "Epoch 740/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.8809 - accuracy: 0.5571 - val_loss: 155.9119 - val_accuracy: 0.5703\n",
      "Epoch 741/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 65.1459 - accuracy: 0.5429 - val_loss: 113.7244 - val_accuracy: 0.5703\n",
      "Epoch 742/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 58.1852 - accuracy: 0.5501 - val_loss: 101.1628 - val_accuracy: 0.4336\n",
      "Epoch 743/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 34.8331 - accuracy: 0.5711 - val_loss: 17.0700 - val_accuracy: 0.5821\n",
      "Epoch 744/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 55.4035 - accuracy: 0.5568 - val_loss: 12.1072 - val_accuracy: 0.6321\n",
      "Epoch 745/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 53.4237 - accuracy: 0.5491 - val_loss: 11.9788 - val_accuracy: 0.6478\n",
      "Epoch 746/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 51.0939 - accuracy: 0.5609 - val_loss: 103.4480 - val_accuracy: 0.4336\n",
      "Epoch 747/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 39.2689 - accuracy: 0.5616 - val_loss: 13.6692 - val_accuracy: 0.6505\n",
      "Epoch 748/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 42.2184 - accuracy: 0.5752 - val_loss: 13.2813 - val_accuracy: 0.6505\n",
      "Epoch 749/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 42.1657 - accuracy: 0.5560 - val_loss: 47.1965 - val_accuracy: 0.5703\n",
      "Epoch 750/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 45.5285 - accuracy: 0.5586 - val_loss: 63.2186 - val_accuracy: 0.4442\n",
      "Epoch 751/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 34.9594 - accuracy: 0.5690 - val_loss: 11.4959 - val_accuracy: 0.6452\n",
      "Epoch 752/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 48.3048 - accuracy: 0.5494 - val_loss: 59.2403 - val_accuracy: 0.5703\n",
      "Epoch 753/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 48.0451 - accuracy: 0.5604 - val_loss: 88.4584 - val_accuracy: 0.5703\n",
      "Epoch 754/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 41.1284 - accuracy: 0.5509 - val_loss: 11.4291 - val_accuracy: 0.6321\n",
      "Epoch 755/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 49.6876 - accuracy: 0.5529 - val_loss: 14.9224 - val_accuracy: 0.5913\n",
      "Epoch 756/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 56.2327 - accuracy: 0.5468 - val_loss: 14.5062 - val_accuracy: 0.5979\n",
      "Epoch 757/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 41.7531 - accuracy: 0.5645 - val_loss: 46.9347 - val_accuracy: 0.5703\n",
      "Epoch 758/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 65.3244 - accuracy: 0.5417 - val_loss: 65.2447 - val_accuracy: 0.5703\n",
      "Epoch 759/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.8309 - accuracy: 0.5527 - val_loss: 49.8891 - val_accuracy: 0.4665\n",
      "Epoch 760/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 64.3020 - accuracy: 0.5407 - val_loss: 12.5234 - val_accuracy: 0.6544\n",
      "Epoch 761/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 42.8786 - accuracy: 0.5654 - val_loss: 28.5604 - val_accuracy: 0.5874\n",
      "Epoch 762/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 66.8690 - accuracy: 0.5481 - val_loss: 24.5773 - val_accuracy: 0.5099\n",
      "Epoch 763/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 44.9815 - accuracy: 0.5596 - val_loss: 60.3507 - val_accuracy: 0.4468\n",
      "Epoch 764/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 44.6006 - accuracy: 0.5626 - val_loss: 15.5376 - val_accuracy: 0.6386\n",
      "Epoch 765/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 32.2539 - accuracy: 0.5734 - val_loss: 13.9254 - val_accuracy: 0.5966\n",
      "Epoch 766/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 57.3252 - accuracy: 0.5534 - val_loss: 50.7120 - val_accuracy: 0.5703\n",
      "Epoch 767/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 61.7576 - accuracy: 0.5494 - val_loss: 12.9033 - val_accuracy: 0.6032\n",
      "Epoch 768/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 50.5511 - accuracy: 0.5394 - val_loss: 252.5510 - val_accuracy: 0.4310\n",
      "Epoch 769/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 71.0712 - accuracy: 0.5465 - val_loss: 35.8642 - val_accuracy: 0.4639\n",
      "Epoch 770/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.5630 - accuracy: 0.5757 - val_loss: 17.0952 - val_accuracy: 0.5558\n",
      "Epoch 771/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 42.5761 - accuracy: 0.5626 - val_loss: 12.4517 - val_accuracy: 0.6518\n",
      "Epoch 772/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 55.4240 - accuracy: 0.5430 - val_loss: 114.1322 - val_accuracy: 0.5703\n",
      "Epoch 773/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 64.8943 - accuracy: 0.5506 - val_loss: 11.9046 - val_accuracy: 0.6478\n",
      "Epoch 774/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 36.1434 - accuracy: 0.5744 - val_loss: 146.7979 - val_accuracy: 0.4323\n",
      "Epoch 775/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 40.8218 - accuracy: 0.5649 - val_loss: 46.0976 - val_accuracy: 0.4639\n",
      "Epoch 776/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 32.6513 - accuracy: 0.5609 - val_loss: 55.2352 - val_accuracy: 0.4494\n",
      "Epoch 777/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.2284 - accuracy: 0.5424 - val_loss: 13.3435 - val_accuracy: 0.6465\n",
      "Epoch 778/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 42.8320 - accuracy: 0.5585 - val_loss: 71.6855 - val_accuracy: 0.5703\n",
      "Epoch 779/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 40.8106 - accuracy: 0.5560 - val_loss: 34.8519 - val_accuracy: 0.5742\n",
      "Epoch 780/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 43.7993 - accuracy: 0.5433 - val_loss: 56.2404 - val_accuracy: 0.5703\n",
      "Epoch 781/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 81.3096 - accuracy: 0.5225 - val_loss: 134.0945 - val_accuracy: 0.4323\n",
      "Epoch 782/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 65.4327 - accuracy: 0.5473 - val_loss: 124.0941 - val_accuracy: 0.5703\n",
      "Epoch 783/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 37.7635 - accuracy: 0.5782 - val_loss: 55.2513 - val_accuracy: 0.5703\n",
      "Epoch 784/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.0360 - accuracy: 0.5667 - val_loss: 23.8601 - val_accuracy: 0.5007\n",
      "Epoch 785/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 57.2446 - accuracy: 0.5435 - val_loss: 12.2918 - val_accuracy: 0.6465\n",
      "Epoch 786/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 42.2302 - accuracy: 0.5611 - val_loss: 67.5530 - val_accuracy: 0.4442\n",
      "Epoch 787/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 57.7937 - accuracy: 0.5461 - val_loss: 46.8052 - val_accuracy: 0.5703\n",
      "Epoch 788/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 38.5666 - accuracy: 0.5560 - val_loss: 32.7824 - val_accuracy: 0.5742\n",
      "Epoch 789/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 41.7082 - accuracy: 0.5560 - val_loss: 27.9284 - val_accuracy: 0.5795\n",
      "Epoch 790/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 56.2010 - accuracy: 0.5369 - val_loss: 53.9687 - val_accuracy: 0.4494\n",
      "Epoch 791/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 32.0825 - accuracy: 0.5785 - val_loss: 25.1009 - val_accuracy: 0.4928\n",
      "Epoch 792/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.2173 - accuracy: 0.5476 - val_loss: 32.2717 - val_accuracy: 0.4625\n",
      "Epoch 793/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 61.3084 - accuracy: 0.5608 - val_loss: 9.4046 - val_accuracy: 0.6649\n",
      "Epoch 794/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 38.4539 - accuracy: 0.5614 - val_loss: 9.7745 - val_accuracy: 0.6242\n",
      "Epoch 795/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.6355 - accuracy: 0.5708 - val_loss: 123.2896 - val_accuracy: 0.5703\n",
      "Epoch 796/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 32.7054 - accuracy: 0.5713 - val_loss: 12.9402 - val_accuracy: 0.6347\n",
      "Epoch 797/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 59.4307 - accuracy: 0.5337 - val_loss: 32.0363 - val_accuracy: 0.4639\n",
      "Epoch 798/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 66.3692 - accuracy: 0.5440 - val_loss: 137.4944 - val_accuracy: 0.5703\n",
      "Epoch 799/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 50.5441 - accuracy: 0.5476 - val_loss: 109.9429 - val_accuracy: 0.4336\n",
      "Epoch 800/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 42.8904 - accuracy: 0.5473 - val_loss: 11.4479 - val_accuracy: 0.6465\n",
      "Epoch 801/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 53.0954 - accuracy: 0.5412 - val_loss: 126.2101 - val_accuracy: 0.5703\n",
      "Epoch 802/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 55.6968 - accuracy: 0.5404 - val_loss: 80.0421 - val_accuracy: 0.5703\n",
      "Epoch 803/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 50.4305 - accuracy: 0.5456 - val_loss: 39.0676 - val_accuracy: 0.5703\n",
      "Epoch 804/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 35.5608 - accuracy: 0.5627 - val_loss: 9.1856 - val_accuracy: 0.6137\n",
      "Epoch 805/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 53.0592 - accuracy: 0.5499 - val_loss: 36.1208 - val_accuracy: 0.4652\n",
      "Epoch 806/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 41.3547 - accuracy: 0.5525 - val_loss: 12.5028 - val_accuracy: 0.6321\n",
      "Epoch 807/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 43.7432 - accuracy: 0.5381 - val_loss: 49.6292 - val_accuracy: 0.4468\n",
      "Epoch 808/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 27.6515 - accuracy: 0.5665 - val_loss: 27.4224 - val_accuracy: 0.4639\n",
      "Epoch 809/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.8918 - accuracy: 0.5657 - val_loss: 50.0253 - val_accuracy: 0.5703\n",
      "Epoch 810/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 44.7808 - accuracy: 0.5343 - val_loss: 160.7331 - val_accuracy: 0.4310\n",
      "Epoch 811/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 37.7327 - accuracy: 0.5598 - val_loss: 37.4765 - val_accuracy: 0.5703\n",
      "Epoch 812/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 50.6096 - accuracy: 0.5512 - val_loss: 51.9982 - val_accuracy: 0.4428\n",
      "Epoch 813/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 63.3756 - accuracy: 0.5278 - val_loss: 119.7977 - val_accuracy: 0.5703\n",
      "Epoch 814/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 53.7487 - accuracy: 0.5276 - val_loss: 22.9292 - val_accuracy: 0.5834\n",
      "Epoch 815/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 49.6502 - accuracy: 0.5309 - val_loss: 43.2091 - val_accuracy: 0.4547\n",
      "Epoch 816/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 30.5150 - accuracy: 0.5458 - val_loss: 19.3748 - val_accuracy: 0.5887\n",
      "Epoch 817/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 42.0994 - accuracy: 0.5463 - val_loss: 17.0324 - val_accuracy: 0.5979\n",
      "Epoch 818/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 42.5553 - accuracy: 0.5535 - val_loss: 70.8752 - val_accuracy: 0.5703\n",
      "Epoch 819/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 36.7883 - accuracy: 0.5629 - val_loss: 43.8690 - val_accuracy: 0.5703\n",
      "Epoch 820/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 38.6920 - accuracy: 0.5438 - val_loss: 93.2247 - val_accuracy: 0.5703\n",
      "Epoch 821/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 61.4084 - accuracy: 0.5153 - val_loss: 103.3241 - val_accuracy: 0.4336\n",
      "Epoch 822/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 37.4263 - accuracy: 0.5379 - val_loss: 101.5773 - val_accuracy: 0.4336\n",
      "Epoch 823/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 30.4284 - accuracy: 0.5545 - val_loss: 51.0090 - val_accuracy: 0.4442\n",
      "Epoch 824/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 54.3129 - accuracy: 0.5407 - val_loss: 22.8869 - val_accuracy: 0.4717\n",
      "Epoch 825/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 43.4947 - accuracy: 0.5458 - val_loss: 20.5599 - val_accuracy: 0.4757\n",
      "Epoch 826/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 67.6711 - accuracy: 0.5156 - val_loss: 43.3620 - val_accuracy: 0.5703\n",
      "Epoch 827/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 34.3028 - accuracy: 0.5608 - val_loss: 16.6004 - val_accuracy: 0.5940\n",
      "Epoch 828/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 35.4084 - accuracy: 0.5491 - val_loss: 79.9790 - val_accuracy: 0.5703\n",
      "Epoch 829/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 30.8507 - accuracy: 0.5589 - val_loss: 111.8111 - val_accuracy: 0.4323\n",
      "Epoch 830/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 49.8745 - accuracy: 0.5384 - val_loss: 18.0700 - val_accuracy: 0.5007\n",
      "Epoch 831/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 32.1311 - accuracy: 0.5509 - val_loss: 13.6398 - val_accuracy: 0.6110\n",
      "Epoch 832/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.4913 - accuracy: 0.5453 - val_loss: 83.8141 - val_accuracy: 0.5703\n",
      "Epoch 833/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 24.5194 - accuracy: 0.5681 - val_loss: 9.8955 - val_accuracy: 0.5953\n",
      "Epoch 834/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.7469 - accuracy: 0.5529 - val_loss: 191.6192 - val_accuracy: 0.5703\n",
      "Epoch 835/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 47.2100 - accuracy: 0.5378 - val_loss: 85.2067 - val_accuracy: 0.4336\n",
      "Epoch 836/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 49.7941 - accuracy: 0.5414 - val_loss: 72.8995 - val_accuracy: 0.4363\n",
      "Epoch 837/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 30.5665 - accuracy: 0.5614 - val_loss: 21.9418 - val_accuracy: 0.5769\n",
      "Epoch 838/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.6140 - accuracy: 0.5560 - val_loss: 7.1001 - val_accuracy: 0.6597\n",
      "Epoch 839/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.9951 - accuracy: 0.5594 - val_loss: 19.5298 - val_accuracy: 0.4941\n",
      "Epoch 840/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 38.1539 - accuracy: 0.5430 - val_loss: 12.9730 - val_accuracy: 0.6163\n",
      "Epoch 841/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 27.9757 - accuracy: 0.5695 - val_loss: 18.0187 - val_accuracy: 0.5020\n",
      "Epoch 842/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 38.0708 - accuracy: 0.5550 - val_loss: 78.3736 - val_accuracy: 0.5703\n",
      "Epoch 843/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.9317 - accuracy: 0.5458 - val_loss: 8.3453 - val_accuracy: 0.6071\n",
      "Epoch 844/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 44.8278 - accuracy: 0.5498 - val_loss: 68.9858 - val_accuracy: 0.4376\n",
      "Epoch 845/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 35.5137 - accuracy: 0.5527 - val_loss: 9.9764 - val_accuracy: 0.5966\n",
      "Epoch 846/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 28.8757 - accuracy: 0.5496 - val_loss: 22.5745 - val_accuracy: 0.5756\n",
      "Epoch 847/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 52.1323 - accuracy: 0.5351 - val_loss: 55.0905 - val_accuracy: 0.5703\n",
      "Epoch 848/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.5577 - accuracy: 0.5662 - val_loss: 57.2223 - val_accuracy: 0.5703\n",
      "Epoch 849/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 23.4684 - accuracy: 0.5701 - val_loss: 38.2753 - val_accuracy: 0.5703\n",
      "Epoch 850/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 22.2232 - accuracy: 0.5729 - val_loss: 28.7702 - val_accuracy: 0.5716\n",
      "Epoch 851/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 44.4240 - accuracy: 0.5486 - val_loss: 103.4942 - val_accuracy: 0.5703\n",
      "Epoch 852/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 34.9219 - accuracy: 0.5550 - val_loss: 45.1520 - val_accuracy: 0.4481\n",
      "Epoch 853/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 28.2185 - accuracy: 0.5711 - val_loss: 104.0076 - val_accuracy: 0.4336\n",
      "Epoch 854/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 32.2038 - accuracy: 0.5696 - val_loss: 66.3396 - val_accuracy: 0.5703\n",
      "Epoch 855/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 47.8998 - accuracy: 0.5240 - val_loss: 8.9532 - val_accuracy: 0.6505\n",
      "Epoch 856/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 34.7040 - accuracy: 0.5530 - val_loss: 90.3683 - val_accuracy: 0.5703\n",
      "Epoch 857/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 31.1603 - accuracy: 0.5570 - val_loss: 10.9154 - val_accuracy: 0.6360\n",
      "Epoch 858/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 27.9535 - accuracy: 0.5686 - val_loss: 108.0611 - val_accuracy: 0.4323\n",
      "Epoch 859/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 40.0846 - accuracy: 0.5555 - val_loss: 29.9253 - val_accuracy: 0.5703\n",
      "Epoch 860/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 41.1336 - accuracy: 0.5586 - val_loss: 16.9514 - val_accuracy: 0.5033\n",
      "Epoch 861/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 25.1493 - accuracy: 0.5672 - val_loss: 11.1456 - val_accuracy: 0.5716\n",
      "Epoch 862/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 32.1491 - accuracy: 0.5532 - val_loss: 17.6370 - val_accuracy: 0.5887\n",
      "Epoch 863/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 45.2342 - accuracy: 0.5502 - val_loss: 8.2922 - val_accuracy: 0.6071\n",
      "Epoch 864/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 48.5758 - accuracy: 0.5350 - val_loss: 39.0442 - val_accuracy: 0.4534\n",
      "Epoch 865/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.6521 - accuracy: 0.5548 - val_loss: 47.1267 - val_accuracy: 0.4442\n",
      "Epoch 866/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 40.1050 - accuracy: 0.5471 - val_loss: 10.9176 - val_accuracy: 0.5769\n",
      "Epoch 867/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 42.9636 - accuracy: 0.5401 - val_loss: 26.7992 - val_accuracy: 0.4678\n",
      "Epoch 868/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 21.2166 - accuracy: 0.5637 - val_loss: 12.8459 - val_accuracy: 0.6202\n",
      "Epoch 869/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 24.5210 - accuracy: 0.5823 - val_loss: 12.1712 - val_accuracy: 0.6229\n",
      "Epoch 870/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 65.1222 - accuracy: 0.5342 - val_loss: 48.7731 - val_accuracy: 0.5703\n",
      "Epoch 871/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 40.5228 - accuracy: 0.5361 - val_loss: 124.0107 - val_accuracy: 0.5703\n",
      "Epoch 872/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 39.9402 - accuracy: 0.5512 - val_loss: 60.0607 - val_accuracy: 0.5703\n",
      "Epoch 873/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 30.8984 - accuracy: 0.5598 - val_loss: 80.8076 - val_accuracy: 0.4336\n",
      "Epoch 874/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.3675 - accuracy: 0.5709 - val_loss: 76.5952 - val_accuracy: 0.4350\n",
      "Epoch 875/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 40.4254 - accuracy: 0.5539 - val_loss: 10.4868 - val_accuracy: 0.5900\n",
      "Epoch 876/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 24.8296 - accuracy: 0.5703 - val_loss: 41.3733 - val_accuracy: 0.4547\n",
      "Epoch 877/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 24.6398 - accuracy: 0.5632 - val_loss: 32.3147 - val_accuracy: 0.4612\n",
      "Epoch 878/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 39.0047 - accuracy: 0.5599 - val_loss: 99.6672 - val_accuracy: 0.5703\n",
      "Epoch 879/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 36.1703 - accuracy: 0.5424 - val_loss: 75.8385 - val_accuracy: 0.4350\n",
      "Epoch 880/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 22.0781 - accuracy: 0.5644 - val_loss: 16.2634 - val_accuracy: 0.5099\n",
      "Epoch 881/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 38.1673 - accuracy: 0.5544 - val_loss: 70.7292 - val_accuracy: 0.4363\n",
      "Epoch 882/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.8605 - accuracy: 0.5693 - val_loss: 51.4557 - val_accuracy: 0.5703\n",
      "Epoch 883/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 37.5040 - accuracy: 0.5581 - val_loss: 16.1567 - val_accuracy: 0.5099\n",
      "Epoch 884/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 39.1283 - accuracy: 0.5353 - val_loss: 7.2775 - val_accuracy: 0.6636\n",
      "Epoch 885/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.3782 - accuracy: 0.5635 - val_loss: 135.0906 - val_accuracy: 0.5703\n",
      "Epoch 886/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.2290 - accuracy: 0.5521 - val_loss: 31.5110 - val_accuracy: 0.5703\n",
      "Epoch 887/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 32.2430 - accuracy: 0.5539 - val_loss: 67.7088 - val_accuracy: 0.4376\n",
      "Epoch 888/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 38.0975 - accuracy: 0.5417 - val_loss: 94.4131 - val_accuracy: 0.4336\n",
      "Epoch 889/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.4680 - accuracy: 0.5673 - val_loss: 46.9513 - val_accuracy: 0.5703\n",
      "Epoch 890/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 39.1009 - accuracy: 0.5422 - val_loss: 13.6338 - val_accuracy: 0.6150\n",
      "Epoch 891/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 42.9114 - accuracy: 0.5433 - val_loss: 13.5619 - val_accuracy: 0.6189\n",
      "Epoch 892/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.0103 - accuracy: 0.5437 - val_loss: 21.5774 - val_accuracy: 0.4770\n",
      "Epoch 893/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 43.3051 - accuracy: 0.5521 - val_loss: 162.1682 - val_accuracy: 0.4310\n",
      "Epoch 894/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 40.3741 - accuracy: 0.5588 - val_loss: 48.2623 - val_accuracy: 0.5703\n",
      "Epoch 895/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 25.1525 - accuracy: 0.5675 - val_loss: 34.7180 - val_accuracy: 0.5703\n",
      "Epoch 896/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 23.6024 - accuracy: 0.5768 - val_loss: 15.8032 - val_accuracy: 0.5138\n",
      "Epoch 897/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 35.7668 - accuracy: 0.5568 - val_loss: 51.8273 - val_accuracy: 0.5703\n",
      "Epoch 898/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 41.3545 - accuracy: 0.5386 - val_loss: 47.8807 - val_accuracy: 0.4428\n",
      "Epoch 899/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 37.1280 - accuracy: 0.5575 - val_loss: 43.9873 - val_accuracy: 0.4494\n",
      "Epoch 900/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 39.1520 - accuracy: 0.5616 - val_loss: 38.9050 - val_accuracy: 0.5703\n",
      "Epoch 901/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 28.7652 - accuracy: 0.5700 - val_loss: 62.1239 - val_accuracy: 0.5703\n",
      "Epoch 902/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 20.0656 - accuracy: 0.5747 - val_loss: 92.2471 - val_accuracy: 0.5703\n",
      "Epoch 903/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 30.6258 - accuracy: 0.5606 - val_loss: 36.4477 - val_accuracy: 0.5703\n",
      "Epoch 904/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.1115 - accuracy: 0.5593 - val_loss: 36.6144 - val_accuracy: 0.4586\n",
      "Epoch 905/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.8611 - accuracy: 0.5591 - val_loss: 17.9026 - val_accuracy: 0.5887\n",
      "Epoch 906/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 29.3805 - accuracy: 0.5580 - val_loss: 9.1424 - val_accuracy: 0.6465\n",
      "Epoch 907/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.9524 - accuracy: 0.5675 - val_loss: 7.1812 - val_accuracy: 0.6360\n",
      "Epoch 908/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 30.6787 - accuracy: 0.5494 - val_loss: 21.9082 - val_accuracy: 0.4717\n",
      "Epoch 909/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 27.4726 - accuracy: 0.5609 - val_loss: 40.9636 - val_accuracy: 0.4547\n",
      "Epoch 910/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 35.7249 - accuracy: 0.5581 - val_loss: 12.1953 - val_accuracy: 0.5466\n",
      "Epoch 911/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 37.3916 - accuracy: 0.5366 - val_loss: 8.7475 - val_accuracy: 0.6478\n",
      "Epoch 912/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 26.4842 - accuracy: 0.5502 - val_loss: 15.7044 - val_accuracy: 0.5099\n",
      "Epoch 913/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 33.7061 - accuracy: 0.5473 - val_loss: 48.8582 - val_accuracy: 0.5703\n",
      "Epoch 914/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 34.6967 - accuracy: 0.5650 - val_loss: 21.1193 - val_accuracy: 0.5782\n",
      "Epoch 915/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 27.8130 - accuracy: 0.5606 - val_loss: 34.5032 - val_accuracy: 0.5703\n",
      "Epoch 916/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 26.2087 - accuracy: 0.5683 - val_loss: 20.8984 - val_accuracy: 0.4770\n",
      "Epoch 917/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 31.5463 - accuracy: 0.5489 - val_loss: 30.6434 - val_accuracy: 0.4625\n",
      "Epoch 918/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 25.4868 - accuracy: 0.5539 - val_loss: 93.2530 - val_accuracy: 0.5703\n",
      "Epoch 919/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 37.5714 - accuracy: 0.5603 - val_loss: 23.3688 - val_accuracy: 0.4652\n",
      "Epoch 920/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 28.8938 - accuracy: 0.5649 - val_loss: 21.8046 - val_accuracy: 0.5756\n",
      "Epoch 921/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 26.0582 - accuracy: 0.5553 - val_loss: 15.1190 - val_accuracy: 0.5177\n",
      "Epoch 922/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 26.1052 - accuracy: 0.5614 - val_loss: 54.8392 - val_accuracy: 0.5703\n",
      "Epoch 923/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 18.7007 - accuracy: 0.5826 - val_loss: 72.9786 - val_accuracy: 0.4363\n",
      "Epoch 924/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 20.0800 - accuracy: 0.5823 - val_loss: 14.8810 - val_accuracy: 0.6005\n",
      "Epoch 925/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 27.8219 - accuracy: 0.5609 - val_loss: 72.7663 - val_accuracy: 0.4363\n",
      "Epoch 926/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 24.0374 - accuracy: 0.5683 - val_loss: 15.2472 - val_accuracy: 0.5138\n",
      "Epoch 927/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 46.4642 - accuracy: 0.5320 - val_loss: 12.3034 - val_accuracy: 0.5493\n",
      "Epoch 928/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 23.7368 - accuracy: 0.5598 - val_loss: 12.8928 - val_accuracy: 0.6124\n",
      "Epoch 929/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 23.9978 - accuracy: 0.5711 - val_loss: 27.5429 - val_accuracy: 0.4678\n",
      "Epoch 930/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 20.7468 - accuracy: 0.5788 - val_loss: 15.5066 - val_accuracy: 0.5099\n",
      "Epoch 931/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 30.6309 - accuracy: 0.5460 - val_loss: 97.5125 - val_accuracy: 0.4336\n",
      "Epoch 932/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 21.7106 - accuracy: 0.5800 - val_loss: 13.4467 - val_accuracy: 0.5230\n",
      "Epoch 933/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 25.4502 - accuracy: 0.5594 - val_loss: 80.0955 - val_accuracy: 0.5703\n",
      "Epoch 934/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 24.4964 - accuracy: 0.5621 - val_loss: 13.9018 - val_accuracy: 0.5217\n",
      "Epoch 935/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 32.4088 - accuracy: 0.5417 - val_loss: 68.9292 - val_accuracy: 0.5703\n",
      "Epoch 936/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.7227 - accuracy: 0.5585 - val_loss: 18.1462 - val_accuracy: 0.4941\n",
      "Epoch 937/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 21.4482 - accuracy: 0.5686 - val_loss: 6.7890 - val_accuracy: 0.6715\n",
      "Epoch 938/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 31.7817 - accuracy: 0.5540 - val_loss: 37.2224 - val_accuracy: 0.4560\n",
      "Epoch 939/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 26.2740 - accuracy: 0.5686 - val_loss: 8.2727 - val_accuracy: 0.5966\n",
      "Epoch 940/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 31.6257 - accuracy: 0.5598 - val_loss: 58.7105 - val_accuracy: 0.5703\n",
      "Epoch 941/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.3297 - accuracy: 0.5872 - val_loss: 15.8474 - val_accuracy: 0.5887\n",
      "Epoch 942/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 15.5005 - accuracy: 0.5859 - val_loss: 7.1540 - val_accuracy: 0.6478\n",
      "Epoch 943/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 33.0639 - accuracy: 0.5718 - val_loss: 19.4187 - val_accuracy: 0.5769\n",
      "Epoch 944/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 34.3730 - accuracy: 0.5532 - val_loss: 13.9999 - val_accuracy: 0.5992\n",
      "Epoch 945/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 26.7579 - accuracy: 0.5470 - val_loss: 34.0835 - val_accuracy: 0.5703\n",
      "Epoch 946/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 27.0246 - accuracy: 0.5565 - val_loss: 25.2492 - val_accuracy: 0.5703\n",
      "Epoch 947/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 23.5086 - accuracy: 0.5673 - val_loss: 35.6010 - val_accuracy: 0.4586\n",
      "Epoch 948/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 16.5918 - accuracy: 0.5860 - val_loss: 35.3957 - val_accuracy: 0.4586\n",
      "Epoch 949/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.8744 - accuracy: 0.5824 - val_loss: 6.3902 - val_accuracy: 0.6662\n",
      "Epoch 950/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 36.2201 - accuracy: 0.5498 - val_loss: 24.6281 - val_accuracy: 0.4678\n",
      "Epoch 951/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 20.2144 - accuracy: 0.5693 - val_loss: 51.1450 - val_accuracy: 0.5703\n",
      "Epoch 952/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 23.8356 - accuracy: 0.5662 - val_loss: 36.8151 - val_accuracy: 0.5703\n",
      "Epoch 953/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 25.4449 - accuracy: 0.5693 - val_loss: 6.0037 - val_accuracy: 0.6518\n",
      "Epoch 954/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 22.0223 - accuracy: 0.5608 - val_loss: 21.4340 - val_accuracy: 0.5716\n",
      "Epoch 955/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 26.7101 - accuracy: 0.5670 - val_loss: 8.4104 - val_accuracy: 0.5926\n",
      "Epoch 956/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 23.7503 - accuracy: 0.5631 - val_loss: 21.4903 - val_accuracy: 0.4652\n",
      "Epoch 957/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 26.0855 - accuracy: 0.5521 - val_loss: 6.8826 - val_accuracy: 0.6005\n",
      "Epoch 958/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 22.0322 - accuracy: 0.5652 - val_loss: 54.0839 - val_accuracy: 0.4415\n",
      "Epoch 959/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 18.4099 - accuracy: 0.5701 - val_loss: 32.6538 - val_accuracy: 0.4560\n",
      "Epoch 960/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.5446 - accuracy: 0.5635 - val_loss: 16.2596 - val_accuracy: 0.4954\n",
      "Epoch 961/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 15.7677 - accuracy: 0.5905 - val_loss: 6.4329 - val_accuracy: 0.6163\n",
      "Epoch 962/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 16.6246 - accuracy: 0.5819 - val_loss: 8.0279 - val_accuracy: 0.6478\n",
      "Epoch 963/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 25.3850 - accuracy: 0.5644 - val_loss: 25.4619 - val_accuracy: 0.4612\n",
      "Epoch 964/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 18.6465 - accuracy: 0.5736 - val_loss: 7.0603 - val_accuracy: 0.6005\n",
      "Epoch 965/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 27.4877 - accuracy: 0.5514 - val_loss: 5.9449 - val_accuracy: 0.6675\n",
      "Epoch 966/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 26.4022 - accuracy: 0.5617 - val_loss: 34.8447 - val_accuracy: 0.5703\n",
      "Epoch 967/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 25.7978 - accuracy: 0.5580 - val_loss: 16.0497 - val_accuracy: 0.5821\n",
      "Epoch 968/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.0830 - accuracy: 0.5747 - val_loss: 43.2797 - val_accuracy: 0.5703\n",
      "Epoch 969/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 22.5372 - accuracy: 0.5675 - val_loss: 26.1255 - val_accuracy: 0.4625\n",
      "Epoch 970/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 22.8563 - accuracy: 0.5806 - val_loss: 103.7667 - val_accuracy: 0.4323\n",
      "Epoch 971/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 30.1012 - accuracy: 0.5544 - val_loss: 8.3885 - val_accuracy: 0.6386\n",
      "Epoch 972/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 18.0139 - accuracy: 0.5788 - val_loss: 7.1868 - val_accuracy: 0.6531\n",
      "Epoch 973/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 19.6359 - accuracy: 0.5644 - val_loss: 33.7343 - val_accuracy: 0.5703\n",
      "Epoch 974/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 27.9720 - accuracy: 0.5514 - val_loss: 22.1762 - val_accuracy: 0.5703\n",
      "Epoch 975/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 20.3025 - accuracy: 0.5642 - val_loss: 11.1769 - val_accuracy: 0.6058\n",
      "Epoch 976/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 25.2064 - accuracy: 0.5685 - val_loss: 6.6738 - val_accuracy: 0.6505\n",
      "Epoch 977/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 17.8781 - accuracy: 0.5837 - val_loss: 7.1802 - val_accuracy: 0.5966\n",
      "Epoch 978/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.8529 - accuracy: 0.5479 - val_loss: 21.4172 - val_accuracy: 0.5703\n",
      "Epoch 979/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 17.2189 - accuracy: 0.5686 - val_loss: 35.3422 - val_accuracy: 0.5703\n",
      "Epoch 980/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.9471 - accuracy: 0.5609 - val_loss: 19.4659 - val_accuracy: 0.5729\n",
      "Epoch 981/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 17.5048 - accuracy: 0.5750 - val_loss: 5.6677 - val_accuracy: 0.6202\n",
      "Epoch 982/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.6345 - accuracy: 0.5647 - val_loss: 10.4096 - val_accuracy: 0.6084\n",
      "Epoch 983/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 20.4891 - accuracy: 0.5598 - val_loss: 8.1621 - val_accuracy: 0.6360\n",
      "Epoch 984/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.2163 - accuracy: 0.5683 - val_loss: 5.9692 - val_accuracy: 0.6518\n",
      "Epoch 985/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.5169 - accuracy: 0.5463 - val_loss: 54.4887 - val_accuracy: 0.5703\n",
      "Epoch 986/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 21.4507 - accuracy: 0.5640 - val_loss: 7.5791 - val_accuracy: 0.5887\n",
      "Epoch 987/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 16.7252 - accuracy: 0.5660 - val_loss: 5.2524 - val_accuracy: 0.6610\n",
      "Epoch 988/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 18.7745 - accuracy: 0.5754 - val_loss: 8.5006 - val_accuracy: 0.5572\n",
      "Epoch 989/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 25.9869 - accuracy: 0.5530 - val_loss: 10.6554 - val_accuracy: 0.6084\n",
      "Epoch 990/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 17.9371 - accuracy: 0.5737 - val_loss: 10.1747 - val_accuracy: 0.6084\n",
      "Epoch 991/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 13.2928 - accuracy: 0.5924 - val_loss: 8.8634 - val_accuracy: 0.6176\n",
      "Epoch 992/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 23.7972 - accuracy: 0.5593 - val_loss: 6.1209 - val_accuracy: 0.6018\n",
      "Epoch 993/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 29.7306 - accuracy: 0.5475 - val_loss: 29.0448 - val_accuracy: 0.5703\n",
      "Epoch 994/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.5574 - accuracy: 0.5823 - val_loss: 13.9154 - val_accuracy: 0.5848\n",
      "Epoch 995/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 14.1148 - accuracy: 0.5793 - val_loss: 29.5154 - val_accuracy: 0.5703\n",
      "Epoch 996/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 16.7412 - accuracy: 0.5701 - val_loss: 7.0564 - val_accuracy: 0.5900\n",
      "Epoch 997/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 20.8409 - accuracy: 0.5614 - val_loss: 5.6854 - val_accuracy: 0.6058\n",
      "Epoch 998/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 11.5989 - accuracy: 0.5852 - val_loss: 54.1529 - val_accuracy: 0.4389\n",
      "Epoch 999/1000\n",
      "191/191 [==============================] - 0s 2ms/step - loss: 21.6627 - accuracy: 0.5483 - val_loss: 9.0618 - val_accuracy: 0.6097\n",
      "Epoch 1000/1000\n",
      "191/191 [==============================] - 0s 1ms/step - loss: 19.7073 - accuracy: 0.5652 - val_loss: 4.7893 - val_accuracy: 0.6583\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow version\n",
    "# Define the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, input_shape=(3,), activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train.values, epochs=1000, batch_size=32, validation_data=(x_val, y_val.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Train",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          1906.77734375,
          506.5526123046875,
          551.8193969726562,
          532.2523193359375,
          561.4923095703125,
          646.3076171875,
          547.038818359375,
          700.1815795898438,
          589.9190673828125,
          743.3292236328125,
          818.6498413085938,
          632.6205444335938,
          611.3372192382812,
          539.487060546875,
          736.5578002929688,
          567.7890625,
          522.9728393554688,
          544.7598266601562,
          637.6984252929688,
          374.67279052734375,
          453.3419189453125,
          497.67498779296875,
          900.3417358398438,
          646.93212890625,
          683.520751953125,
          617.0653076171875,
          520.7421264648438,
          566.4530639648438,
          892.6661987304688,
          613.257568359375,
          877.66796875,
          643.2352294921875,
          594.7989501953125,
          589.4299926757812,
          408.3144226074219,
          552.5260620117188,
          398.598388671875,
          493.6427307128906,
          564.533935546875,
          640.10498046875,
          314.6422424316406,
          639.0899047851562,
          806.9398193359375,
          458.15850830078125,
          449.08837890625,
          608.1195678710938,
          443.1107482910156,
          381.5881652832031,
          481.6151428222656,
          772.267333984375,
          341.2938537597656,
          336.27850341796875,
          493.0606994628906,
          411.822509765625,
          424.58892822265625,
          379.508544921875,
          636.399658203125,
          380.76483154296875,
          501.748779296875,
          515.5529174804688,
          348.00439453125,
          534.6360473632812,
          380.142822265625,
          1000.1393432617188,
          394.0047607421875,
          758.953857421875,
          348.9692077636719,
          683.56787109375,
          322.70947265625,
          630.0374145507812,
          353.1314392089844,
          345.6597595214844,
          597.1624755859375,
          619.5156860351562,
          320.0111083984375,
          414.3028259277344,
          533.1708374023438,
          410.6111755371094,
          331.5740966796875,
          421.322998046875,
          430.0254821777344,
          485.6712646484375,
          472.19158935546875,
          541.6297607421875,
          460.0010681152344,
          257.76397705078125,
          275.42034912109375,
          532.7269897460938,
          354.5697021484375,
          586.0877685546875,
          325.2434387207031,
          401.35919189453125,
          428.230224609375,
          627.358642578125,
          379.8475646972656,
          407.4551696777344,
          439.0474548339844,
          415.2033386230469,
          384.23309326171875,
          474.0263671875,
          520.7955322265625,
          481.02947998046875,
          483.7940979003906,
          314.52545166015625,
          354.5962219238281,
          267.4334716796875,
          310.5933532714844,
          327.6271057128906,
          516.0488891601562,
          447.77923583984375,
          558.3048095703125,
          335.1939697265625,
          373.86456298828125,
          376.04351806640625,
          603.9065551757812,
          567.8381958007812,
          320.92572021484375,
          462.5327453613281,
          299.3572998046875,
          352.26751708984375,
          573.9574584960938,
          350.12896728515625,
          497.14691162109375,
          615.076904296875,
          384.90655517578125,
          315.0418701171875,
          579.7828979492188,
          548.3241577148438,
          254.21995544433594,
          543.072265625,
          655.9946899414062,
          306.811279296875,
          348.5381774902344,
          251.0800323486328,
          360.6064147949219,
          452.204833984375,
          389.3540954589844,
          434.7826232910156,
          333.60064697265625,
          457.9561462402344,
          304.8401794433594,
          421.1900939941406,
          279.6084289550781,
          351.13104248046875,
          355.4972839355469,
          277.696044921875,
          480.8282470703125,
          429.88641357421875,
          338.8189392089844,
          389.61456298828125,
          412.4989318847656,
          383.71356201171875,
          377.31085205078125,
          471.77679443359375,
          295.2917785644531,
          327.4388427734375,
          621.8455200195312,
          569.581787109375,
          416.3027038574219,
          452.8542785644531,
          331.4910583496094,
          210.53390502929688,
          314.5863342285156,
          546.9151611328125,
          439.09332275390625,
          277.7225341796875,
          442.1919860839844,
          361.917724609375,
          364.5158386230469,
          304.6427001953125,
          500.887451171875,
          253.38844299316406,
          429.1676940917969,
          562.5985717773438,
          444.86505126953125,
          415.2503967285156,
          325.7987976074219,
          341.934814453125,
          309.6440734863281,
          389.2965087890625,
          474.3852233886719,
          451.7317810058594,
          451.1761169433594,
          349.14532470703125,
          311.0382080078125,
          399.5679016113281,
          241.35887145996094,
          415.3798522949219,
          428.218994140625,
          333.5009460449219,
          289.3761901855469,
          272.65777587890625,
          284.1744384765625,
          309.9373474121094,
          471.84442138671875,
          345.2825927734375,
          296.2710266113281,
          456.94732666015625,
          305.85711669921875,
          240.16412353515625,
          262.8565368652344,
          331.886474609375,
          355.6781921386719,
          223.88165283203125,
          274.0580749511719,
          467.42791748046875,
          267.8877868652344,
          440.40045166015625,
          289.75634765625,
          271.94122314453125,
          489.5787658691406,
          226.44961547851562,
          472.9635925292969,
          307.77020263671875,
          251.6065216064453,
          191.51516723632812,
          356.0854797363281,
          329.3172912597656,
          289.7508544921875,
          284.5852966308594,
          222.3589324951172,
          214.43763732910156,
          323.0494384765625,
          553.49755859375,
          313.3515625,
          291.892333984375,
          337.7875061035156,
          226.67108154296875,
          350.5359191894531,
          346.82623291015625,
          236.60435485839844,
          378.6830749511719,
          239.738037109375,
          301.2326354980469,
          431.3730773925781,
          233.7584228515625,
          456.29437255859375,
          207.39891052246094,
          221.14588928222656,
          273.9134216308594,
          336.6709289550781,
          330.76019287109375,
          400.26531982421875,
          389.5186767578125,
          219.3188018798828,
          203.75364685058594,
          262.9777526855469,
          292.01019287109375,
          323.3253479003906,
          350.2035217285156,
          230.47682189941406,
          175.6743621826172,
          266.59381103515625,
          379.1820983886719,
          173.3960723876953,
          237.77871704101562,
          277.1434631347656,
          234.97914123535156,
          295.4816589355469,
          315.1103820800781,
          243.83255004882812,
          181.7584228515625,
          249.71253967285156,
          435.2884216308594,
          155.35121154785156,
          256.08721923828125,
          292.51806640625,
          337.75567626953125,
          133.97259521484375,
          210.41818237304688,
          261.27191162109375,
          210.4938201904297,
          241.344970703125,
          377.16302490234375,
          167.8873748779297,
          239.1248016357422,
          138.06201171875,
          195.8074951171875,
          275.5420837402344,
          188.83409118652344,
          206.39930725097656,
          207.69041442871094,
          415.2005310058594,
          255.3229522705078,
          146.87765502929688,
          272.8743896484375,
          173.4113311767578,
          231.18133544921875,
          185.92855834960938,
          228.75765991210938,
          241.7002716064453,
          312.3722839355469,
          224.79261779785156,
          221.21044921875,
          291.1115417480469,
          229.65591430664062,
          184.29351806640625,
          221.79745483398438,
          213.74012756347656,
          363.0765075683594,
          220.86471557617188,
          259.7546691894531,
          371.67852783203125,
          406.6651611328125,
          209.40174865722656,
          212.6071014404297,
          223.34336853027344,
          335.3868713378906,
          141.89817810058594,
          138.0359344482422,
          185.50741577148438,
          237.61672973632812,
          250.689697265625,
          323.40850830078125,
          287.2871398925781,
          164.1992950439453,
          310.867431640625,
          165.37364196777344,
          178.0070343017578,
          166.9141082763672,
          231.87013244628906,
          185.27035522460938,
          504.1507873535156,
          164.64999389648438,
          207.746826171875,
          200.68260192871094,
          180.6673583984375,
          253.4596405029297,
          202.73109436035156,
          275.4581298828125,
          139.44403076171875,
          247.5460662841797,
          262.28363037109375,
          131.51173400878906,
          247.22027587890625,
          187.0249786376953,
          202.4616241455078,
          168.15234375,
          185.29307556152344,
          137.8648681640625,
          298.5511474609375,
          140.49281311035156,
          201.11019897460938,
          151.7473907470703,
          248.5575714111328,
          204.46817016601562,
          219.9249725341797,
          124.28225708007812,
          222.97227478027344,
          179.42340087890625,
          280.6567687988281,
          136.9062042236328,
          200.32301330566406,
          113.17778015136719,
          247.06666564941406,
          237.3589324951172,
          173.17532348632812,
          152.7349395751953,
          207.16343688964844,
          145.6629180908203,
          137.38388061523438,
          244.76194763183594,
          267.8546447753906,
          299.8597106933594,
          155.67933654785156,
          254.20523071289062,
          148.89773559570312,
          201.60964965820312,
          221.45291137695312,
          149.9688262939453,
          185.17193603515625,
          190.671142578125,
          135.08053588867188,
          179.71560668945312,
          126.38420867919922,
          134.21189880371094,
          179.557861328125,
          99.79228210449219,
          199.4844970703125,
          251.93814086914062,
          222.48512268066406,
          121.21749877929688,
          159.20228576660156,
          142.83966064453125,
          203.72450256347656,
          174.02700805664062,
          157.3028106689453,
          133.26455688476562,
          145.64901733398438,
          243.29476928710938,
          173.96051025390625,
          214.3278045654297,
          299.2405700683594,
          134.06004333496094,
          131.2701873779297,
          172.47128295898438,
          165.21240234375,
          185.61529541015625,
          177.22572326660156,
          109.37194061279297,
          143.68875122070312,
          155.1009063720703,
          235.1503448486328,
          184.43417358398438,
          171.47744750976562,
          168.0411376953125,
          282.6332092285156,
          229.80270385742188,
          143.8988494873047,
          97.33966827392578,
          216.45523071289062,
          123.02587890625,
          317.47149658203125,
          127.9172592163086,
          188.65234375,
          157.86610412597656,
          158.513916015625,
          144.15415954589844,
          194.60821533203125,
          171.844482421875,
          126.48286437988281,
          149.4169158935547,
          136.81756591796875,
          114.28744506835938,
          119.327880859375,
          160.1669158935547,
          89.13481903076172,
          183.68345642089844,
          195.4508056640625,
          124.08626556396484,
          177.8497314453125,
          216.0565948486328,
          170.114013671875,
          122.33143615722656,
          198.03932189941406,
          142.3612518310547,
          162.31369018554688,
          91.47077178955078,
          117.0328598022461,
          146.1470947265625,
          240.80838012695312,
          276.2525939941406,
          132.7533721923828,
          123.31066131591797,
          165.2919464111328,
          227.8303985595703,
          141.84156799316406,
          133.92918395996094,
          218.84213256835938,
          88.01825714111328,
          196.44021606445312,
          145.36241149902344,
          93.7935791015625,
          125.65520477294922,
          144.70628356933594,
          113.58155059814453,
          183.67752075195312,
          123.94654083251953,
          111.38873291015625,
          136.9140625,
          164.12478637695312,
          178.31297302246094,
          120.48094940185547,
          122.64456176757812,
          152.3596649169922,
          148.00502014160156,
          140.32904052734375,
          173.69528198242188,
          115.97126770019531,
          117.6382064819336,
          136.1714630126953,
          130.6637725830078,
          263.08251953125,
          77.1999740600586,
          103.32837677001953,
          80.98897552490234,
          131.96510314941406,
          104.29182434082031,
          105.67525482177734,
          135.74307250976562,
          103.0647201538086,
          121.7048568725586,
          167.87716674804688,
          217.22879028320312,
          87.35688781738281,
          110.9533462524414,
          129.06198120117188,
          101.80664825439453,
          75.12600708007812,
          84.84376525878906,
          181.21914672851562,
          116.53262329101562,
          107.16178131103516,
          77.1596450805664,
          100.00981903076172,
          147.81246948242188,
          97.14005279541016,
          90.05656433105469,
          100.11910247802734,
          87.7706069946289,
          208.0155792236328,
          91.10198211669922,
          84.96269226074219,
          127.38471984863281,
          103.88365936279297,
          124.4813461303711,
          76.64372253417969,
          115.66667938232422,
          90.61480712890625,
          89.00553131103516,
          82.78558349609375,
          127.10416412353516,
          95.2398910522461,
          70.5679931640625,
          93.13811492919922,
          116.763671875,
          125.6209945678711,
          123.94115447998047,
          120.81764221191406,
          105.50421142578125,
          62.6006965637207,
          87.39240264892578,
          85.21935272216797,
          119.3560562133789,
          91.37588500976562,
          78.2466049194336,
          177.1807861328125,
          80.71685028076172,
          112.3042984008789,
          79.85540008544922,
          91.42849731445312,
          80.3449935913086,
          77.82799530029297,
          63.236915588378906,
          68.46282196044922,
          148.8147430419922,
          83.37621307373047,
          108.73995971679688,
          99.55025482177734,
          92.93226623535156,
          73.13433074951172,
          94.2418441772461,
          88.85118865966797,
          94.87371826171875,
          114.79801940917969,
          87.10040283203125,
          71.4124755859375,
          65.16975402832031,
          62.42008972167969,
          70.79666900634766,
          83.52871704101562,
          127.01808166503906,
          115.5296401977539,
          68.98424530029297,
          114.233642578125,
          101.98582458496094,
          83.92407989501953,
          46.84372329711914,
          85.02235412597656,
          58.84834289550781,
          87.11833190917969,
          122.37782287597656,
          166.6256561279297,
          64.04828643798828,
          66.10385131835938,
          50.41216278076172,
          70.71642303466797,
          72.7088851928711,
          88.98958587646484,
          95.43839263916016,
          99.31103515625,
          62.49173355102539,
          69.09899139404297,
          60.679542541503906,
          87.66171264648438,
          98.58042907714844,
          115.97103881835938,
          108.4651870727539,
          102.71538543701172,
          89.16476440429688,
          86.82737731933594,
          62.0795783996582,
          93.30429077148438,
          52.47684860229492,
          113.26292419433594,
          125.43167114257812,
          81.15287017822266,
          70.8374252319336,
          70.23800659179688,
          81.82703399658203,
          69.05203247070312,
          82.98458862304688,
          49.948486328125,
          58.26299285888672,
          59.16656494140625,
          120.88507080078125,
          62.45315170288086,
          66.31208801269531,
          65.67953491210938,
          51.08197784423828,
          47.97365951538086,
          63.43764877319336,
          145.78018188476562,
          75.19862365722656,
          70.7848892211914,
          56.41798400878906,
          68.63030242919922,
          62.8016357421875,
          48.35173034667969,
          53.51287841796875,
          63.05933380126953,
          67.75386047363281,
          79.73802185058594,
          68.22648620605469,
          48.20581817626953,
          76.97893524169922,
          49.98609924316406,
          63.96416091918945,
          91.95271301269531,
          92.31803131103516,
          81.4962387084961,
          79.5083236694336,
          73.03143310546875,
          60.40192794799805,
          44.549903869628906,
          81.42034912109375,
          71.15008544921875,
          73.2312240600586,
          46.61700439453125,
          58.73281478881836,
          61.28617477416992,
          53.83110046386719,
          50.62168502807617,
          66.18882751464844,
          47.00307846069336,
          73.44837188720703,
          38.56926727294922,
          47.886531829833984,
          79.98124694824219,
          64.65624237060547,
          36.805118560791016,
          49.56349182128906,
          73.84439849853516,
          77.05523681640625,
          69.87702178955078,
          54.556480407714844,
          61.99806594848633,
          51.14395523071289,
          47.642784118652344,
          69.19409942626953,
          64.9988784790039,
          57.04403305053711,
          55.72715377807617,
          50.84297561645508,
          93.03620910644531,
          54.759666442871094,
          54.109642028808594,
          35.15823745727539,
          83.81565856933594,
          53.29276657104492,
          95.29066467285156,
          102.32502746582031,
          56.788639068603516,
          37.500858306884766,
          46.49507522583008,
          76.30807495117188,
          57.8519401550293,
          86.88819885253906,
          42.40828323364258,
          38.695213317871094,
          60.97163009643555,
          57.97166442871094,
          43.474876403808594,
          58.90266799926758,
          56.69715118408203,
          42.21141815185547,
          59.055049896240234,
          61.24158477783203,
          39.500797271728516,
          65.1104965209961,
          37.663387298583984,
          40.86035919189453,
          52.27116775512695,
          78.89514923095703,
          59.80636215209961,
          38.353675842285156,
          35.8505973815918,
          45.20012283325195,
          92.83587646484375,
          48.828338623046875,
          51.292091369628906,
          53.084144592285156,
          47.435569763183594,
          50.730743408203125,
          61.93983459472656,
          46.39745330810547,
          47.359195709228516,
          39.73332977294922,
          57.941627502441406,
          52.07064437866211,
          48.212799072265625,
          52.27158737182617,
          79.81393432617188,
          123.4433822631836,
          45.1895637512207,
          54.44106674194336,
          29.018842697143555,
          113.89369201660156,
          67.518798828125,
          53.62461853027344,
          54.07040786743164,
          53.7179069519043,
          47.57467269897461,
          50.673038482666016,
          54.22554016113281,
          46.6141471862793,
          66.38411712646484,
          53.79571533203125,
          56.73336410522461,
          49.58426284790039,
          69.35369110107422,
          42.220619201660156,
          64.58889770507812,
          106.95619201660156,
          43.087188720703125,
          43.5770378112793,
          52.27424240112305,
          76.53137969970703,
          41.997230529785156,
          53.032066345214844,
          82.04178619384766,
          60.07182312011719,
          59.71898651123047,
          50.7989616394043,
          52.35380935668945,
          47.7690315246582,
          40.52735900878906,
          71.25495910644531,
          69.28775024414062,
          53.88090133666992,
          65.1458740234375,
          58.18524169921875,
          34.833133697509766,
          55.40354919433594,
          53.42366409301758,
          51.093868255615234,
          39.26892852783203,
          42.21837615966797,
          42.16568374633789,
          45.5284538269043,
          34.95941162109375,
          48.304832458496094,
          48.04508972167969,
          41.128414154052734,
          49.68760681152344,
          56.23271179199219,
          41.75308609008789,
          65.32443237304688,
          47.83085632324219,
          64.30198669433594,
          42.87857437133789,
          66.86898040771484,
          44.981475830078125,
          44.600616455078125,
          32.253944396972656,
          57.325164794921875,
          61.75762176513672,
          50.55106735229492,
          71.07119750976562,
          33.56299591064453,
          42.576148986816406,
          55.42401123046875,
          64.89433288574219,
          36.14339065551758,
          40.82179641723633,
          32.651268005371094,
          46.22838592529297,
          42.832027435302734,
          40.81060791015625,
          43.799251556396484,
          81.30962371826172,
          65.43274688720703,
          37.763545989990234,
          33.036006927490234,
          57.24462890625,
          42.23017120361328,
          57.793663024902344,
          38.56658172607422,
          41.70822525024414,
          56.200958251953125,
          32.08249282836914,
          53.21733856201172,
          61.30842590332031,
          38.45392608642578,
          33.63554000854492,
          32.705387115478516,
          59.430702209472656,
          66.36917877197266,
          50.544063568115234,
          42.89036178588867,
          53.09541320800781,
          55.696773529052734,
          50.43052291870117,
          35.56081771850586,
          53.05915069580078,
          41.354679107666016,
          43.74324035644531,
          27.65151596069336,
          33.89179611206055,
          44.78076171875,
          37.73271179199219,
          50.609580993652344,
          63.37562561035156,
          53.74870681762695,
          49.65019989013672,
          30.515003204345703,
          42.099388122558594,
          42.555335998535156,
          36.78826904296875,
          38.6920051574707,
          61.40837478637695,
          37.4262809753418,
          30.428407669067383,
          54.31291580200195,
          43.494659423828125,
          67.67112731933594,
          34.30282974243164,
          35.40838623046875,
          30.850683212280273,
          49.874534606933594,
          32.131134033203125,
          46.491329193115234,
          24.519418716430664,
          33.746891021728516,
          47.21003341674805,
          49.79412078857422,
          30.566545486450195,
          33.61397933959961,
          29.99506950378418,
          38.15385437011719,
          27.97571563720703,
          38.07084274291992,
          46.931697845458984,
          44.827781677246094,
          35.51371765136719,
          28.875741958618164,
          52.13228225708008,
          33.557674407958984,
          23.46839141845703,
          22.223237991333008,
          44.42395782470703,
          34.92191696166992,
          28.21854019165039,
          32.20375442504883,
          47.89975357055664,
          34.70400619506836,
          31.16027069091797,
          27.95346450805664,
          40.08457565307617,
          41.13360595703125,
          25.14930534362793,
          32.149139404296875,
          45.234195709228516,
          48.57582092285156,
          29.652063369750977,
          40.10499954223633,
          42.963623046875,
          21.216581344604492,
          24.520998001098633,
          65.12220764160156,
          40.52277374267578,
          39.94015121459961,
          30.898380279541016,
          29.367523193359375,
          40.4254264831543,
          24.8295955657959,
          24.639753341674805,
          39.00467300415039,
          36.17030334472656,
          22.078086853027344,
          38.167335510253906,
          33.860538482666016,
          37.50402069091797,
          39.12825393676758,
          33.37822723388672,
          29.229000091552734,
          32.243003845214844,
          38.09751892089844,
          29.46795654296875,
          39.10090255737305,
          42.91140365600586,
          29.010332107543945,
          43.30512237548828,
          40.374141693115234,
          25.152467727661133,
          23.602401733398438,
          35.76683044433594,
          41.35446548461914,
          37.12803268432617,
          39.15201950073242,
          28.765155792236328,
          20.065589904785156,
          30.625818252563477,
          33.11146545410156,
          33.86111068725586,
          29.380510330200195,
          29.952381134033203,
          30.67868423461914,
          27.47262954711914,
          35.72490692138672,
          37.391632080078125,
          26.48422622680664,
          33.70608901977539,
          34.69668960571289,
          27.812984466552734,
          26.208702087402344,
          31.546340942382812,
          25.48678207397461,
          37.5714225769043,
          28.893835067749023,
          26.05823516845703,
          26.105188369750977,
          18.70071029663086,
          20.080034255981445,
          27.821931838989258,
          24.03743553161621,
          46.46424865722656,
          23.73675537109375,
          23.99776840209961,
          20.7468204498291,
          30.630855560302734,
          21.710615158081055,
          25.450227737426758,
          24.49641227722168,
          32.40877914428711,
          29.722728729248047,
          21.448152542114258,
          31.781713485717773,
          26.273971557617188,
          31.62566375732422,
          19.329666137695312,
          15.500517845153809,
          33.06385803222656,
          34.37297439575195,
          26.757850646972656,
          27.024560928344727,
          23.508623123168945,
          16.591800689697266,
          19.874420166015625,
          36.22007751464844,
          20.21436309814453,
          23.835594177246094,
          25.444866180419922,
          22.02234649658203,
          26.710092544555664,
          23.750335693359375,
          26.085540771484375,
          22.032184600830078,
          18.409915924072266,
          19.54461669921875,
          15.767683982849121,
          16.62456512451172,
          25.38498878479004,
          18.646514892578125,
          27.487743377685547,
          26.402196884155273,
          25.79781723022461,
          19.08302879333496,
          22.537195205688477,
          22.856304168701172,
          30.101152420043945,
          18.013948440551758,
          19.635900497436523,
          27.972026824951172,
          20.302453994750977,
          25.206403732299805,
          17.878135681152344,
          29.852914810180664,
          17.218904495239258,
          19.947105407714844,
          17.50483512878418,
          19.634456634521484,
          20.4891414642334,
          19.216257095336914,
          29.516887664794922,
          21.45074462890625,
          16.725170135498047,
          18.774497985839844,
          25.9869327545166,
          17.93708610534668,
          13.292757987976074,
          23.79719352722168,
          29.730607986450195,
          19.557350158691406,
          14.114761352539062,
          16.741167068481445,
          20.840911865234375,
          11.598902702331543,
          21.662704467773438,
          19.707284927368164
         ]
        },
        {
         "name": "Validation",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999
         ],
         "y": [
          589.0330200195312,
          293.0824279785156,
          367.0710144042969,
          793.6818237304688,
          178.296875,
          979.0083618164062,
          865.9180297851562,
          697.2062377929688,
          141.33355712890625,
          534.84716796875,
          905.359375,
          591.7183227539062,
          1627.8013916015625,
          535.7981567382812,
          780.7842407226562,
          227.96543884277344,
          852.2430419921875,
          686.9672241210938,
          1279.9749755859375,
          143.444580078125,
          415.01202392578125,
          106.26873779296875,
          355.7829895019531,
          811.97998046875,
          264.130615234375,
          196.4908447265625,
          107.98645782470703,
          1320.6195068359375,
          167.34571838378906,
          1664.2694091796875,
          3114.090576171875,
          110.702392578125,
          1233.982177734375,
          586.115478515625,
          112.16822052001953,
          143.65406799316406,
          113.66873168945312,
          860.658935546875,
          285.63916015625,
          111.55271911621094,
          194.02166748046875,
          1631.193603515625,
          582.0263061523438,
          175.6068115234375,
          233.92916870117188,
          177.93760681152344,
          165.4733428955078,
          764.1185913085938,
          546.3641357421875,
          382.2807922363281,
          283.3692626953125,
          106.46393585205078,
          299.9493408203125,
          185.19334411621094,
          593.7091674804688,
          346.0589599609375,
          716.5643310546875,
          547.128173828125,
          156.54083251953125,
          124.05317687988281,
          391.29656982421875,
          824.4835815429688,
          359.5709228515625,
          326.1223449707031,
          433.1268005371094,
          304.75439453125,
          548.7872314453125,
          720.151123046875,
          1049.6905517578125,
          623.44970703125,
          668.3323364257812,
          161.5233154296875,
          510.8386535644531,
          533.9503784179688,
          113.46414184570312,
          379.1478576660156,
          174.61697387695312,
          477.2300720214844,
          99.85967254638672,
          124.62464904785156,
          408.7145080566406,
          776.8470458984375,
          312.599609375,
          1228.1466064453125,
          116.69891357421875,
          475.4268493652344,
          125.41735076904297,
          672.6492309570312,
          1449.6427001953125,
          670.201904296875,
          539.5191650390625,
          196.1278533935547,
          933.72265625,
          595.761962890625,
          436.93084716796875,
          652.510009765625,
          389.4342041015625,
          201.23138427734375,
          898.2164916992188,
          478.9955749511719,
          97.42745971679688,
          328.7036437988281,
          735.2385864257812,
          96.91179656982422,
          390.53924560546875,
          841.6273193359375,
          255.58560180664062,
          109.17842102050781,
          958.9915161132812,
          586.8602294921875,
          585.8114013671875,
          435.12811279296875,
          196.93197631835938,
          97.0064468383789,
          219.56832885742188,
          922.35107421875,
          141.37728881835938,
          259.8233947753906,
          192.2543182373047,
          565.502197265625,
          182.91558837890625,
          192.13853454589844,
          2159.2685546875,
          479.916259765625,
          634.859619140625,
          114.2600326538086,
          115.94733428955078,
          297.67767333984375,
          786.5575561523438,
          189.18939208984375,
          398.8595275878906,
          138.5315704345703,
          277.70849609375,
          121.25302124023438,
          432.54376220703125,
          726.1702270507812,
          100.50611877441406,
          97.49461364746094,
          100.5978775024414,
          151.58596801757812,
          216.5492401123047,
          569.4361572265625,
          92.73634338378906,
          355.39373779296875,
          662.8450317382812,
          334.66229248046875,
          1796.8218994140625,
          309.0532531738281,
          628.8082885742188,
          462.883056640625,
          528.7776489257812,
          1264.43359375,
          110.58531951904297,
          506.9678039550781,
          183.36549377441406,
          348.5905456542969,
          607.221923828125,
          130.8529510498047,
          442.38580322265625,
          582.4550170898438,
          241.5252685546875,
          99.3641357421875,
          2279.654296875,
          110.31107330322266,
          88.20735168457031,
          96.01123046875,
          641.2352905273438,
          303.96728515625,
          101.65928649902344,
          308.8000793457031,
          417.5953063964844,
          113.79850769042969,
          909.000732421875,
          631.5682983398438,
          698.0839233398438,
          380.1324768066406,
          494.9260559082031,
          125.87554168701172,
          820.356689453125,
          196.42376708984375,
          444.4652099609375,
          328.63702392578125,
          1204.2313232421875,
          1035.430908203125,
          494.5135498046875,
          550.4135131835938,
          567.2417602539062,
          261.099853515625,
          958.2106323242188,
          254.60179138183594,
          691.54248046875,
          360.6220703125,
          120.02620697021484,
          1287.32275390625,
          439.537353515625,
          630.2864379882812,
          451.7434997558594,
          501.084716796875,
          76.21110534667969,
          112.16372680664062,
          72.35176849365234,
          214.9105987548828,
          286.0994873046875,
          1002.4868774414062,
          129.72821044921875,
          314.0097351074219,
          404.414306640625,
          135.32672119140625,
          1282.165771484375,
          311.89654541015625,
          363.09039306640625,
          80.13677978515625,
          103.85750579833984,
          570.6746215820312,
          76.25702667236328,
          96.62860107421875,
          762.1630859375,
          142.76361083984375,
          820.5558471679688,
          121.36056518554688,
          438.13909912109375,
          376.7627258300781,
          464.95709228515625,
          828.5430297851562,
          144.4500274658203,
          409.9895324707031,
          741.0023193359375,
          569.0516357421875,
          592.3784790039062,
          221.69985961914062,
          230.0069122314453,
          95.27864074707031,
          221.49826049804688,
          89.56584930419922,
          116.69264221191406,
          294.1828918457031,
          82.95829010009766,
          595.9780883789062,
          645.4736938476562,
          154.8631591796875,
          1359.5513916015625,
          1124.270263671875,
          506.16265869140625,
          231.85618591308594,
          269.8182067871094,
          206.37464904785156,
          171.00775146484375,
          305.1927795410156,
          554.7101440429688,
          196.0316162109375,
          551.716796875,
          342.8367614746094,
          716.3800659179688,
          65.84070587158203,
          285.0021057128906,
          413.6511535644531,
          562.8896484375,
          162.19906616210938,
          398.3732604980469,
          74.51331329345703,
          348.9337158203125,
          92.82228088378906,
          68.24891662597656,
          484.8798522949219,
          57.46754837036133,
          59.423431396484375,
          61.26926803588867,
          65.1360092163086,
          55.69026184082031,
          181.78683471679688,
          276.59521484375,
          60.40129470825195,
          226.71316528320312,
          77.6827621459961,
          193.68836975097656,
          468.5279541015625,
          609.60791015625,
          87.24629211425781,
          113.62277221679688,
          336.91180419921875,
          75.79313659667969,
          257.35870361328125,
          157.19168090820312,
          110.0300064086914,
          494.1499328613281,
          143.5062255859375,
          289.1216735839844,
          477.2001953125,
          203.59555053710938,
          97.87833404541016,
          765.46337890625,
          621.6846923828125,
          444.3114013671875,
          457.3539733886719,
          255.1163330078125,
          121.20010375976562,
          304.7958984375,
          240.98834228515625,
          85.09780883789062,
          62.060699462890625,
          254.33779907226562,
          461.04931640625,
          85.66447448730469,
          1091.0350341796875,
          396.7603454589844,
          51.693824768066406,
          392.5923156738281,
          64.81867980957031,
          43.976627349853516,
          245.1909637451172,
          144.0612335205078,
          65.01676177978516,
          90.91582489013672,
          626.307373046875,
          272.2812194824219,
          215.84796142578125,
          44.57129669189453,
          120.07201385498047,
          201.0543670654297,
          382.59136962890625,
          374.4977111816406,
          812.1564331054688,
          94.60807800292969,
          342.4534912109375,
          38.71782302856445,
          69.46923065185547,
          66.59262084960938,
          188.6830596923828,
          289.9610595703125,
          118.7591552734375,
          43.289268493652344,
          118.49712371826172,
          120.1257095336914,
          192.88401794433594,
          76.44361114501953,
          45.55795669555664,
          45.55597686767578,
          46.44358444213867,
          83.0488052368164,
          152.5939483642578,
          248.72007751464844,
          104.9491195678711,
          125.64791107177734,
          254.85134887695312,
          130.740478515625,
          56.064544677734375,
          60.35206985473633,
          239.61642456054688,
          94.65229034423828,
          1250.54931640625,
          390.6945495605469,
          55.68075942993164,
          43.69490051269531,
          153.8067169189453,
          148.65562438964844,
          127.130859375,
          202.482666015625,
          205.8201141357422,
          176.9928741455078,
          65.10431671142578,
          311.34893798828125,
          54.6405029296875,
          144.2214813232422,
          318.3089599609375,
          144.3488006591797,
          56.32132339477539,
          360.7731628417969,
          241.60716247558594,
          262.5180358886719,
          246.57562255859375,
          282.6675109863281,
          145.33987426757812,
          361.4901123046875,
          48.66995620727539,
          45.44552230834961,
          73.72566223144531,
          108.92987060546875,
          67.45508575439453,
          50.65868377685547,
          901.94873046875,
          128.55824279785156,
          211.13092041015625,
          70.52104187011719,
          482.9180908203125,
          244.11056518554688,
          97.30921173095703,
          86.42151641845703,
          237.40567016601562,
          400.6424865722656,
          42.10630416870117,
          434.19085693359375,
          234.38955688476562,
          105.57218933105469,
          288.2978210449219,
          64.82377624511719,
          69.45732879638672,
          182.72171020507812,
          859.6839599609375,
          65.42205810546875,
          346.87713623046875,
          150.0692138671875,
          277.96636962890625,
          92.49288940429688,
          93.0943374633789,
          151.64976501464844,
          51.63257598876953,
          41.23291778564453,
          714.2273559570312,
          69.09876251220703,
          124.4798812866211,
          61.02130126953125,
          403.7251892089844,
          35.469356536865234,
          278.59283447265625,
          39.533897399902344,
          189.8236541748047,
          194.36117553710938,
          34.335079193115234,
          84.9961166381836,
          97.80608367919922,
          84.24248504638672,
          53.82950210571289,
          43.0878791809082,
          202.70620727539062,
          97.44677734375,
          66.08440399169922,
          137.346435546875,
          351.97161865234375,
          419.6739501953125,
          102.53050231933594,
          392.20599365234375,
          169.33282470703125,
          359.5731506347656,
          114.50603485107422,
          370.7554626464844,
          31.032007217407227,
          396.5904235839844,
          32.85305404663086,
          189.98069763183594,
          30.268163681030273,
          281.55059814453125,
          118.2035140991211,
          600.5272827148438,
          94.779296875,
          81.57896423339844,
          169.8424530029297,
          416.0437316894531,
          142.4654998779297,
          61.41389846801758,
          222.31387329101562,
          37.60543441772461,
          29.115930557250977,
          232.0477752685547,
          343.1856994628906,
          67.9395980834961,
          54.06222915649414,
          152.50230407714844,
          287.5640869140625,
          108.05302429199219,
          174.51611328125,
          40.07807540893555,
          458.61407470703125,
          35.57306671142578,
          336.33343505859375,
          94.91372680664062,
          63.990657806396484,
          137.8759307861328,
          25.925039291381836,
          178.92288208007812,
          111.39733123779297,
          380.0333557128906,
          263.8570861816406,
          182.06619262695312,
          30.70367431640625,
          23.362552642822266,
          289.2929382324219,
          389.9692687988281,
          34.519439697265625,
          22.761037826538086,
          244.9376220703125,
          193.8986358642578,
          72.21241760253906,
          143.5089111328125,
          39.00971603393555,
          58.26302719116211,
          138.593505859375,
          327.9081115722656,
          58.39011001586914,
          31.349340438842773,
          147.9383087158203,
          94.00939178466797,
          237.09341430664062,
          98.06627655029297,
          62.0367317199707,
          143.523193359375,
          25.16619873046875,
          92.67975616455078,
          137.6965789794922,
          27.681211471557617,
          45.318607330322266,
          32.487056732177734,
          145.91488647460938,
          74.76287841796875,
          452.7389221191406,
          41.51680374145508,
          87.33367919921875,
          136.36289978027344,
          202.52667236328125,
          69.95005798339844,
          74.354736328125,
          235.84535217285156,
          33.062801361083984,
          42.65341567993164,
          111.81932830810547,
          51.57175827026367,
          208.59005737304688,
          158.73533630371094,
          72.07819366455078,
          174.48721313476562,
          73.00656127929688,
          44.315147399902344,
          140.4812469482422,
          29.78078842163086,
          95.94771575927734,
          43.94679260253906,
          226.9489288330078,
          337.8359375,
          43.25396728515625,
          228.43637084960938,
          32.17302322387695,
          40.38401794433594,
          37.02622985839844,
          27.574201583862305,
          62.353904724121094,
          153.565673828125,
          134.08065795898438,
          75.10911560058594,
          82.31206512451172,
          93.76226043701172,
          149.76742553710938,
          64.5020523071289,
          30.3875675201416,
          40.687889099121094,
          28.058008193969727,
          192.14430236816406,
          42.665225982666016,
          80.65449523925781,
          123.03238677978516,
          37.08494186401367,
          65.51744079589844,
          90.22166442871094,
          170.8279266357422,
          210.56427001953125,
          113.2620849609375,
          29.723812103271484,
          225.55715942382812,
          60.963226318359375,
          43.926082611083984,
          82.11137390136719,
          31.126480102539062,
          38.2274055480957,
          174.20884704589844,
          78.88261413574219,
          110.62505340576172,
          29.606000900268555,
          35.677425384521484,
          143.8887939453125,
          27.295196533203125,
          78.87184143066406,
          256.83489990234375,
          57.15654373168945,
          31.509897232055664,
          25.8994083404541,
          24.067461013793945,
          45.641944885253906,
          55.42829132080078,
          74.56106567382812,
          32.84260940551758,
          212.50833129882812,
          35.19626235961914,
          88.60163116455078,
          31.95062828063965,
          110.96918487548828,
          27.668468475341797,
          144.66213989257812,
          193.95655822753906,
          23.050678253173828,
          22.522005081176758,
          88.68619537353516,
          43.0063591003418,
          151.5980987548828,
          35.60966491699219,
          29.933385848999023,
          193.46951293945312,
          67.73208618164062,
          131.634033203125,
          60.276939392089844,
          57.131160736083984,
          83.09101867675781,
          34.068172454833984,
          202.2935028076172,
          88.43096160888672,
          32.383304595947266,
          21.177663803100586,
          22.54403305053711,
          46.907997131347656,
          21.56443214416504,
          107.27689361572266,
          77.47553253173828,
          104.73918151855469,
          119.5044174194336,
          107.6002197265625,
          33.137779235839844,
          201.9113006591797,
          31.629371643066406,
          66.1673812866211,
          42.980411529541016,
          54.38802719116211,
          211.4969024658203,
          38.3339958190918,
          58.009490966796875,
          26.967853546142578,
          30.156063079833984,
          36.24467849731445,
          39.56267547607422,
          62.15713882446289,
          41.83847427368164,
          21.296680450439453,
          22.972625732421875,
          24.352996826171875,
          230.60105895996094,
          25.389490127563477,
          30.50767707824707,
          29.958602905273438,
          28.62623405456543,
          55.83293533325195,
          34.487823486328125,
          18.74067497253418,
          53.71953582763672,
          21.267852783203125,
          57.64078903198242,
          21.00442123413086,
          247.9620361328125,
          30.192140579223633,
          238.4209747314453,
          22.066600799560547,
          145.95530700683594,
          86.13158416748047,
          79.31951141357422,
          51.253353118896484,
          19.148698806762695,
          66.3387222290039,
          92.17291259765625,
          25.00891876220703,
          29.25210952758789,
          52.06998062133789,
          28.037181854248047,
          43.3836555480957,
          18.59434700012207,
          104.40492248535156,
          62.87455368041992,
          19.731870651245117,
          19.920047760009766,
          74.95794677734375,
          65.96601867675781,
          49.61200714111328,
          85.29329681396484,
          22.055496215820312,
          25.356870651245117,
          17.135223388671875,
          152.24612426757812,
          26.961284637451172,
          21.258699417114258,
          16.478628158569336,
          26.3079776763916,
          66.94441223144531,
          160.7781982421875,
          16.24403190612793,
          66.0814437866211,
          16.349712371826172,
          16.795896530151367,
          16.34592628479004,
          94.47490692138672,
          47.78002166748047,
          16.14547348022461,
          15.11815357208252,
          52.606163024902344,
          18.19316864013672,
          18.771066665649414,
          14.492433547973633,
          64.35134887695312,
          22.838314056396484,
          44.26317596435547,
          84.40057373046875,
          29.533527374267578,
          30.27376365661621,
          14.625686645507812,
          55.146522521972656,
          13.687226295471191,
          21.173885345458984,
          121.78797149658203,
          14.65550422668457,
          212.23558044433594,
          20.06587791442871,
          66.25617218017578,
          63.80339813232422,
          32.55656433105469,
          164.5828399658203,
          39.03438186645508,
          29.91950035095215,
          143.99436950683594,
          28.004932403564453,
          15.725319862365723,
          28.84115982055664,
          25.386289596557617,
          20.285526275634766,
          15.473930358886719,
          41.27907943725586,
          43.642520904541016,
          13.268729209899902,
          21.08510398864746,
          27.82468032836914,
          72.12654876708984,
          107.44119262695312,
          26.22159194946289,
          40.40890884399414,
          94.21795654296875,
          13.461755752563477,
          45.76435852050781,
          26.799095153808594,
          54.12712478637695,
          73.06991577148438,
          12.50475025177002,
          43.87883377075195,
          12.417655944824219,
          13.29914665222168,
          78.66281127929688,
          160.278076171875,
          113.50349426269531,
          155.91189575195312,
          113.72443389892578,
          101.16281127929688,
          17.069950103759766,
          12.107210159301758,
          11.978801727294922,
          103.44804382324219,
          13.669161796569824,
          13.281328201293945,
          47.19649124145508,
          63.218631744384766,
          11.495861053466797,
          59.24028778076172,
          88.45843505859375,
          11.429107666015625,
          14.922393798828125,
          14.506171226501465,
          46.93474197387695,
          65.24470520019531,
          49.889137268066406,
          12.523367881774902,
          28.560441970825195,
          24.577301025390625,
          60.350730895996094,
          15.537604331970215,
          13.925443649291992,
          50.71201705932617,
          12.90328598022461,
          252.55096435546875,
          35.86424255371094,
          17.095211029052734,
          12.45174789428711,
          114.1322250366211,
          11.904556274414062,
          146.7978973388672,
          46.097625732421875,
          55.23524856567383,
          13.343523979187012,
          71.68550109863281,
          34.85185623168945,
          56.24037551879883,
          134.09449768066406,
          124.09407043457031,
          55.251312255859375,
          23.860071182250977,
          12.291816711425781,
          67.5530014038086,
          46.80520248413086,
          32.782432556152344,
          27.92842674255371,
          53.968650817871094,
          25.10094451904297,
          32.27168273925781,
          9.404605865478516,
          9.774534225463867,
          123.28960418701172,
          12.940152168273926,
          32.036293029785156,
          137.49440002441406,
          109.94287872314453,
          11.447894096374512,
          126.21007537841797,
          80.04206085205078,
          39.067623138427734,
          9.185602188110352,
          36.12082290649414,
          12.502806663513184,
          49.62919998168945,
          27.422441482543945,
          50.02533721923828,
          160.73313903808594,
          37.47648239135742,
          51.99817657470703,
          119.7977294921875,
          22.9292049407959,
          43.20909881591797,
          19.374845504760742,
          17.032411575317383,
          70.87515258789062,
          43.86896896362305,
          93.22474670410156,
          103.32411193847656,
          101.57726287841797,
          51.00898361206055,
          22.88686180114746,
          20.559900283813477,
          43.36198425292969,
          16.600427627563477,
          79.97900390625,
          111.81108093261719,
          18.070009231567383,
          13.63975715637207,
          83.81414031982422,
          9.895537376403809,
          191.61923217773438,
          85.20665740966797,
          72.89949035644531,
          21.941823959350586,
          7.100129127502441,
          19.529794692993164,
          12.97296142578125,
          18.018733978271484,
          78.37357330322266,
          8.345261573791504,
          68.98582458496094,
          9.97636890411377,
          22.5744571685791,
          55.09048080444336,
          57.22227478027344,
          38.27534103393555,
          28.770235061645508,
          103.49424743652344,
          45.15200424194336,
          104.00755310058594,
          66.33955383300781,
          8.953169822692871,
          90.36832427978516,
          10.915420532226562,
          108.06112670898438,
          29.925256729125977,
          16.951396942138672,
          11.145645141601562,
          17.63697624206543,
          8.292218208312988,
          39.04423141479492,
          47.126705169677734,
          10.917579650878906,
          26.799222946166992,
          12.845888137817383,
          12.1712064743042,
          48.773136138916016,
          124.01069641113281,
          60.060699462890625,
          80.8075942993164,
          76.59523010253906,
          10.486785888671875,
          41.37327194213867,
          32.31468200683594,
          99.66716003417969,
          75.83849334716797,
          16.263446807861328,
          70.72920989990234,
          51.45573806762695,
          16.156652450561523,
          7.277467727661133,
          135.09056091308594,
          31.5109920501709,
          67.7087631225586,
          94.41305541992188,
          46.95134353637695,
          13.633756637573242,
          13.5619478225708,
          21.577369689941406,
          162.168212890625,
          48.26230239868164,
          34.71800994873047,
          15.80318832397461,
          51.82732391357422,
          47.880672454833984,
          43.98725891113281,
          38.90500259399414,
          62.12385940551758,
          92.24714660644531,
          36.447715759277344,
          36.61435317993164,
          17.90262794494629,
          9.142440795898438,
          7.18124532699585,
          21.9082088470459,
          40.963584899902344,
          12.195276260375977,
          8.747538566589355,
          15.704439163208008,
          48.858184814453125,
          21.11931610107422,
          34.50322341918945,
          20.89836883544922,
          30.643404006958008,
          93.25303649902344,
          23.36884117126465,
          21.80463409423828,
          15.118988037109375,
          54.839237213134766,
          72.9786148071289,
          14.880993843078613,
          72.7662582397461,
          15.247230529785156,
          12.303377151489258,
          12.892826080322266,
          27.542877197265625,
          15.506612777709961,
          97.51249694824219,
          13.4467191696167,
          80.09554290771484,
          13.901834487915039,
          68.92918395996094,
          18.146194458007812,
          6.789044380187988,
          37.222408294677734,
          8.272675514221191,
          58.710506439208984,
          15.847380638122559,
          7.153987407684326,
          19.41873550415039,
          13.999910354614258,
          34.08346176147461,
          25.24921417236328,
          35.601036071777344,
          35.39567947387695,
          6.39016580581665,
          24.628143310546875,
          51.14501190185547,
          36.815147399902344,
          6.003713130950928,
          21.433992385864258,
          8.410365104675293,
          21.490264892578125,
          6.882580280303955,
          54.08391571044922,
          32.65384292602539,
          16.259613037109375,
          6.432901382446289,
          8.027891159057617,
          25.461912155151367,
          7.060305595397949,
          5.9448628425598145,
          34.844703674316406,
          16.04973793029785,
          43.2796745300293,
          26.12554359436035,
          103.7667007446289,
          8.3884916305542,
          7.186809062957764,
          33.73432540893555,
          22.17623519897461,
          11.176933288574219,
          6.67376184463501,
          7.180183410644531,
          21.417173385620117,
          35.342247009277344,
          19.46588134765625,
          5.6676554679870605,
          10.409623146057129,
          8.162104606628418,
          5.969227313995361,
          54.488685607910156,
          7.5791168212890625,
          5.252441883087158,
          8.500572204589844,
          10.65541934967041,
          10.17470932006836,
          8.863384246826172,
          6.1208953857421875,
          29.04476547241211,
          13.915428161621094,
          29.515422821044922,
          7.056397914886475,
          5.685370445251465,
          54.15291213989258,
          9.061797142028809,
          4.789332866668701
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Loss"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation with plotly\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=history.epoch, y=history.history['loss'], name='Train'))\n",
    "fig.add_trace(go.Scatter(x=history.epoch, y=history.history['val_loss'], name='Validation'))\n",
    "fig.update_layout(title='Loss', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 1ms/step\n",
      "Accuracy on test set: 0.6496\n"
     ]
    }
   ],
   "source": [
    "# predicting on test set and computing accuracy\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print('Accuracy on test set: {:.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch version\n",
    "# transform data to tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.long)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class TwoLayerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(3, 64)\n",
    "        self.layer2 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.softmax(self.layer2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = TwoLayerModel()\n",
    "\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(2000):\n",
    "    # Forward pass\n",
    "    output = model(x_train)\n",
    "    loss = criterion(output, y_train)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.5709\n"
     ]
    }
   ],
   "source": [
    "# Predicting on test set and computing accuracy\n",
    "with torch.no_grad():\n",
    "    output = model(x_test)\n",
    "    y_pred = torch.argmax(output, dim=1)\n",
    "    print('Accuracy on test set: {:.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: the best model was the baseline built-in random forest classifier with a 65,62% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
